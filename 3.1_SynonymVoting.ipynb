{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import operator\n",
    "\n",
    "\n",
    "def union_num_index_syn_rule_out(dic_syn,list_index_rule_out):\n",
    "    _dic_syn_=dic_syn.copy()\n",
    "    for row,dic in enumerate(_dic_syn_):\n",
    "        synset=set()\n",
    "        for idx,syn in dic.items():\n",
    "            if idx not in list_index_rule_out[row]:\n",
    "                synset=synset.union(set(syn))\n",
    "        _dic_syn_[row]=synset\n",
    "    return(_dic_syn_) \n",
    "\n",
    "\n",
    "def union_num_index_syn_keep_in(dic_syn,list_index_rule_out):\n",
    "    _dic_syn_=dic_syn.copy()\n",
    "    for row,dic in enumerate(_dic_syn_):\n",
    "        synset=set()\n",
    "        for idx,syn in dic.items():\n",
    "            if idx in list_index_rule_out[row]:\n",
    "                synset=synset.union(set(syn))\n",
    "        _dic_syn_[row]=synset\n",
    "    return(_dic_syn_) \n",
    "\n",
    "\n",
    "\n",
    "def update_table_with_weights_and_remove_sets(words_table,columns,remove_sets):\n",
    "    table=words_table.copy()\n",
    "    for i in range(len(table)):\n",
    "        for col in columns:\n",
    "            table[col[1]][i]=set(table[col[0]][i])\n",
    "            table[col[1]][i]=table[col[1]][i].difference(table[remove_sets[0]][i])\n",
    "            table[col[1]][i]=table[col[1]][i].difference(table[remove_sets[1]][i])\n",
    "            table[col[1]][i]=list(table[col[1]][i])\n",
    "            table[col[1]][i]=table[col[1]][i]*col[2]\n",
    "    return(table)\n",
    "        \n",
    "\n",
    "def union_syn_cols(dataset,features,union_feature):\n",
    "    _dataset_=dataset.copy()\n",
    "    _dataset_[union_feature]=\"\"\n",
    "    for row in range(len(_dataset_[union_feature])):\n",
    "        synlist=[]\n",
    "        for feature in features:\n",
    "            synlist+=_dataset_[feature][row]\n",
    "        _dataset_[union_feature][row]=synlist\n",
    "    return(_dataset_[union_feature])\n",
    "\n",
    "def synonym_voter(dataset,union_feature):\n",
    "    _dataset_=dataset.copy()\n",
    "    _dataset_[\"temp\"]=\"\"\n",
    "    for row in range(0,len(_dataset_[union_feature])):\n",
    "        ranked_dic={}\n",
    "        for syn in _dataset_[union_feature][row]:\n",
    "            if syn in ranked_dic:\n",
    "                ranked_dic[syn]+=1\n",
    "            else:\n",
    "                ranked_dic[syn]=1\n",
    "        ranked_dic = sorted(ranked_dic.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        _dataset_[\"temp\"][row]=ranked_dic\n",
    "    return(_dataset_[\"temp\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2961: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "words_table=pd.read_excel(\n",
    "    \"./excels/2_Phase3_Word_Sense_Voting_CJ-15-07-19.xlsx\")\n",
    "\n",
    "columns=['JDM_Sense',\n",
    "         'JDM',\n",
    "         'WordNet',\n",
    "         'Cnrtl',\n",
    "         'Synonymo',\n",
    "         'Cisco',\n",
    "         'DicSyn_Sense']\n",
    "\n",
    "\n",
    "\n",
    "words_table[\"JDM sense to drop\"]=words_table[\"JDM sense to drop\"].astype(str).str.replace(\".\",\",\").str.replace(\"nan\",\"\")\n",
    "words_table[\"JDM sense to drop\"]=words_table[\"JDM sense to drop\"].apply(lambda s : re.sub(\"(^.*$)\",\"[\\\\1]\",s))\n",
    "words_table[\"JDM sense to drop\"]=words_table[\"JDM sense to drop\"].apply(lambda s: ast.literal_eval(s))\n",
    "\n",
    "\n",
    "words_table[\"DicSyn sense to drop\"]=words_table[\"DicSyn sense to drop\"].astype(str).str.replace(\".\",\",\").str.replace(\"nan\",\"\")\n",
    "words_table[\"DicSyn sense to drop\"]=words_table[\"DicSyn sense to drop\"].apply(lambda s : re.sub(\"(^.*$)\",\"[\\\\1]\",s))\n",
    "words_table[\"DicSyn sense to drop\"]=words_table[\"DicSyn sense to drop\"].apply(lambda s: ast.literal_eval(s))\n",
    "\n",
    "\n",
    "words_table=words_table.fillna(\"[]\")\n",
    "words_table[\"DicSyn_Sense\"]=words_table[\"DicSyn_Sense\"].apply(lambda s: re.sub(\"\\[\\]\", '{}', s))\n",
    "words_table[\"JDM_Sense\"]=words_table[\"JDM_Sense\"].apply(lambda s: re.sub(\"\\[\\]\", '{}', s))\n",
    "\n",
    "for col in columns:\n",
    "    words_table[col]=words_table[col].apply(lambda s: re.sub(\",[\\s]*nan\", ' ', s))\n",
    "    words_table[col]=words_table[col].apply(lambda s: re.sub(\"[^,\\s]*nan[\\s]+,\", '[', s))\n",
    "    words_table[col]=words_table[col].apply(lambda s: ast.literal_eval(s))\n",
    "    words_table[col+\"_\"]=\"\"\n",
    "    \n",
    "\n",
    "words_table[\"DicSyn_Sense_\"]=union_num_index_syn_rule_out(words_table[\"DicSyn_Sense\"],words_table[\"DicSyn sense to drop\"])  \n",
    "words_table[\"JDM_Sense_\"]=union_num_index_syn_rule_out(words_table[\"JDM_Sense\"],words_table[\"JDM sense to drop\"])  \n",
    "\n",
    "words_table[\"DicSyn_Sense_\"]=words_table[\"DicSyn_Sense_\"].apply(lambda s: list(s)) \n",
    "words_table[\"JDM_Sense_\"]=words_table[\"JDM_Sense_\"].apply(lambda s: list(s)) \n",
    "\n",
    "\n",
    "words_table[\"DicSyn_remove\"]=union_num_index_syn_keep_in(words_table[\"DicSyn_Sense\"],words_table[\"DicSyn sense to drop\"])  \n",
    "words_table[\"JDM_remove\"]=union_num_index_syn_keep_in(words_table[\"JDM_Sense\"],words_table[\"JDM sense to drop\"])  \n",
    "\n",
    "remove_sets=[\"DicSyn_remove\",\"JDM_remove\"]\n",
    "\n",
    "columns=[['JDM_Sense_'   ,'JDM_Sense_'   ,3],\n",
    "         ['JDM'          ,'JDM_'         ,2],\n",
    "         ['WordNet'      ,'WordNet_'     ,2],\n",
    "         ['Cnrtl'        ,'Cnrtl_'       ,1],\n",
    "         ['Synonymo'     ,'Synonymo_'    ,2],\n",
    "         ['Cisco'        ,'Cisco_'       ,2],\n",
    "         ['DicSyn_Sense_','DicSyn_Sense_',3]\n",
    "        ]\n",
    "\n",
    "words_table=update_table_with_weights_and_remove_sets(words_table,columns,remove_sets)\n",
    "\n",
    "words_table[\"Union_Sense\"]=union_syn_cols(words_table,\n",
    "                                      ['JDM_Sense_','JDM_','WordNet_','Cnrtl_','Synonymo_','Cisco_','DicSyn_Sense_']\n",
    "                                      ,\"Union_Sense\")\n",
    "\n",
    "words_table[\"Synonyms_Voting\"]=synonym_voter(words_table,\"Union_Sense\")\n",
    "\n",
    "words_table_to_write=words_table[['Word','Word_Corrected','JDM_Sense_','JDM sense to drop','JDM_','WordNet_','Cnrtl_','Synonymo_','Cisco_','DicSyn_Sense_','DicSyn sense to drop','Synonyms_Voting']]\n",
    "\n",
    "\n",
    "words_table_to_write[\"Synonyms_Voting_Top5\"]=\"\"\n",
    "words_table_to_write[\"Synonyms_Voting_Top10\"]=\"\"\n",
    "words_table_to_write[\"Synonyms_Voting_Top15\"]=\"\"\n",
    "words_table_to_write[\"Synonyms_Voting_Top20\"]=\"\"\n",
    "words_table_to_write[\"Synonyms_Voting_Rest\"]=\"\"\n",
    "\n",
    "for row in range(len(words_table_to_write[\"Synonyms_Voting\"])):\n",
    "    words_table_to_write[\"Synonyms_Voting_Top5\"][row]=[x for x,y in words_table_to_write[\"Synonyms_Voting\"][row][0:5]]\n",
    "    words_table_to_write[\"Synonyms_Voting_Top10\"][row]=[x for x,y in words_table_to_write[\"Synonyms_Voting\"][row][0:10]]\n",
    "    words_table_to_write[\"Synonyms_Voting_Top15\"][row]=[x for x,y in words_table_to_write[\"Synonyms_Voting\"][row][0:15]]\n",
    "    words_table_to_write[\"Synonyms_Voting_Top20\"][row]=[x for x,y in words_table_to_write[\"Synonyms_Voting\"][row][0:20]]\n",
    "    words_table_to_write[\"Synonyms_Voting_Rest\"][row]=[x for x,y in words_table_to_write[\"Synonyms_Voting\"][row][20:]]\n",
    "\n",
    "\n",
    "# words_table_to_write.to_excel(\n",
    "#     \"./excels/3_Phase3_Word_Sense_Voting_New_Format.xlsx\")\n",
    "\n",
    "# words_table_to_write  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=pd.read_excel(\n",
    "    \"./excels/1_Phase3_TranslationTable.xlsx\")\n",
    "\n",
    "words_table_to_write[\"List_of_Occurances\"]=\"\"\n",
    "\n",
    "for i in range(len(words_table_to_write[\"Word\"])):\n",
    "    words_list=[]\n",
    "    for row,value in enumerate(words[\"French Expression\"]):\n",
    "        if words_table_to_write[\"Word\"][i] in value:\n",
    "            words_list.append(value)    \n",
    "    words_table_to_write[\"List_of_Occurances\"][i]=words_list\n",
    "            \n",
    "words_table_to_write.to_excel(\n",
    "    \"./excels/3_Phase3_Word_Sense_Voting_with_Occurances.xlsx\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
