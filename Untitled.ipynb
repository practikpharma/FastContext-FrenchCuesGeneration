{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "update=[]\n",
    "\n",
    "list_of_notebooks=[\n",
    "\"Validation_Notebook_0_100.ipynb\",\n",
    "\"Validation_Notebook_101_200.ipynb\",\n",
    "\"Validation_Notebook_201_300.ipynb\",\n",
    "\"Validation_Notebook_301_400.ipynb\",\n",
    "\"Validation_Notebook_401_500.ipynb\",\n",
    "\"Validation_Notebook_501_600.ipynb\",\n",
    "\"Validation_Notebook_601_737.ipynb\"]\n",
    "\n",
    "pattern=re.compile(r\"Group\\[(\\d+),?\\s?(\\d+)?\\]\")\n",
    "count=0\n",
    "\n",
    "for i in range(len(list_of_notebooks)):\n",
    "    with open('./notebooks-Clement/'+list_of_notebooks[i]) as json_data:\n",
    "        notebook = json.load(json_data)\n",
    "        json_data.close()\n",
    "    \n",
    "    for j in range(len(notebook[\"cells\"])):\n",
    "        text=notebook[\"cells\"][j][\"source\"]\n",
    "        if \"Trigger_Rule\" in text[-5]:\n",
    "            matches = pattern.finditer(text[-5])\n",
    "        else:\n",
    "            matches = pattern.finditer(text[-4])            \n",
    "        groups=[]\n",
    "        for match in matches:\n",
    "            groups.append(match.group(0))\n",
    "        count+=1\n",
    "        update.append([count,groups,notebook[\"cells\"][j][\"source\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  ['Group[2]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"\\\\\\\\> 0 mois\" | \"\\\\\\\\> 0 ans\" | \"\\\\\\\\> 0 année\" | \"\\\\\\\\> 0 années\" | \"\\\\\\\\> 1 semaines\" | \"\\\\\\\\> 13 jours\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|historical|30|Group[2]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [2,\n",
       "  ['Group[4]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"il y a \\\\\\\\> 0 mois\" | \"il y a \\\\\\\\> 0 an\" | \"il y a \\\\\\\\> 0 ans\" | \"il y a \\\\\\\\> 1 semaines\" \\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[4]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [3,\n",
       "  ['Group[23]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \": non\" | \": neg\" | \": nég\"| \": négatif\" | \": negatif\" | \": négative\" | \": nul\" | \": nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[23]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [4,\n",
       "  ['Group[24]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Word Var1 Trigger_Rule\\n',\n",
       "   'Word -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var1 -> \"pas\" | \"aucun\" | \"aucune\" | \"nul\" | \"nulle\" | \"sans\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[24]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [5,\n",
       "  ['Group[26]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"absence\" | \"manque\" | \"omission\" | \"privation\" | \"carence\" | \"défaillance\" | \"défection\" | \"lacune\" | \"déficit\" | \"déficience\"\\n',\n",
       "   'Var2 -> \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[26]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [6,\n",
       "  ['Group[30]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"suffisant\" | \"suffisante\" | \"passable\" | \"satisfaisant\" | \"satisfaisante\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"correcte\" | \"tolérable\" | \"bon\" | \"pas mal\" | \"bien\" | \"adéquat\" | \"adéquate\" | \"assez bien\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Var3 -> \"écarter\" | \"rejeter\" | \"éliminer\" | \"évincer\" | \"supprimer\" | \"proscrire\" | \"ôter\" | \"exclure\" | \"éloigner\" | \"refuser\" | \"se défaire\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[30]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [7,\n",
       "  ['Group[42]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Patient Trigger_Rule\\n',\n",
       "   'Var1 -> \"suffisant\" | \"suffisante\" | \"passable\" | \"satisfaisant\" | \"satisfaisante\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"correcte\" | \"tolérable\" | \"bon\" | \"pas mal\" | \"bien\" | \"adéquat\" | \"adéquate\" | \"assez bien\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Var3 -> \"exclure\" | \"éliminer\" | \"rejeter\" | \"proscrire\" | \"éloigner\" | \"supprimer\" | \"radier\"\\n',\n",
       "   'Patient -> \"le patient\" | \"la patiente\"| \"le souffrant\" | \"la souffrante\"| \"le sujet\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[42]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [8,\n",
       "  ['Group[47]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"après\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[47]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [9,\n",
       "  ['Group[48]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"bien\"\\n',\n",
       "   'Var2 -> \"que\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[48]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [10,\n",
       "  ['Group[51]', 'Group[49]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"présenté\"\\n',\n",
       "   'Var2 -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|historical|10|Group[51]|Clement\" | \"|forward|termination|negated|10|Group[49]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [11,\n",
       "  ['Group[53]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+ \\\\\\\\w+\" | \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"montre\" | \"démontre\" | \"signale\" \\n',\n",
       "   'Var4 -> \"_\"|\"_nt\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[53]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [12,\n",
       "  ['Group[59]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Var2 -> \"a\"\\n',\n",
       "   'Var3 -> \"fait\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[59]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [13,\n",
       "  ['Group[60]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Pronoun Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Pronoun -> \"il\" | \"elle\"\\n',\n",
       "   'Var2 -> \"avait\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[60]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [14,\n",
       "  ['Group[61]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Termin Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"noté\" | \"remarqué\" | \"observé\" | \"consigné\" | \"classé\" | \"évalué\" | \"étiqueté\" | \"mentionné\"\\n',\n",
       "   'Termin -> \"_\"|\"_e\"\\n',\n",
       "   'Var4 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[61]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [15,\n",
       "  ['Group[61]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Termin Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ont\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"noté\" | \"remarqué\" | \"observé\" | \"consigné\" | \"classé\" | \"évalué\" | \"étiqueté\" | \"mentionné\"\\n',\n",
       "   'Termin -> \"_s\"|\"_es\"\\n',\n",
       "   'Var4 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[61]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [16,\n",
       "  ['Group[62]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Var2 -> \"il\" | \"elle\" \\n',\n",
       "   'Var3 -> \"était\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[62]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [17,\n",
       "  ['Group[63]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Var2 -> \"noté\" | \"constaté\" | \"relevé\" | \"remarqué\" | \"observé\" | \"évalué\" | \"mentionné\"\\n',\n",
       "   'Var3 -> \"d\\'avoir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[63]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [18,\n",
       "  ['Group[64]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Var2 -> \"il\" | \"elle\"\\n',\n",
       "   'Var3 -> \"avait\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[64]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [19,\n",
       "  ['Group[67]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Patient Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Patient -> \"le patient\" | \"la patiente\"| \"le souffrant\" | \"la souffrante\"| \"le sujet\"\\n',\n",
       "   'Var2 -> \"avait\" | \"était\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[67]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [20,\n",
       "  ['Group[69]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"et\"\\n',\n",
       "   'Var2 -> \"avec\"\\n',\n",
       "   'Var3 -> \"seulement\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[69]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [21,\n",
       "  ['Group[71]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"tout\"\\n',\n",
       "   'Var2 -> \"autre\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[71]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [22,\n",
       "  ['Group[73]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"excepté\" | \"sauf\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[73]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [23,\n",
       "  ['Group[74]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"semble\" | \"semblait\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[74]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [24,\n",
       "  ['Group[75]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"est négatif\" | \"est null\" | \"sont négatifs\" | \"sont nulls\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[75]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [25,\n",
       "  ['Group[77]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'est\" | \"ne sont\"\\n',\n",
       "   'Var2 -> \"plus\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[77]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [26,\n",
       "  ['Group[79]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"est exclu\" | \"est exclue\" | \"sont exclus\" | \"sont exclues\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[79]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [27,\n",
       "  ['Group[81]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sont arrêtés\" | \"sont stoppés\" | \"sont enrayés\" | \"sont contenus\" | \"sont suspendus\" | \"sont jugulés\" | \"sont terminés\" | \"sont immobilisés\" | \"sont finis\" | \"sont endigés\" | \"ont cessés\" | \"sont gelés\" | \"sont coupés\" | \"sont arrêtées\" | \"sont stoppées\" | \"sont enrayées\" | \"sont contenues\" | \"sont suspendues\" | \"sont jugulées\" | \"sont terminées\" | \"sont immobilisées\" | \"sont finies\" | \"sont endigées\" | \"ont cessées\" | \"sont gelées\" | \"sont coupées\" | \"est arrêté\" | \"est stoppé\" | \"est enrayé\" | \"est contenu\" | \"est suspendu\" | \"est jugulé\" | \"est terminé\" | \"est immobilisé\" | \"est fini\" | \"est endigé\" | \"a cessé\" | \"est gelé\" | \"est coupé\" | \"est arrêtée\" | \"est stoppée\" | \"est enrayée\" | \"est contenue\" | \"est suspendue\" | \"est jugulée\" | \"est terminée\" | \"est immobilisée\" | \"est finie\" | \"est endigée\" | \"est gelée\" | \"est coupée\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[81]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [28,\n",
       "  ['Group[84]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Termin Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"origine\" | \"début\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"prédéterminant\" | \"raison\" | \"départ\" | \"étiologie\" | \"causalité\" | \"source\" | \"point de départ\" | \"prétexte\" | \"déclencheur\" | \"mobile\" | \"explication\"\\n',\n",
       "   'Termin -> \"_s\"  \\n',\n",
       "   'Var2 -> \"de\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[84]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [29,\n",
       "  ['Group[84]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"comme\"\\n',\n",
       "   'Var2 -> \"l\\'origine\" | \"le début\" | \"le commencement\" | \"la provenance\" | \"la cause\" | \"la formation\" | \"la base\" | \"le fondement\" | \"le prédéterminant\" | \"la raison\" | \"le départ\" | \"l\\'étiologie\" | \"la causalité\" | \"la source\" | \"le point de départ\" | \"le prétexte\" | \"le déclencheur\" | \"le mobile\" | \"l\\'explication\" |\"une origine\" | \"un début\" | \"un commencement\" | \"une provenance\" | \"une cause\" | \"une formation\" | \"une base\" | \"un fondement\" | \"un prédéterminant\" | \"une raison\" | \"un départ\" | \"une étiologie\" | \"une causalité\" | \"une source\" | \"un point de départ\" | \"un prétexte\" | \"un déclencheur\" | \"un mobile\" | \"une explication\"\\n',\n",
       "   'Var3 -> \"de\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[84]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [30,\n",
       "  ['Group[84]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"comme\"\\n',\n",
       "   'Var2 -> \"pour\" | \"pourquoi\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[84]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [31,\n",
       "  ['Group[90]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"comme\"\\n',\n",
       "   'Var2 -> \"origine\" | \"début\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"prédéterminant\" | \"raison\" | \"départ\" | \"étiologie\" | \"causalité\" | \"source\" | \"point de départ\" | \"prétexte\" | \"déclencheur\" | \"mobile\" | \"explication\" |\\n',\n",
       "   'Var3 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var4 -> \"de\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[90]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [32,\n",
       "  ['Group[122]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Article Trigger_Rule\\n',\n",
       "   'Var1 -> \"comme\"\\n',\n",
       "   'Article -> \"l\\'\" | \"le\" | \"la\" | \"un\" | \"une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[122]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [33,\n",
       "  ['Group[123]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"comme\" | \"tel que\"\\n',\n",
       "   'Var2 -> \"requis\" | \"nécessaire\" | \"prescrit\" | \"demandé\" | \"réclamé\" | \"souhaitable\" | \"sollicité\" | \"commandé\" | \"nécessité\" | \"souhaité\" | \"enjoint\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[123]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [34,\n",
       "  ['Group[144]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Deter Trigger_Rule\\n',\n",
       "   'Var1 -> \"ainsi\"\\n',\n",
       "   'Var2 -> \"que\"\\n',\n",
       "   'Deter -> \"tout\" | \"tous\" | \"toute\" | \"toutes\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[144]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [35,\n",
       "  ['Group[146]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"à\"\\n',\n",
       "   'Var2 -> \"part\" | \"l\\'exception\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[146]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [36,\n",
       "  ['Group[147]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"comme\" | \"ainsi\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[147]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [37,\n",
       "  ['Group[148]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en\" | \"à\" \\n',\n",
       "   'Var2 -> \"ce\"\\n',\n",
       "   'Var3 -> \"moment\" | \"jour\" | \"temps\" | \"stage\" | \"stade\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[148]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [38,\n",
       "  ['Group[148]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en\" | \"à\" \\n',\n",
       "   'Var2 -> \"cet\"\\n',\n",
       "   'Var3 -> \"épisode\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[148]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [39,\n",
       "  ['Group[148]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en\" | \"à\" \\n',\n",
       "   'Var2 -> \"cette\"\\n',\n",
       "   'Var3 -> \"saison\" | \"époque\" | \"phase\" | \"plage de temps\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[148]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [40,\n",
       "  ['Group[148]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pendant que\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[148]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [41,\n",
       "  ['Group[150]', 'Group[151]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"tenté\" | \"expérimenté\" | \"risqué\" | \"cherché\" | \"entrepris\" | \"osé\" | \"hasardé\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[150]|Clement\"|\"|both|termination|nonpatient|30|Group[151]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [42,\n",
       "  ['Group[152]', 'Group[153]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"tentative\" | \"expérience\" | \"expérimentation\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[152]|Clement\"|\"|both|termination|nonpatient|30|Group[153]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [43,\n",
       "  ['Group[234]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"par la famille\" |\"par \\\\\\\\w+ famille\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|nonpatient|30|Group[234]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [44,\n",
       "  ['Group[234]', 'Group[234]', 'Group[153]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Member Var1 Trigger_Rule\\n',\n",
       "   'Member -> \"parent a\" | \"parents ont\" | \"père a\" | \"beau-père a\" | \"mère a\" |\"belle-mère a\" | \"papa a\" | \"maman a\" |\"fils a\" | \"fils ont\" |\"beau-fils a\" | \"beau-fils ont\" |\"fils a\" | \"fils ont\" | \"garçon a\" | \"garçcons ont\" | \"fille a\" | \"filles ont\" | \"belle-fille a\" | \"belle-filles ont\" | \"frère a\" | \"frères ont\" |\"soeur a\" | \"soeurs ont\" |\"sœur a\" |\"sœurs ont\" | \"oncle a\" | \"tonton a\" |\"grand-mère a\" | \"grand-père a\" |\"tante a\" | \"tata a\"|\"cousin a\" |\"cousins ont\" |\"famille a\" |\"colocataire a\" | \"colocataires ont\"|\"voisin a\"|\"voisins ont\"  \\n',\n",
       "   'Var1 -> \"rapporté\" |\"appelé\" | \"dit\" |\"déclaré\" |\"trouvé\" | \"signalé\" | \"sollicité\" | \"requéri\" | \"téléphoné\" | \"averti\" | \"prévenu\" | \"alerté\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|nonpatient|30|Group[234]|Clement\" | \"|both|termination|historical|30|Group[234]|Clement\"|\"|both|termination|nonpatient|30|Group[153]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [45,\n",
       "  ['Group[154]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Member Trigger_Rule\\n',\n",
       "   'Member -> \"parent\" | \"parents\" | \"père\" | \"beau-père\" | \"mère\" |\"belle-mère\" | \"papa\" | \"maman\" |\"fils\" | \"beau-fils\" | \"garçon\" | \"garçons\" | \"fille\" | \"belle-fille\" | \"filles\" | \"frère\"| \"frères\" |\"soeur\" |\"soeurs\" |\"sœur\" |\"sœurs\" | \"fratrie\" | \"oncle\"| \"tonton\"| \"oncles\" |\"tante\" | \"tata\"| \"tantes\" |\"grand-mère\" | \"grand-père\" |\"cousin\" |\"cousins\" |\"famille\" |\"colocataire\" | \"colocataires\" | \"voisin\" | \"voisins\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|nonpatient|30|Group[154]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [46,\n",
       "  ['Group[1040]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire sociale\" \\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[1040]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [47,\n",
       "  ['Group[156]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"être\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Termin -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Var3 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[156]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [48,\n",
       "  ['Group[157]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"été\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Termin -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[157]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [49,\n",
       "  ['Group[158]', 'Group[159]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"être\"\\n',\n",
       "   'Var2 -> \"arrêté\" | \"stoppé\" | \"suspendu\" | \"terminé\" | \"fini\" | \"endigué\" | \"cessé\" | \"interrompu\" | \"gelé\"\\n',\n",
       "   'Var3 -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[158]|Clement\"|\"|forward|termination|negated|10|Group[159]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [50,\n",
       "  ['Group[158]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"est\"\\n',\n",
       "   'Var2 -> \"arrêté\" | \"stoppé\" | \"suspendu\" | \"terminé\" | \"fini\" | \"endigué\" | \"cessé\" | \"interrompu\" | \"gelé\"| \"arrêtée\" | \"stoppée\" | \"suspendue\" | \"terminée\" | \"finie\" | \"endiguée\" | \"cessée\" | \"interrompue\" | \"gelée\"\\n',\n",
       "   'Termin -> \"_\" | \"_e\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[158]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [51,\n",
       "  ['Group[158]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"sont\"\\n',\n",
       "   'Var2 -> \"arrêtés\" | \"stoppés\" | \"suspendus\" | \"terminés\" | \"finis\" | \"endigués\" | \"cessés\" | \"interrompus\" | \"gelés\"| \"arrêtées\" | \"stoppées\" | \"suspendues\" | \"terminées\" | \"finies\" | \"endiguées\" | \"cessées\" | \"interrompues\" | \"gelées\"\\n',\n",
       "   'Termin -> \"_s\" |\"_es\"\\n',\n",
       "   '\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[158]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [52,\n",
       "  ['Group[159]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"mettre fin\" | \"mis fin\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[159]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [53,\n",
       "  ['Group[160]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"parce\"\\n',\n",
       "   'Var2 -> \"que\"|\"qu\\'il\"|\"qu\\'elle\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|conditional|30|Group[160]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [54,\n",
       "  ['Group[162]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"au-delà\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[162]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [55,\n",
       "  ['Group[163]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"biopsie\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[163]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [56,\n",
       "  ['Group[164]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"limite\" | \"seuil\" | \"serré\"| \"serrée\"| \"juste\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[164]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [57,\n",
       "  ['Group[168]', 'Group[169]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"mais\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[168]|Clement\"|\"|backward|termination|negated|10|Group[169]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [58,\n",
       "  ['Group[174]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Article Trigger_Rule\\n',\n",
       "   'Var1 -> \"pour\" | \"par\"\\n',\n",
       "   'Article -> \"l\\'\" | \"le\" | \"la\" | \"un\" | \"une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[174]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [59,\n",
       "  ['Group[176]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[176]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [60,\n",
       "  ['Group[177]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Termin -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[177]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [61,\n",
       "  ['Group[179]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"éliminer\" | \"écarter\" | \"évincer\" | \"exclure\" | \"chasser\" | \"proscrire\" | \"rejeter\" | \"repousser\" | \"enlever\" | \"éloigner\" | \"retirer\"  | \"ôter\" | \"récuser\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[179]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [62,\n",
       "  ['Group[196]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Patient Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"exclure\" | \"éliminer\" | \"rejeter\" | \"proscrire\" | \"éloigner\" | \"supprimer\" | \"radier\"\\n',\n",
       "   'Patient -> \"le patient\" | \"la patiente\"| \"le souffrant\" | \"la souffrante\"| \"le sujet\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[196]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [63,\n",
       "  ['Group[202]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Var5 Var6 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"peut\"\\n',\n",
       "   'Var3 -> \"pas\"\\n',\n",
       "   'Var4 -> \"être\"\\n',\n",
       "   'Var5 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var6 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscri\"\\n',\n",
       "   'Termin -> \"_\"|\"_e\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[202]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [64,\n",
       "  ['Group[205]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"peut\"\\n',\n",
       "   'Var3 -> \"voir\" | \"saisir\" | \"percevoir\" | \"constater\" | \"considérer\" | \"concevoir\" | \"remarquer\" | \"trouver\" | \"rencontrer\" | \"découvrir\" | \"vérifier\" | \"distinguer\" | \"entrevoir\" | \"discerner\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[205]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [65,\n",
       "  ['Group[207]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"peux\" |\"peut\"|\"pouvait\"|\"pouvais\"\\n',\n",
       "   'Var3 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[207]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [66,\n",
       "  ['Group[209]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"cause\" | \"raison\" | \"prétexte\" | \"fondement\" | \"source\" | \"intention\" | \"origine\" | \"déclencheur\" | \"départ\"\\n',\n",
       "   'Var2 -> \"_\" | \"_s\"\\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[209]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [67,\n",
       "  ['Group[213]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"vérifié\" | \"contrôlé\" | \"examiné\" | \"testé\" | \"expertisé\" | \"inspecté\"\\n',\n",
       "   'Var2 -> \"pour\" | \"par\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[213]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [68,\n",
       "  ['Group[215]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"libre\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[215]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [69,\n",
       "  ['Group[217]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"revenir\" | \"reparaître\" | \"reprendre\" | \"repasser\"| \"remettre\"\\n',\n",
       "   'Var2 -> \"à\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[217]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [70,\n",
       "  ['Group[219]', 'Group[220]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"se\"\\n',\n",
       "   'Var2 -> \"plaint\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[219]|Clement\"|\"|both|termination|nonpatient|30|Group[220]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [71,\n",
       "  ['Group[221, 223]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"concerné\" | \"préoccupé\" | \"tourmenté\" | \"anxieux\" | \"inquiet\" | \"hanté\" | \"tracassé\" | \"absorbé\" | \"ennuyé\" | \"angoissé\" | \"embarrassé\" | \"occupé\" | \"agité\"\\n',\n",
       "   'Termin -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Var2 -> \"pour\"|\"par\"|\"à propos de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[221, 223]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [72,\n",
       "  ['Group[225]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"cohérent\" | \"homogène\" | \"harmonieux\" | \"rationnel\" | \"compréhensible\" | \"consistant\" | \"uni\" | \"en accord\" | \"rationnelle\" \\n',\n",
       "   'Var2 -> \"avec\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[225]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [73,\n",
       "  ['Group[226]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pourrait\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"soit\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[226]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [74,\n",
       "  ['Group[227]', 'Group[665]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pourrait\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[227]|Clement\"|\"|forward|trigger|uncertain|30|Group[665]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [75,\n",
       "  ['Group[228]', 'Group[230]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"pourrait\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Termin -> \"_\"|\"_e\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[228]|Clement\"|\"|backward|trigger|uncertain|30|Group[230]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [76,\n",
       "  ['Group[228]', 'Group[230]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"pourraient\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Termin -> \"_s\"|\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[228]|Clement\"|\"|backward|trigger|uncertain|30|Group[230]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [77,\n",
       "  ['Group[245]', 'Group[246]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"décide\" | \"choisi\" | \"décréte\" \\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[245]|Clement\"|\"|both|termination|nonpatient|30|Group[246]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [78,\n",
       "  ['Group[245]', 'Group[246]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a décidé\" | \"a choisi\" | \"a décrété\" \\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[245]|Clement\"|\"|both|termination|nonpatient|30|Group[246]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [79,\n",
       "  ['Group[252]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"décline\" | \"dédaigne\" | \"atténu\" | \"tombe\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[252]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [80,\n",
       "  ['Group[252]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a décliné\"|\"a diminué\" | \"s\\'affaibli\" | \"a baissé\" | \"s\\'est atténué\" | \"s\\'est atténuée\" | \"a ralenti\" | \"s\\'est tempéré\" | \"s\\'est tempérée\" | \"est tombé\" | \"est tombée\" | \"a faibli\" | \"s\\'est allégé\" | \"s\\'est allégée\" | \"a décru\" | \"s\\'est adouci\"| \"s\\'est adoucie\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[252]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [81,\n",
       "  ['Group[255]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"renvoyé\" | \"contesté\" | \"dédaigné\" | \"exclu\" | \"écarté\" | \"décliné\" | \"résisté\" | \"répugné\" | \"dit non à\" | \"retoqué\" |\"désapprouvé\" | \"opposé\" | \"opposée\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[255]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [82,\n",
       "  ['Group[255]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nier\" |\"dénier\" | \"renier\" | \"contredire\" | \"démentir\" | \"refuser\" | \"rejeter\" |\"réfuter\" | \"renvoyer\" | \"contester\" | \"dédaigner\" | \"exclure\" | \"écarter\" | \"décliner\" | \"résister\" | \"répugner\" | \"dire non\" | \"retoquer\" |\"désapprouver\" | \"opposer\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[255]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [83,\n",
       "  ['Group[257]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Deter Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"renvoyé\" | \"contesté\" | \"dédaigné\" | \"exclu\" | \"écarté\" | \"décliné\" | \"résisté\" | \"répugné\" | \"dit non à\" | \"retoqué\" |\"désapprouvé\" | \"opposé\" | \"opposée\" | \"désapprouvé\"\\n',\n",
       "   'Deter -> \"tout\" | \"toute\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\" \\n',\n",
       "   'Var3 -> \"significatif\" | \"important\" |\"anormale\" | \"aberrant\" | \"étonnant\" | \"inhabituel\" | \"étrange\" | \"inaccoutumé\" | \"singulier\" | \"insolite\" | \"irrégulier\" | \"anomal\" | \"exceptionnel\" | \"paradoxal\" | \"surprenant\" | \"déséquilibré\" | \"excentrique\" | \"courant\" | \"habituel\" | \"fréquent\" | \"connu\" | \"répandu\" | \"normal\" | \"classique\" | \"présent\" | \"commune\" | \"régulier\" | \"en cours\"\\n',\n",
       "   '\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[257]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [84,\n",
       "  ['Group[260]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Deter Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"renvoyé\" | \"contesté\" | \"dédaigné\" | \"exclu\" | \"écarté\" | \"décliné\" | \"résisté à\" | \"répugné\" | \"dit non à\" | \"retoqué\" |\"désapprouvé\" | \"opposé\" | \"opposée\"\\n',\n",
       "   'Deter -> \"tout changement\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[260]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [85,\n",
       "  ['Group[264]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"renvoyé\"  | \"exclu\" | \"écarté\" | \"décliné\" | \"résisté à\" | \"dit non à\" | \"retoqué\" |\"désapprouvé\" | \"opposé\" | \"opposée\"\\n',\n",
       "   'Var2 -> \"tout risque élevé\" | \"toute chance\" | \"tout danger\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[264]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [86,\n",
       "  ['Group[264]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"rejeté\" |\"réfuté\" | \"contesté\" | \"exclu\" | \"écarté\" | \"décliné\" | \"résisté à\" | \"dit non à\" | \"retoqué\" |\"désapprouvé\" | \"opposé\" | \"opposée\"\\n',\n",
       "   'Var2 -> \"toute récente\" | \"tout nouveau\" | \"tout jeune\" | \"tout récent\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[264]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [87,\n",
       "  ['Group[264]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"rejeté\" |\"réfuté\" | \"contesté\" | \"dédaigné\" | \"exclu\" | \"écarté\"| \"désapprouvé\"\\n',\n",
       "   'Var2 -> \"tout problème\" | \"tout ennui\" | \"tout souci\" | \"toute complication\" | \"toute anomalie\" | \"tout dysfonctionnement\" | \"tout disfonctionnement\" | \"tout soucis\" | \"tout trouble\" | \"tout abus\" | \"tous excès\" | \"toutes exagérations\" | \"tous débordements\"  | \"toutes débauches\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[264]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [88,\n",
       "  ['Group[264]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"contesté\" | \"exclu\" | \"écarté\"\\n',\n",
       "   'Var2 -> \"toute histoire\" | \"tout passé\" | \"tout souvenir\" | \"toute historique\" | \"tout antécédent\" | \"tout symptôme\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[264]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [89,\n",
       "  ['Group[264]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"rejeté\" |\"réfuté\" | \"contesté\" | \"dédaigné\" | \"exclu\" | \"écarté\"| \"désapprouvé\"\\n',\n",
       "   'Var2 -> \"des problèmes\" | \"des ennuis\" | \"des soucis\" | \"des complications\" | \"des histoires\" | \"des anomalies\" | \"des dysfonctionnements\" | \"des disfonctionnements\" | \"des soucis\" | \"des troubles\" | \"des abus\" | \"des excès\" | \"des exagérations\" | \"des débordements\" | \"trop de\" | \"des débauches\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[264]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [90,\n",
       "  ['Group[295]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"contesté\" | \"exclu\" | \"écarté\"\\n',\n",
       "   'Var2 -> \"des symptômes\" | \"des marques\" | \"des indices\" | \"des manifestations\" | \"des présages\" | \"un syndrome\" | \"des stigmates\" | \"des signes\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[295]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [91,\n",
       "  ['Group[297]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Auxiliary1 -> \"a\"\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"rejeté\" |\"réfuté\" | \"contesté\" | \"exclu\" | \"écarté\" |\"désapprouvé\" | \"opposé\" | \"opposée\"\\n',\n",
       "   'Var2 -> \"qu\\'il\"\\n',\n",
       "   'Var3 -> \"y avait\" |\"avait\" |\"y ait\" |\"y en ait\" | \"n\\'y ait\"| \"n\\'y en ait\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[297]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [92,\n",
       "  ['Group[329]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"nié\" |\"dénié\" | \"renié\" | \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"renvoyé\" | \"contesté\" | \"exclu\" | \"écarté\" | \"décliné\" | \"résisté à\" | \"répugné\" | \"dit non à\" | \"retoqué\" |\"désapprouvé\" | \"opposé à\" | \"opposée à\"\\n',\n",
       "   'Var2 -> \"l\\'utilisation\" | \"l\\'emploi\" | \"le maniement\" | \"l\\'usage\" | \"l\\'exploitation\" | \"la consommation\" | \"l\\'appel\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[329]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [93,\n",
       "  ['Group[429]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\" | \"ait\"| \"avait\"\\n',\n",
       "   'Var2 -> \"eu\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[429]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [94,\n",
       "  ['Group[430]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->   Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\"| \"n\\'ait\"| \"n\\'avait\"| \"n\\'y avait\" |\"n\\'y ait\" |\"n\\'y en ait\"\\n',\n",
       "   'Var2 -> | \"eu\" \\n',\n",
       "   'Var3 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[430]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [95,\n",
       "  ['Group[432]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3  Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\"\\n',\n",
       "   'Var2 -> \"plus\"\\n',\n",
       "   'Var3 -> \"d\\'épisodes\" | \"fait\" | \"d\\'histoire\" | \"de phase\" | \"d\\'accident\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[432]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [96,\n",
       "  ['Group[434]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\"| \"n\\'ait\"| \"n\\'avait\"| \"n\\'y avait\" |\"n\\'y ait\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"eu\" | \" \"\\n',\n",
       "   'Var4 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[434]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [97,\n",
       "  ['Group[434]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Var4 Var5 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"eu\"\\n',\n",
       "   'Var4 -> \"de problème\" | \"d\\'ennui\" | \"de souci\" | \"de complication\" | \"de dysfonctionnement\" | \"de disfonctionnement\" | \"de soucis\" | \"de tracas\"  | \"d\\'incident\" | \"de couac\"\\n',\n",
       "   'Var5 -> \"avec\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[434]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [98,\n",
       "  ['Group[434]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\"| \"n\\'ait\"| \"n\\'avait\"\\n',\n",
       "   'Var2 -> \"signalé\" | \"indiqué\" | \"notifié\" | \"découvert\" | \"montré\" | \"dévoilé\" | \"souligné\" | \"informé d\\'\" | \"révélé\" | \"signifié\" | \"déclaré\" | \"averti d\\'\" | \"rapporté\" | \"témoigné\" | \"alerté d\\'\"\\n',\n",
       "   'Var3 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[434]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [99,\n",
       "  ['Group[436]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"observé\" | \"remarqué\" | \"noté\" | \"découvert\" | \"apercu\" | \"signalé\" | \"vu\" | \"relevé\" | \"décelé\" | \"détecté\" | \"souligné\" | \"mentionné\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[436]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [100,\n",
       "  ['Group[438]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\" | \"n\\'ait\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[438]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [101,\n",
       "  ['Group[439]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"l\\'a\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"mise à lécart\" | \"mis à lécart\" |\"rendu inenvisageable\" | \"rendu irréalisable\" | \"évincé\"| \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[439]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [102,\n",
       "  ['Group[439]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Var3 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[439]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [103,\n",
       "  ['Group[439]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" |  \"contredit\" | \"démentit\" | \"refusé\" | \"rejeté\" |\"réfuté\" | \"contesté\" | \"écarté\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[439]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [104,\n",
       "  ['Group[457]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Patient Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Patient -> \"le patient\" | \"la patiente\"| \"le souffrant\" | \"la souffrante\"| \"le sujet\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[457]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [105,\n",
       "  ['Group[457]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Var3 -> \"le patient\" | \"le client\" | \"souffrant\" | \"sujet\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[457]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [106,\n",
       "  ['Group[463]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"montré\" | \"affiché\" | \"exhibé\" | \"fait état\" | \"démontré\" | \"exposé\" | \"exhibé\" | \"dénoté\" | \"confirmé\" | \"expliqué\" | \"découvert\" | \"dévoilé\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[463]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [107,\n",
       "  ['Group[463]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"montre\" | \"affiche\" | \"exhibe\" | \"démontre\" | \"expose\" | \"exhibe\" | \"dénote\" | \"confirme\" | \"explique\" | \"dévoile\"\\n',\n",
       "   'Termin -> \"_\"|\"_ent\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[463]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [108,\n",
       "  ['Group[463]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 ->  \"fait état\" | \"font état\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[463]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [109,\n",
       "  ['Group[464]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\" | \"n\\'ait\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"exprimé\" | \"manifesté\" | \"dit\" | \"signifié\" | \"témoigné\" | \"montré\" | \"expliqué\" | \"traduit\" | \"extériorisé\" | \"révélé\" | \"formulé\" | \"exposé\" | \"affiché\" | \"signalé\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[464]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [110,\n",
       "  ['Group[466]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'a\" | \"n\\'ait\"\\n',\n",
       "   'Var2 -> \"exprimé\" | \"manifesté\" | \"dit\" | \"signifié\" | \"témoigné\" | \"montré\" | \"expliqué\" | \"traduit\" | \"extériorisé\" | \"révélé\" | \"formulé\" | \"exposé\" | \"affiché\" | \"signalé\" | \"indiqué\" | \"notifié\" | \"découvert\" | \"dévoilé\" | \"souligné\" | \"informé\" | \"déclaré\" | \"averti\" | \"rapporté\" | \"alerté\"\\n',\n",
       "   'Var3 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[466]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [111,\n",
       "  ['Group[475]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"différentiel\"\\n',\n",
       "   'Var2 -> \"comprend\" | \"consiste\" | \"posséde\" | \"contient\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[475]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [112,\n",
       "  ['Group[476]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"diagnostics\"\\n',\n",
       "   'Var2 -> \"différentiels\"\\n',\n",
       "   'Var3 -> \"comprenent\" | \"consistenr\" | \"possédent\" | \"contienent\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[476]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [113,\n",
       "  ['Group[479]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Var5 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"semble\" | \"semblent\" | \" \"\\n',\n",
       "   'Var3 -> \"pas\"\\n',\n",
       "   'Var4 -> \"avoir\"\\n',\n",
       "   'Var5 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[479]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [114,\n",
       "  ['Group[487]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Termin Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'exprime\" | \"ne dit\" | \"n\\'expose\" | \"n\\'énonce\" | \"n\\'affiche\" | \"n\\'émet\" | \"ne signale\" | \"ne signifie\" | \"ne déclare\" | \"ne témoigne\" | \"ne montre\" | \"ne manifeste\" | \"ne découvre\" | \"ne figure\" | \"ne traduise\"\\n',\n",
       "   'Termin -> \"_\"|\"_ent\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[487]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [115,\n",
       "  ['Group[489]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Termin Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'utilise\" | \"n\\'employe\" | \"ne serve\" | \"ne recoure\" | \"ne serve\" | \"n\\'use\" | \"ne prene\" | \"n\\'applique\" | \"ne manipule\" | \"n\\'exploite\" | \"ne manie\"\\n',\n",
       "   'Termin -> \"_\"|\"_ent\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[489]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [116,\n",
       "  ['Group[491]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"généralement\" | \"en général\" | \"habituellement\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[491]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [117,\n",
       "  ['Group[493]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"fait\" | \"faisait\"\\n',\n",
       "   'Var3 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[493]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [118,\n",
       "  ['Group[495]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"ressemble\" | \"s\\'approche\" | \"corresponde\" | \"ne rappelle\" | \"se recoupe\"  | \"se rapproche\"\\n',\n",
       "   'Termin -> \"_\"|\"_ent\"\\n',\n",
       "   'Var3 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[495]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [119,\n",
       "  ['Group[495]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'imite pas\" | \"n\\'a aucun rapport avec\" | \"n\\'est la réplique de\" | \"n\\'ont aucun rapport avec\" | \"ne sont la réplique de\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[495]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [120,\n",
       "  ['Group[497]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"doute\" | \"perplexité\" | \"hésitation\" | \"indétermination\" | \"indécision\" | \"crainte\" | \"appréhension\" | \"supposition\" | \"inquiétude\" | \"croyance\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[497]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [121,\n",
       "  ['Group[498]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en raison\" | \"a cause\" | \"pourquoi\" | \"comme explication\" | \"comme fondement\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[498]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [122,\n",
       "  ['Group[499]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ecchymoses\" | \"hématome\" | \"coup\" | \"blessure\" | \"meurtrissure\" | \"cicatrice\" | \"égratignure\" | \"escarre\" | \"contusion\" | \"entaille\" | \"éraflure\"\\n',\n",
       "   'Termin -> \"_\"|\"_s\"\\n',\n",
       "   'Var2 -> \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[499]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [123,\n",
       "  ['Group[501]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"département d\\'urgences\" | \"aux urgences\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[501]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [124,\n",
       "  ['Group[502]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"étiologie\" | \"étiologie\" | \"causalité\"\\n',\n",
       "   'Var2 -> \"de\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[502]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [125,\n",
       "  ['Group[504]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"exacerbation\" | \"redoublement\" | \"intensification\" | \"recrudescence\" | \"excitation\" | \"augmentation\" | \"irritation\" | \"aggravation\" | \"agravation\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[504]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [126,\n",
       "  ['Group[505]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"examens\" | \"consultation\" | \"observation\" | \"auscultation\" | \"examen médical\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Var3 -> \"évaluer\" | \"juger\" | \"apprécier\" | \"chiffrer\" | \"calculer\" | \"quantifier\" | \"mesurer\" | \"déterminer\" | \"expertiser\" | \"jauger\" | \"compter\" | \"examiner\" | \"recenser\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[505]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [127,\n",
       "  ['Group[510]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sauf\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[510]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [128,\n",
       "  ['Group[512]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne parvient\" | \"n\\'aboutir\" | \"ne réussi\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"à\"\\n',\n",
       "   'Var4 -> \"révéler\" | \"divulguer\" | \"déceler\" | \"trahir\" | \"dire\" | \"exposer\" | \"faire connaître\" | \"exprimer\" | \"signaler\" | \"signifier\" | \"annoncer\" | \"développer\" | \"démasquer\" | \"afficher\" | \"déclarer\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[512]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [129,\n",
       "  ['Group[514]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"faux\"\\n',\n",
       "   'Var2 -> \"négatif\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[514]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [130,\n",
       "  ['Group[530]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"fh\" |\"f / h\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|nonpatient|30|Group[530]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [131,\n",
       "  ['Group[531]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"indication\" | \"prescription\" | \"directive\" | \"renvoi\" | \"information\" | \"note\" | \"recommandation\" | \"suggestion\" | \"mention\"\\n',\n",
       "   'Var2 -> \"du\"\\n',\n",
       "   'Var3 -> \"rapport\"\\n',\n",
       "   'Var4 -> \"final\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[531]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [132,\n",
       "  ['Group[532]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pour\"\\n',\n",
       "   'Var2 -> \"présumer\" | \"soupçonner\" | \"estimer\" | \"conjecturer\" | \"pressentir\" | \"présager\" | \"espérer\" |\"préjuger\" | \"présupposer\" | \"prétendre\" | \"prédire\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[532]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [133,\n",
       "  ['Group[533]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"mur\" | \"mûri\" | \"obstacle\" | \"bon pour\" | \"mûr\" | \"accompli\" | \"mature\" | \"apte\" | \"usagé\" | \"falaise\" | \"frontière\" | \"avancé\" | \"formé\" | \"cloisonnement\" | \"barrières\"\\n',\n",
       "   'Var2 -> \"libre\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[533]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [134,\n",
       "  ['Group[541]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[541]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [135,\n",
       "  ['Group[542]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Patient Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\\n',\n",
       "   'Patient -> \"du patient\" | \"de la patiente\"| \"du souffrant\" | \"de la souffrante\"| \"du sujet\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[542]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [136,\n",
       "  ['Group[543]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"compte\"\\n',\n",
       "   'Var2 -> \"tenu\"\\n',\n",
       "   'Var3 -> \"de l\\'histoire\" | \"du passé\" | \"de l\\'historique\" | \"du fait\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[543]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [137,\n",
       "  ['Group[543]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Var5 Trigger_Rule\\n',\n",
       "   'Var1 -> \"compte\"\\n',\n",
       "   'Var2 -> \"tenu\"\\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Var4 -> \"son\"\\n',\n",
       "   'Var5 -> \"histoire\" | \"passé\" | \"historique\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[543]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [138,\n",
       "  ['Group[543]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"compte\"\\n',\n",
       "   'Var2 -> \"tenu\"\\n',\n",
       "   'Var3 -> \"de la gravité\" | \"du sérieux\" | \"de la sévérité\" | \"de l\\'urgence\" | \"du caractère\" | \"de la sériosité\"\\n',\n",
       "   'Var4 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[543]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [139,\n",
       "  ['Group[543]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"étant\"\\n',\n",
       "   'Var2 -> \"donné\"\\n',\n",
       "   'Var3 -> \"que\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[543]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [140,\n",
       "  ['Group[550]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"gram\"\\n',\n",
       "   'Var2 -> \"négatif\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[550]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [141,\n",
       "  ['Group[557]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"avoir\" |\"avait\" | \"a\" | \"ait\" | \"aient\"\\n',\n",
       "   'Var2 -> \"un\"\\n',\n",
       "   'Var3 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var4 -> \"négatif\" |\"négative\" | \"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[557]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [142,\n",
       "  ['Group[557]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"avoir\" |\"avait\" | \"a\" | \"ait\" | \"aient\"\\n',\n",
       "   'Var2 -> \"une\"\\n',\n",
       "   'Var3 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var4 -> \"négatif\" |\"négative\" | \"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[557]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [143,\n",
       "  ['Group[561]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a été\"|\"ait été\"|\"était\"\\n',\n",
       "   'Var2 -> \"négatif\" |\"négative\" |\"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[561]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [144,\n",
       "  ['Group[561]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ont été\"|\"aient été\"|\"ont étaient\"\\n',\n",
       "   'Var2 -> \"négatifs\" |\"négatives\" |\"nuls\" | \"nulles\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[561]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [145,\n",
       "  ['Group[561, 563]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"été\"|\"était\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" |\"écartés\" |\"évincé\" | \"supprimé\" | \"éloigné\" | \"enlevé\" | \"arrêté\" | \"stoppé\" | \"enrayé\" | \"contenu\" | \"suspendu\" | \"jugulé\" | \"terminé\" | \"fini\" | \"endigué\" | \"interrompu\" | \"gelé\" | \"absent\" | \"en défaut\" | \"dénué\" | \"dépourvu\" | \"disparu\"\\n',\n",
       "   'Termin -> \"_\" |\"_e\" \\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[561, 563]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [146,\n",
       "  ['Group[561, 563]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"étaient\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" |\"écarté\" |\"évincé\" | \"supprimé\" | \"éloigné\" | \"enlevé\" | \"récusé\" | \"absent\" | \"en défaut\" | \"dénué\" | \"dépourvu\" | \"disparu\"\\n',\n",
       "   'Termin -> \"_s\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[561, 563]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [147,\n",
       "  ['Group[561, 563]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"été\"|\"était\"\\n',\n",
       "   'Var2 -> \"mis à l\\'écart\" | \"mises de coté\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[561, 563]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [148,\n",
       "  ['Group[561, 563]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"étaient\"\\n',\n",
       "   'Var2 -> \"mises à l\\'écart\" | \"mises de coté\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[561, 563]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [149,\n",
       "  ['Group[569]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> | \"n\\'a\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> | \"eu\"\\n',\n",
       "   'Var4 -> \"d\\'\" | \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[569]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [150,\n",
       "  ['Group[575]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"continué\" | \"perpétué\" | \"tenu\"\\n',\n",
       "   'Var3 -> \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[575]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [151,\n",
       "  ['Group[576]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->   Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"son vieux\"| \"son ancien\" | \"son vieil\" | \"sa vielle\"| \"son ancienne\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[576]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [152,\n",
       "  ['Group[578]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"examen historique\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [153,\n",
       "  ['Group[578]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\\n',\n",
       "   'Var2 -> \"et\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [154,\n",
       "  ['Group[578]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [155,\n",
       "  ['Group[578]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire\" | \"passé\" | \"historique\"\\n',\n",
       "   'Var2 -> \"et\"\\n',\n",
       "   'Var3 -> \"examen\" | \"analyse\" | \"consultation\" | \"observation\" | \"auscultation\" | \"examen médical\" | \"autopsie\" | \"dépistage\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [156,\n",
       "  ['Group[578]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire\" | \"passé\" | \"historique\"\\n',\n",
       "   'Var2 -> \"de la maladie\" | \"du malaise\" | \"du mal\" | \"du trouble\" | \"de l\\'indisposition\" | \"de la souffrance\" | \"du syndrome\" | \"de l\\'infirmité\" | \"de l\\'incommodité\" | \"de l\\'atteinte\" | \"de la tare\" | \"de la pathologie\" | \"du traumatisme\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [157,\n",
       "  ['Group[586]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"hist.\" | \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\\n',\n",
       "   'Var2 -> \"de\" | \"d\\'un\" | \"d\\'une\" | \"dans\" | \"pour\" | \"par\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|historical|30|Group[586]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [158,\n",
       "  ['Group[587]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"toutefois\" | \"cependant\" | \"néanmoins\" | \"pourtant\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[587]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [159,\n",
       "  ['Group[590]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"si\"\\n',\n",
       "   'Var2 -> \"négatif\" |\"négative\" |\"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|conditional|30|Group[590]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [160,\n",
       "  ['Group[591]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"si\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[591]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [161,\n",
       "  ['Group[592]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en\"\\n',\n",
       "   'Var2 -> \"elle\" | \"lui\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[592]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [162,\n",
       "  ['Group[593]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"dans\"\\n',\n",
       "   'Var2 -> \"son\" | \"sa\" | \"ses\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[593]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [163,\n",
       "  ['Group[594]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"autrefois\"|\"anciennement\" | \"jadis\"\\n',\n",
       "   'Trigger_Rule -> \"|both|trigger|historical|30|Group[594]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [164,\n",
       "  ['Group[595]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"dans\"\\n',\n",
       "   'Var2 -> \"le contexte\" | \"la situation\" | \"les circonstances\" | \"le cadre\" |  \"la condition\" |  \"les conditions\"\\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[595]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [165,\n",
       "  ['Group[596]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"incompatible\"\\n',\n",
       "   'Var2 -> \"avec\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[596]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [166,\n",
       "  ['Group[598]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"indication\" | \"avertissement\" | \"suggestion\" | \"mention\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[598]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [167,\n",
       "  ['Group[599]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"est\"|\"était\"\\n',\n",
       "   'Var2 -> \"neg\"|\"nég\"|\"nég.\"| \"négatif\" |\"négative\" |\"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[599]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [168,\n",
       "  ['Group[599]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sont\"|\"étaient\"\\n',\n",
       "   'Var2 -> \"neg\"|\"nég\"|\"nég.\"| \"négatifs\" |\"négatives\" |\"nuls\" | \"nulles\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[599]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [169,\n",
       "  ['Group[603]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'est\" | \"ne sont\" | \"n\\'était\" | \"n\\'étaient\"\\n',\n",
       "   'Var2 -> \"plus\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[603]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [170,\n",
       "  ['Group[605]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'est\" | \"ne sont\" | \"n\\'était\" | \"n\\'étaient\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[605]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [171,\n",
       "  ['Group[607]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"est\"  |\"était\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" |\"écarté\" |\"évincé\" | \"supprimé\" | \"éloigné\" | \"enlevé\" | \"arrêté\" | \"stoppé\" | \"enrayé\" | \"contenu\" | \"suspendu\" | \"jugulé\" | \"terminé\" | \"fini\" | \"endigué\" | \"interrompu\" | \"gelé\" | \"absent\" | \"en défaut\" | \"dénué\" | \"dépourvu\" | \"disparu\"\\n',\n",
       "   'Termin -> \"_\"|\"_e\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[607]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [172,\n",
       "  ['Group[607]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"sont\"|\"étaient\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" |\"écarté\" |\"évincé\" | \"supprimé\" | \"éloigné\" | \"enlevé\" | \"arrêté\" | \"stoppé\" | \"enrayé\" | \"contenu\" | \"suspendu\" | \"jugulé\" | \"terminé\" | \"fini\" | \"endigué\" | \"interrompu\" | \"gelé\" | \"absent\" | \"en défaut\" | \"dénué\" | \"dépourvu\" | \"disparu\"\\n',\n",
       "   'Termin -> \"_s\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[607]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [173,\n",
       "  ['Group[609]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\" |\"ont\" | \"ait\" | \"aient\" | \"avait\" | \"avaient\"\\n',\n",
       "   'Var2 -> \"arrêté\" | \"stoppé\" | \"terminé\" | \"fini\" | \"cessé\" | \"pris fin\" | \"gelé\" | \"disparu\" | \"fait défaut\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[609]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [174,\n",
       "  ['Group[611]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"est\"\\n',\n",
       "   'Var2 -> \"à\"\\n',\n",
       "   'Var3 -> \"exclure\" | \"éliminer\" | \"rejeter\" | \"proscrire\" | \"éloigner\" | \"supprimer\" | \"radier\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[611]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [175,\n",
       "  ['Group[615]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"manque\" | \"insuffisance\" | \"défaut\" | \"déficience\" | \"pénurie\" | \"carence\" | \"privation\" | \"lacune\" | \"omission\" | \"manquement\" | \"défaillance\" | \"rareté\" | \"oubli\" | \"faute\" | \"faiblesse\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[615]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [176,\n",
       "  ['Group[617]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"manquait\" | \"oubliait\" | \"ratait\" | \"omettait\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[617]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [177,\n",
       "  ['Group[619]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"il y a\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\> 0\"\\n',\n",
       "   'Var3 -> \"année\" | \"années\" | \"an\" | \"ans\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[619]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [178,\n",
       "  ['Group[619]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"il y a\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\> 1 semaines\" | \"\\\\\\\\> 13 jours\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[619]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [179,\n",
       "  ['Group[626]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Seasons Var1 Trigger_Rule\\n',\n",
       "   'Seasons -> \"au printemps\"|\"le printemps\"|\"l\\'été\"|\"l\\'automne\"|\"l\\'hiver\"\\n',\n",
       "   'Var1 -> \"dernier\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[626]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [180,\n",
       "  ['Group[626]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"janvier\"|\"février\"|\"mars\"|\"avril\"|\"mai\"|\"juin\" |\"juillet\"|\"août\"|\"septembre\"|\"octobre\"|\"novembre\"|\"décembre\"\\n',\n",
       "   'Var2 -> \"dernier\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[626]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [181,\n",
       "  ['Group[626]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en\"\\n',\n",
       "   'Var2 -> \"janvier\"|\"février\"|\"mars\"|\"avril\"|\"mai\"|\"juin\" |\"juillet\"|\"août\"|\"septembre\"|\"octobre\"|\"novembre\"|\"décembre\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[626]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [182,\n",
       "  ['Group[642]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"contributeurs\"\\n',\n",
       "   'Var2 -> \"probables\"\\n',\n",
       "   'Var3 -> \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [183,\n",
       "  ['Group[642]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"contributeur\"\\n',\n",
       "   'Var2 -> \"probable\"\\n',\n",
       "   'Var3 -> \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [184,\n",
       "  ['Group[642]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"probablement\"\\n',\n",
       "   'Var2 -> \"en\"\\n',\n",
       "   'Var3 -> \"cas\" | \"situation\"\\n',\n",
       "   'Var4 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [185,\n",
       "  ['Group[642]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"probablement\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [186,\n",
       "  ['Group[642]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"élément\" | \"ingrédient\" | \"constituant\" | \"facteur\"\\n',\n",
       "   'Var2 -> \"probable\"\\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [187,\n",
       "  ['Group[646]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->   Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"probablement\"| \"éventuellement\" | \"plausiblement\" | \"possiblement\" | \"sans doute\" | \"sûrement\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[646]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [188,\n",
       "  ['Group[647]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"probable\"| \"éventuel\" | \"plausible\" | \"possible\"\\n',\n",
       "   'Termin -> |\"_s\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[647]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [189,\n",
       "  ['Group[648]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"chercher\" | \"scruter\" | \"sonder\" | \"essayer\" | \"explorer\" | \"rechercher\" | \"examiner\" | \"fouiller\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[648]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [190,\n",
       "  ['Group[651]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var4 -> \"sous-estimé\" | \"minimisé\" | \"minoré\" | \"mésestimé\" | \"sous-évalué\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[651]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [191,\n",
       "  ['Group[652]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"contribuer\" | \"collaborer\" | \"concourir\" | \"participer\" | \"favoriser\" | \"prendre part\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[652]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [192,\n",
       "  ['Group[653]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut-être\"\\n',\n",
       "   'Var2 -> \"dû\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[653]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [193,\n",
       "  ['Group[654]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pourrait\"\\n',\n",
       "   'Var2 -> \"démasquer\" | \"révéler\" | \"dévoiler\" | \"déceler\" | \"détecter\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [194,\n",
       "  ['Group[654]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"lié\" | \"connexe\" | \"relié\" | \"imbriqué\" | \"conjoint\" | \"attaché\" | \"inhérent\" | \"rattaché\" | \"coordonné\" | \"adjoint\" | \"assujetti\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [195,\n",
       "  ['Group[654]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"sous-estimé\" | \"minimisé\" | \"minoré\" | \"mésestimé\" | \"déconsidéré\" | \"méprisé\" | \"décrié\" | \"dévalué\" | \"décrédité\" | \"discrédité\" | \"déprécié\" | \"méjugé\" | \"dévalorisé\" | \"sous-évalué\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [196,\n",
       "  ['Group[659]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut-être\" |\"peut être\" | \"peut-etre\" |\"peut etre\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [197,\n",
       "  ['Group[659]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\"\\n',\n",
       "   'Var2 -> \"représenter\" | \"symboliser\" | \"décrire\" | \"montrer\" | \"dépeindre\" | \"figurer\" | \"exposer\" | \"signifier\" | \"exhiber\" | \"évoquer\" | \"désigner\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [198,\n",
       "  ['Group[659]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut\" | \"pourrait\"\\n',\n",
       "   'Var2 -> \"avoir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [199,\n",
       "  ['Group[666]'],\n",
       "  ['## from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"léger\" | \"légers\" |\"légerement\" | \"doux\"| \"douce\"| \"douces\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[666]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [200,\n",
       "  ['Group[672]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"surveiller\" |  \"examiner\" | \"suivre\" | \"avoir à l\\'oeil\"\\n',\n",
       "   'Var2 -> \"le\"\\n',\n",
       "   'Var3 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var4 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[672]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [201,\n",
       "  ['Group[672]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"être à l\\'affût du\" | \"faire attention au\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[672]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [202,\n",
       "  ['Group[678]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"doit\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Var4 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|both|trigger|uncertain|30|Group[678]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [203,\n",
       "  ['Group[682]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"neg\"|\"nég\"| \"nég.\"| \"négatifs\" |\"négatives\" |\"nuls\" | \"nulles\"\\n',\n",
       "   'Var2 -> \"dans\" | \"pour\" | \"par\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[682]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [204,\n",
       "  ['Group[688]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"neg\"|\"nég\"| \"nég.\"| \"négatifs\" |\"négatives\" |\"nuls\" | \"nulles\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[688]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [205,\n",
       "  ['Group[702]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"jamais\"\\n',\n",
       "   'Var2 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[702]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [206,\n",
       "  ['Group[704]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"jamais\"\\n',\n",
       "   'Var2 -> \"développé\" | \"manifesté\" | \"révélé\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[704]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [207,\n",
       "  ['Group[706]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"jamais\"\\n',\n",
       "   'Var2 -> \"eu\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[706]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [208,\n",
       "  ['Group[709]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"non\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"évident\" | \"clair\" | \"indiscutable\" | \"notoire\" | \"patent\" | \"certain\" | \"indéniable\" | \"flagrant\" | \"incontestable\" | \"sûr\" | \"assuré\"\\n',\n",
       "   'Var4 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"| \"dans\" | \"pour\" | \"par\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[709]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [209,\n",
       "  ['Group[715]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" | \"sans\" \\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"témoignage\" | \"gage\" | \"argument\" | \"critère\" | \"signe\" | \"motif\" | \"fondement\" | \"stigmate\" \\n',\n",
       "   'Var4 -> \"d\\'\" |\"de\" | \"d\\'un\" | \"d\\'une\" | \"dans\" | \"pour\" | \"par\" | \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[715]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [210,\n",
       "  ['Group[715]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\"  | \"sans\" \\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"preuve\" | \"justification\" | \"démonstration\" | \"conviction\" | \"constatation\" | \"confirmation\" | \"assurance\" | \"évidence\" | \"marque\" | \"annonce\" | \"indication\" | \"manifestation\" | \"trace\" | \"observation\"\\n',\n",
       "   'Var4 -> \"d\\'\" |\"de\" | \"d\\'un\" | \"d\\'une\" | \"dans\" | \"pour\" | \"par\" | \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[715]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [211,\n",
       "  ['Group[715]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\"  | \"sans\" \\n',\n",
       "   'Var2 -> \"témoignage\" | \"gage\" | \"argument\" | \"critère\" | \"signe\" | \"motif\" | \"fondement\"| \"signal\" | \"indice\" | \"témoignage\"| \"avertissement\" | \"stigmate\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[715]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [212,\n",
       "  ['Group[715]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"preuve\" | \"justification\" | \"démonstration\" | \"conviction\" | \"constatation\" | \"confirmation\" | \"assurance\" | \"évidence\"| \"marque\" | \"preuve\" | \"indication\" | \"manifestation\" | \"trace\" | \"observation\"| \"suggestion\" | \"incitation\" | \"évocation\" | \"indication\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[715]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [213,\n",
       "  ['Group[723]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"non\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"évident\" | \"clair\" | \"net\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[723]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [214,\n",
       "  ['Group[725]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Var5 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"aucune\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"a\"\\n',\n",
       "   'Var4 -> \"été\"\\n',\n",
       "   'Var5 -> \"donné\" | \"prescrit\" | \"administré\" | \"prodigué\" | \"appliqué\" | \"fait\" | \"indiqué\" | \"proposé\" | \"distribué\" | \"redonné\" | \"assené\" | \"employé\" | \"inoculé\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[725]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [215,\n",
       "  ['Group[730]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\"  | \"sans\" \\n',\n",
       "   'Var2 -> \"autre\" | \"autres\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[730]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [216,\n",
       "  ['Group[734]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\"  | \"sans\" \\n',\n",
       "   'Var2 -> \"fondement\" | \"déclencheur\" | \"départ\" | \"but\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[734]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [217,\n",
       "  ['Group[734]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\"  | \"sans\" \\n',\n",
       "   'Var2 -> \"cause\" | \"raison\" | \"fondement\" | \"source\" | \"intention\" | \"origine\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[734]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [218,\n",
       "  ['Group[736]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"de changement\" | \"de variation\" | \"d\\'altération\" | \"d\\'évolution\" | \"de transformation\" | \"de fluctuation\" | \"de mutation\" | \"de retournement\" | \"de renversement\" | \"d\\'amélioration\" | \"de revirement\" | \"de transition\" | \"de modulation\" | \"d\\'inflexion\" | \"de différence\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[736]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [219,\n",
       "  ['Group[736]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" | \"sans\" \\n',\n",
       "   'Var2 -> \"changement\" | \"retournement\" | \"renversement\" | \"revirement\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[736]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [220,\n",
       "  ['Group[736]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 ->  \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"variation\" | \"altération\" | \"évolution\" | \"transformation\" | \"fluctuation\" | \"amélioration\" | \"transition\" | \"inflexion\" | \"différence\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[736]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [221,\n",
       "  ['Group[737]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"plainte\" | \"lamentation\" | \"protestation\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[737]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [222,\n",
       "  ['Group[746]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" | \"sans\" \\n',\n",
       "   'Var2 -> \"témoignage\" | \"gage\" | \"argument\" | \"signe\" | \"motif\" | \"fondement\" | \"décèlement\" | \"stigmate\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[746]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [223,\n",
       "  ['Group[746]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"preuve\" |  \"justification\" | \"démonstration\" | \"conviction\" |  \"constatation\" | \"confirmation\" | \"assurance\" |  \"évidence\" | \"découverte\" | \"trouvaille\" | \"révélation\" | \"constatation\"| \"marque\" | \"annonce\" | \"indication\" | \"manifestation\" | \"trace\" | \"observation\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[746]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [224,\n",
       "  ['Group[754]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" \\n',\n",
       "   'Var2 -> \"résultat\" | \"évènement\" | \"calcul\" | \"constat\"\\n',\n",
       "   'Var3 -> \"n\\'a\"\\n',\n",
       "   'Var4 -> \"indiqué\" | \"prouvé\" | \"montré\" | \"démontré\" | \"signalé\" | \"annoncé\" | \"manifesté\" | \"révélé\" | \"témoigné\" | \"attesté\" | \"désigné\" | \"affiché\" | \"déterminé\" | \"décelé\" | \"donné\" | \"suggéré\" | \"proposé\" | \"évoqué\" | \"fait pensé à\" | \"sous-entendu\" | \"supposé\" | \"laissé envisager\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[754]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [225,\n",
       "  ['Group[760]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"d\\'histoire\" | \"de passé\" | \"d\\'historique\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[760]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [226,\n",
       "  ['Group[764]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Word Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"d\\'augmentation\" | \"d\\'extension\" | \"d\\'amplification\" | \"d\\'allongement\" | \"d\\'élévation\" | \"de hausse\" | \"d\\'aggravation\" | \"d\\'agrandissement\" | \"d\\'intensification\" | \"de redoublement\" | \"de dilatation\" | \"de croissance\" \\n',\n",
       "   'Word -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[764]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [227,\n",
       "  ['Group[764]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Word Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\"  | \"sans\" \\n',\n",
       "   'Var2 -> \"allongement\" | \"agrandissement\" | \"redoublement\" | \"changement\" | \"retournement\" | \"renversement\" | \"revirement\"\\n',\n",
       "   'Word -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[764]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [228,\n",
       "  ['Group[764]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Word Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"augmentation\" | \"extension\" | \"amplification\" | \"élévation\" | \"hausse\" | \"aggravation\" | \"intensification\" | \"dilatation\" | \"croissance\" | \"variation\" | \"altération\" | \"évolution\" | \"transformation\" | \"fluctuation\" | \"mutation\" | \"amélioration\" | \"transition\" | \"modulation\" | \"inflexion\" | \"différence\"\\n',\n",
       "   'Word -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[764]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [229,\n",
       "  ['Group[765]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" | \"sans\" \\n',\n",
       "   'Var2 -> \"avertissement\" | \"renvoi\" | \"critère\" | \"symptôme\"\\n',\n",
       "   'Var3 ->  \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[765]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [230,\n",
       "  ['Group[770]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" | \"sans\" \\n',\n",
       "   'Var2 -> \"passé\" | \"souvenir\"\\n',\n",
       "   'Var3 ->  | \"\\\\\\\\w+\"\\n',\n",
       "   'Var4 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[770]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [231,\n",
       "  ['Group[770]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"histoire\" | \"historique\"\\n',\n",
       "   'Var3 ->  | \"\\\\\\\\w+\"\\n',\n",
       "   'Var4 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[770]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [232,\n",
       "  ['Group[774]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'est\" | \"n\\'était\"\\n',\n",
       "   'Var2 -> \"plus\" | \"pas\"\\n',\n",
       "   'Var3 -> \"présent\" | \"actif\" | \"actuel\" | \"là\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[774]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [233,\n",
       "  ['Group[774]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne sont\" | \"n\\'étaient\"\\n',\n",
       "   'Var2 -> \"plus\" | \"pas\"\\n',\n",
       "   'Var3 -> \"présents\" | \"actifs\" | \"actuels\" | \"là\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[774]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [234,\n",
       "  ['Group[776]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"plus\" | \"pas\"\\n',\n",
       "   'Var2 -> \"maintenant\" | \"actuellement\" | \"aujourd\\'hui\" | \"à présent\" | \"dèsdésormais\" | \"présentement\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[776]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [235,\n",
       "  ['Group[782]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"mention\" | \"évocation\" | \"notation\" | \"signalement\" | \"note\" | \"expression\" | \"référence\" | \"reflet\" | \"allusion\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\" | \"signalé\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[782]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [236,\n",
       "  ['Group[784]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"preuve\" | \"justification\" | \"démonstration\" | \"conviction\" | \"constatation\" | \"confirmation\" | \"assurance\" |  \"évidence\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[784]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [237,\n",
       "  ['Group[784]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" | \"sans\" \\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"témoignage\" |\"gage\" | \"argument\" | \"critère\" | \"signe\" | \"motif\" | \"fondement\" | \"stigmate\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[784]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [238,\n",
       "  ['Group[786]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Var3 -> \"nouveau\" | \"récent\" | \"nouveauté\" | \"nouvelle\" | \"récente\" | \"jeune\" | \"nouvel\"| \"nouveaux\" | \"récents\" | \"nouveautés\" | \"nouvelles\" | \"récentes\" | \"jeunes\" | \"nouvels\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[786]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [239,\n",
       "  ['Group[790]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\" | \"\\\\\\\\w+ \\\\\\\\w+\" \\n',\n",
       "   'Var3 -> \"marque\" | \"indice\" | \"manifestation\" | \"présage\" | \"syndrome\" | \"diagnostique\" | \"stigmate\" | \"signal\" | \"signe\" |  \"diagnostic\" | \"symptôme\"\\n',\n",
       "   'Termin ->  |\"_s\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[790]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [240,\n",
       "  ['Group[794]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"de problème\" | \"d\\'ennui\" | \"de souci\" | \"de complication\" | \"de dysfonctionnement\" | \"de disfonctionnement\" | \"de soucis\" | \"de tracas\" | \"d\\'incident\"\\n',\n",
       "   'Var3 -> \"avec\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[794]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [241,\n",
       "  ['Group[794]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"nul\" | \"sans\" \\n',\n",
       "   'Var2 -> \"problème\" | \"ennui\" | \"souci\" | \"de complication\" | \"dysfonctionnement\" | \"disfonctionnement\" | \"soucis\" | \"tracas\" | \"incident\"\\n',\n",
       "   'Var3 -> \"avec\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[794]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [242,\n",
       "  ['Group[794]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucune\"| \"nulle\" | \"sans\" \\n',\n",
       "   'Var2 -> \"complication\"\\n',\n",
       "   'Var3 -> \"avec\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[794]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [243,\n",
       "  ['Group[798]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\" | \"non\"\\n',\n",
       "   'Var2 -> \"récurrent\" | \"séquentiel\" | \"répétitif\" | \"intermittent\" | \"pérenne\" | \"périodique\" | \"cyclique\" | \"répété\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[798]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [244,\n",
       "  ['Group[802]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"non\" | \"pas\"\\n',\n",
       "   'Var2 -> \"rapporté\" | \"révélé\" | \"exposé\" | \"signalé\" |  \"dévoilé\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[802]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [245,\n",
       "  ['Group[804]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Var3 -> \"résidu\" | \"reliquat\" | \"déchet\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[804]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [246,\n",
       "  ['Group[810]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"non\" | \"pas\"\\n',\n",
       "   'Var2 -> \"significatif\" | \"visible\" | \"diagnostiqué\" | \"identifié\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[810]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [247,\n",
       "  ['Group[829]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\" | \"sans\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[829]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [248,\n",
       "  ['Group[831]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ni\"\\n',\n",
       "   'Var2 -> \"tout\" | \"tous\" | \"toute\" | \"toutes\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[831]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [249,\n",
       "  ['Group[833]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ni\"\\n',\n",
       "   'Var2 -> \"aucun\" | \"aucun\" | \"nul\" | \"nulle\"  | \"sans\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[833]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [250,\n",
       "  ['Group[835]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ni\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[835]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [251,\n",
       "  ['Group[839]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"apparaître\" | \"survenir\" | \"ressortir\" | \"naître\" | \"transparaître\" | \"se manifester\" | \"se révéler\" | \"se dévoiler\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[839]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [252,\n",
       "  ['Group[843]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"non\" | \"pas\"\\n',\n",
       "   'Var2 -> \"associé\" | \"réuni\" | \"lié\" | \"groupé\" | \"composé\" | \"mélangé\" | \"mêlé\" | \"assorti\" | \"joint\" | \"relié\" | \"conjoint\"\\n',\n",
       "   'Var3 -> \"à\" | \"avec\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[843]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [253,\n",
       "  ['Group[845]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1  Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\" | \"non\"\\n',\n",
       "   'Var2 -> \"donné\" | \"prescrit\" | \"administré\" | \"prodigué\" | \"appliqué\" | \"fait\" | \"indiqué\" | \"proposé\" | \"employé\" | \"inoculé\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|pseudo|negated|10|Group[845]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [254,\n",
       "  ['Group[846]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[846]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [255,\n",
       "  ['Group[847]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"causer\" | \"susciter\" | \"amener\" | \"entraîner\" | \"procurer\" | \"provoquer\" | \"occasionner\" | \"donner\" | \"engendrer\" | \"créer\" | \"être cause de\" | \"déclencher\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[847]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [256,\n",
       "  ['Group[848]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"certain\"\\n',\n",
       "   'Var3 -> \"que\" | \"qu\\'\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[848]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [257,\n",
       "  ['Group[850]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"se\"\\n',\n",
       "   'Var3 -> \"plaindre\"\\n',\n",
       "   'Var4 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[850]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [258,\n",
       "  ['Group[854]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\" \\n',\n",
       "   'Var2 -> \"démontrer\" | \"témoigner\" | \"prouver\" | \"attester\" | \"montrer\" | \"convaincre\" | \"indiquer\" | \"illustrer\" | \"établir\" | \"justifier\" | \"révéler\" | \"dévoiler\" | \"déduire\" | \"conclure\" | \"garantir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[854]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [259,\n",
       "  ['Group[857]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"exposer\" | \"présenter\" | \"révéler\" | \"afficher\" | \"exprimer\" | \"signaler\" | \"signifier\" | \"annoncer\"| \"divulguer\" | \"déceler\" | \"dire\" | \"exposer\" | \"démasquer\" | \"afficher\" | \"déclarer\"\\n',\n",
       "   '\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[857]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [260,\n",
       "  ['Group[859]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"augmenter\" | \"grandir\" | \"se développer\" | \"s\\'accroître\" | \"s\\'allonger\" | \"s\\'élargir\" | \"se propager\" | \"s\\'amplifier\" | \"grossir\" | \"se généraliser\" | \"s\\'agrandir\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[859]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [261,\n",
       "  ['Group[860]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"pas\" | \"plus\"\\n',\n",
       "   'Var3 -> \"ressentir\" | \"sentir\" | \"endurer\" | \"souffrir\" | \"subir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[860]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [262,\n",
       "  ['Group[864]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Article  Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"avoir\"\\n',\n",
       "   'Article -> \"l\\'\" |\"le\" | \"la\" | \"un\" | \"une\" | \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[864]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [263,\n",
       "  ['Group[870]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"intéressé\" | \"attaché\" | \"concerné\" | \"intrigué\" | \"attiré\" | \"touché\" | \"curieux\" | \"affecté\" | \"motivé\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[870]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [264,\n",
       "  ['Group[871]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"dedans\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[871]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [265,\n",
       "  ['Group[875]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"connu\"\\n',\n",
       "   'Var3 -> \"pour\"\\n',\n",
       "   'Var4 -> \"avoir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[875]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [266,\n",
       "  ['Group[877]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"sur\" | \"sure\" | \"sûr\" | \"sûre\" |\"nécessairement\" | \"seulement\" | \"obligatoirement\" | \"forcément\" | \"automatiquement\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[877]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [267,\n",
       "  ['Group[882]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Termin -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[882]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [268,\n",
       "  ['Group[883]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"vu\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[883]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [269,\n",
       "  ['Group[885]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"arrêter\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[885]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [270,\n",
       "  ['Group[886]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Var3 -> \"être\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[886]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [271,\n",
       "  ['Group[888, 889]', 'Group[888, 889]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"noté\" | \"constaté\" \\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[888, 889]|Clement\"|\"|both|termination|nonpatient|30|Group[888, 889]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [272,\n",
       "  ['Group[891, 890]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ne\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[891, 890]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [273,\n",
       "  ['Group[892, 893]', 'Group[892, 893]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"maintenant\" | \"actuellement\" | \"aujourd\\'hui\" | \"à présent\" | \"dèsdésormais\" | \"présentement\"\\n',\n",
       "   'Var2 -> \"résolu\" | \"solutionné\" | \"traité\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[892, 893]|Clement\"|\"|forward|termination|negated|10|Group[892, 893]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [274,\n",
       "  ['Group[896]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"origine\" | \"début\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"prédéterminant\" | \"raison\" | \"départ\" | \"étiologie\" | \"causalité\" | \"source\" | \"point de départ\" | \"prétexte\" | \"déclencheur\" | \"mobile\" | \"explication\"\\n',\n",
       "   'Termin -> |\"_s\"\\n',\n",
       "   'Var2 -> \"pour\" | \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[896]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [275,\n",
       "  ['Group[900]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"autre\"\\n',\n",
       "   'Var2 -> \"possibilité\" | \"cas\" | \"hypothèse\"\\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[900]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [276,\n",
       "  ['Group[900]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"autres\"\\n',\n",
       "   'Var2 -> \"possibilités\" | \"cas\" | \"hypothèses\"\\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[900]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [277,\n",
       "  ['Group[901]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"devrait\" | \"pourrait\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Var3 -> \"exclu\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Termin -> \"_\"|\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[901]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [278,\n",
       "  ['Group[903]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire\" | \"historique\"\\n',\n",
       "   'Var2 -> \"passée\" | \"finie\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|historical|30|Group[903]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [279,\n",
       "  ['Group[903]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 ->  \"passé\" | \"souvenir\"\\n',\n",
       "   'Var2 -> \"passé\" | \"fini\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|historical|30|Group[903]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [280,\n",
       "  ['Group[904]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"antécédents\" | \"antérieurs\"\\n',\n",
       "   'Var2 -> \"médicaux\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|historical|30|Group[904]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [281,\n",
       "  ['Group[904]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"antécédent\" | \"antérieur\" | \"préexistant\" | \"passé\" | \"précédent\" | \"préliminaire\"\\n',\n",
       "   'Var2 -> \"médical\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|historical|30|Group[904]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [282,\n",
       "  ['Group[904]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"hérédité\" |\"antériorité\" | \"condition\" |\"ancienneté\" | \"antécédence\"\\n',\n",
       "   'Var2 -> \"médicale\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|historical|30|Group[904]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [283,\n",
       "  ['Group[905]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Patient Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Patient -> \"patient\" | \"patiente\"| \"souffrant\" | \"souffrante\"| \"sujet\"\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"continué\"\\n',\n",
       "   'Var3 -> \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[905]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [284,\n",
       "  ['Group[906]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Patient Var1 Var2 Trigger_Rule\\n',\n",
       "   'Patient -> \"patient\" | \"patiente\"| \"souffrant\" | \"souffrante\"| \"sujet\"\\n',\n",
       "   'Var1 -> \"n\\'est\" |\"n\\'était\"\\n',\n",
       "   'Var2 -> \"pas\" | \"plus\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[906]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [285,\n",
       "  ['Group[908, 911]', 'Group[908, 911]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Patient Trigger_Rule\\n',\n",
       "   'Var1 -> \"les\"\\n',\n",
       "   'Patient -> \"patients\" | \"patientes\"| \"souffrants\" | \"souffrantes\"| \"sujets\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[908, 911]|Clement\"|\"|both|termination|nonpatient|30|Group[908, 911]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [286,\n",
       "  ['Group[908, 911]', 'Group[908, 911]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Patient Trigger_Rule\\n',\n",
       "   'Patient -> \"patient\" | \"patiente\"| \"souffrant\" | \"souffrante\"| \"sujet\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[908, 911]|Clement\"|\"|both|termination|nonpatient|30|Group[908, 911]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [287,\n",
       "  ['Group[912]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"mauvaise\"\\n',\n",
       "   'Var2 -> \"historique\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[912]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [288,\n",
       "  ['Group[913]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"possible\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[913]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [289,\n",
       "  ['Group[913]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"possibilité\" | \"hypothèse\" | \"probabilité\" | \"chance\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[913]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [290,\n",
       "  ['Group[913]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peut-être\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[913]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [291,\n",
       "  ['Group[913, 914]', 'Group[913, 914]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"possible\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[913, 914]|Clement\"|\"|forward|trigger|conditional|30|Group[913, 914]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [292,\n",
       "  ['Group[918, 919]', 'Group[918, 919]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"présente\" | \"révéle\" | \"expose\" | \"étale\" |  \"affiche\" | \"exhibe\" | \"montre\"\\n',\n",
       "   'Termin -> |\"nt\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[918, 919]|Clement\"|\"|both|termination|nonpatient|30|Group[918, 919]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [293,\n",
       "  ['Group[918, 919]', 'Group[918, 919]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en\"\\n',\n",
       "   'Var2 -> \"présentant\" | \"révélant\" | \"exposant\" | \"étalant\" |  \"affichant\" | \"exhibant\" | \"montrant\" | \"mettant en évidence\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[918, 919]|Clement\"|\"|both|termination|nonpatient|30|Group[918, 919]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [294,\n",
       "  ['Group[922]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"probablement\" | \"apparemment\" | \"éventuellement\" | \"plausiblement\" | \"possiblement\" | \"sans doute\" | \"sûrement\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[922]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [295,\n",
       "  ['Group[923]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"présumé\" | \"soupçonné\" | \"conjecturé\" | \"pressenti\" | \"présagé\" | \"présupposé\"\\n',\n",
       "   'Termin -> |\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[923]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [296,\n",
       "  ['Group[924]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"antérieur à\" | \"préexistant à\" |\"précédent le\" | \"antécédent\" | \"préexistant\" | \"ancien\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[924]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [297,\n",
       "  ['Group[928]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"prophylaxie\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|10|Group[928]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [298,\n",
       "  ['Group[931]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"la\"\\n',\n",
       "   'Var2 -> \"question\"\\n',\n",
       "   'Var3 -> \"était\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[931]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [299,\n",
       "  ['Group[932]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"en question\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[932]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [300,\n",
       "  ['Group[932]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"se questionne sur\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[932]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [301,\n",
       "  ['Group[934]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"plutôt que\" |\"de préférence\" | \"préférablement\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[934]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [302,\n",
       "  ['Group[936]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"raison\" | \"cause\" | \"prétexte\" | \"justification\" | \"explication\" | \"fondement\" |  \"preuve\"\\n',\n",
       "   'Termin -> |\"_s\"\\n',\n",
       "   'Var2 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[936]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [303,\n",
       "  ['Group[940, 941]', 'Group[940, 941]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"rapporte\" | \"signale\" | \"indique\" | \"montre\" | \"dévoile\" | \"souligne\" | \"informe\"| \"révéle\" | \"signifie\" | \"avertisse\" | \"témoigne\" | \"alerte\"\\n',\n",
       "   'Termin -> |\"_nt\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[940, 941]|Clement\"|\"|both|termination|nonpatient|30|Group[940, 941]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [304,\n",
       "  ['Group[940, 941]', 'Group[940, 941]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"rapporté\" | \"signalé\" | \"indiqué\" | \"montré\" | \"dévoilé\" | \"souligné\" | \"informé\"| \"révélé\" | \"signifié\" | \"averti\" | \"témoigné\" | \"alerté\"\\n',\n",
       "   'Termin -> |\"_s\" |\"_e\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[940, 941]|Clement\"|\"|both|termination|nonpatient|30|Group[940, 941]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [305,\n",
       "  ['Group[947]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"risque\" | \"chance\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[947]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [306,\n",
       "  ['Group[955]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"l\\'éliminer\" | \"l\\'écarter\" | \"l\\'évincer\" | \"l\\'exclure\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[955]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [307,\n",
       "  ['Group[955]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"éliminer\" | \"écarter\" | \"évincer\" | \"exclure\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[955]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [308,\n",
       "  ['Group[977]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"exclut\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" | \"écarte\"\\n',\n",
       "   'Var2 -> \"pour\"| \"par\" | \"contre\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[977]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [309,\n",
       "  ['Group[979]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"exclut\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" | \"écarte\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[979]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [310,\n",
       "  ['Group[985]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Patient Trigger_Rule\\n',\n",
       "   'Var1 -> \"exclut\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\" | \"écarte\"\\n',\n",
       "   'Patient -> \"le patient\" | \"la patiente\"| \"le souffrant\" | \"la souffrante\"| \"le sujet\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[985]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [311,\n",
       "  ['Group[987]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->   Var1  Trigger_Rule\\n',\n",
       "   'Var1 -> \"l\\'exclut\" | \"le refuse\"| \"la refuse\" | \"le repousse\" | \"la repousse\" | \"le rejete\"| \"la rejete\" | \"l\\'élimine\" | \"le proscrit\" | \"la proscrit\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[987]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [312,\n",
       "  ['Group[997]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"exclut\" | \"interdit\" | \"proscrit\" | \"éloigne\" | \"rejete\" | \"évince\" | \"écarte\" | \"empêche\" | \"écarte\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[997]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [313,\n",
       "  ['Group[1004]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"secondaire\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1004]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [314,\n",
       "  ['Group[1006]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S -> Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"continué\" | \"perpétuer\" | \"tenu\"\\n',\n",
       "   'Var3 -> \"à\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1006]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [315,\n",
       "  ['Group[1009]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Pronoun Trigger_Rule\\n',\n",
       "   'Var1 -> \"devrait\" | \"pourrait\"\\n',\n",
       "   'Pronoun -> \"_-il\" | \"_-elle\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[1009]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [316,\n",
       "  ['Group[1013]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"montre\" | \"indique\" | \"expose\" | \"témoigne\" | \"signale\" | \"manifeste\" | \"révéle\"\\n',\n",
       "   'Var2 -> \"une\"\\n',\n",
       "   'Var3 -> \"question\" | \"interpellation\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1013]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [317,\n",
       "  ['Group[1015]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Depuis Seasons Trigger_Rule\\n',\n",
       "   'Depuis -> \"depuis\" | \"dès\" | \"à partir de\"\\n',\n",
       "   'Seasons -> \"le printemps\"|\"l\\'été\"|\"l\\'automne\"|\"l\\'hiver\" \\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [318,\n",
       "  ['Group[1015]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Depuis Month Trigger_Rule\\n',\n",
       "   'Depuis -> \"depuis\" | \"dès\" | \"à partir de\"\\n',\n",
       "   'Month -> \"janvier\"|\"février\"|\"mars\"|\"avril\"|\"mai\"|\"juin\" |\"juillet\"|\"août\"|\"septembre\"|\"octobre\"|\"novembre\"|\"décembre\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [319,\n",
       "  ['Group[1040]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"histoire\" | \"historique\"\\n',\n",
       "   'Var2 -> \"sociale\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[1040]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [320,\n",
       "  ['Group[1041, 1042]', 'Group[1041, 1042]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Member Trigger_Rule\\n',\n",
       "   'Var1 -> \"le rapport\" \\n',\n",
       "   'Member -> \"du parent\" | \"des parents\" | \"du père\" | \"du beau-père\" | \"de la mère\" |\"de la belle-mère\" | \"du papa\" | \"de la maman\" |\"du fils\" |\"des fils\" | \"du beau-fils\" | \"du garçon\" | \"des garçons\" | \"de la fille\" | \"de la belle-fille\" | \"des filles\" | \"du frère\"| \"des frères\" |\"de la soeur\" |\"des soeurs\" |\"de la sœur\" |\"des sœurs\" | \"de la fratrie\" | \"de l\\'oncle\"| \"du tonton\"| \"des oncles\" |\"de la tante\" | \"de la tata\"|\"des tantes\" |\" de la grand-mère\" | \"du grand-père\" |\"du cousin\" |\"des cousins\" |\"de la famille\" |\"du colocataire\" | \"des colocataires\" | \"du voisin\" | \"des voisins\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1041, 1042]|Clement\"|\"|both|termination|nonpatient|30|Group[1041, 1042]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [321,\n",
       "  ['Group[1053, 1054]', 'Group[1053, 1054]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"parler\" | \"bavarder\" | \"discuter\" | \"dialoguer\" | \"communiquer\" | \"s\\'entretenir\"\\n',\n",
       "   'Var2 -> \"avec\"\\n',\n",
       "   'Var3 -> \"la famille\" | \"le cercle familial\" | \"l\\'entourage\" | \"les parents\" | \"la belle-famille\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1053, 1054]|Clement\"|\"|both|termination|nonpatient|30|Group[1053, 1054]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [322,\n",
       "  ['Group[1053, 1054]', 'Group[1053, 1054]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"s\\'adresser\"\\n',\n",
       "   'Var2 -> \"à la famille\" | \"au cercle familial\" | \"à l\\'entourage\" | \"aux parents\" | \"à la belle-famille\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1053, 1054]|Clement\"|\"|both|termination|nonpatient|30|Group[1053, 1054]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [323,\n",
       "  ['Group[1060]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"encore\" |\"toujours\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1060]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [324,\n",
       "  ['Group[1061]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"arrêté\" | \"terminé\" | \"fini\" | \"cessé\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Var3 -> \"prendre\" | \"manger\" | \"boire\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|negated|10|Group[1061]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [325,\n",
       "  ['Group[1062]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Termin Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"étude\" | \"examen\" | \"expérimentation\" | \"enquête\" | \"analyse\"\\n',\n",
       "   'Termin -> |\"_s\" \\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Var3 -> \"évaluer\" | \"juger\" | \"apprécier\" | \"chiffrer\" | \"calculer\" | \"quantifier\" | \"mesurer\" | \"déterminer\" | \"expertiser\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1062]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [326,\n",
       "  ['Group[1063]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"étude\" | \"examen\" | \"expérimentation\" | \"enquête\" | \"analyse\" | \"exploration\" | \"observation\" | \"expertise\" | \"rapport\" | \"investigation\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Var3 -> \"évaluer\" | \"juger\" | \"apprécier\" | \"chiffrer\" | \"calculer\" | \"quantifier\" | \"mesurer\" | \"déterminer\" | \"expertiser\" | \"jauger\" | \"compter\" | \"peser\" | \"comparer\" | \"examiner\" | \"recenser\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1063]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [327,\n",
       "  ['Group[1064]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"apparition\" | \"arrivée\" | \"éclosion\" | \"manifestation\" | \"éruption\" | \"naissance\" | \"survenue\" | \"émergence\" | \"poussée\"\\n',\n",
       "   'Var2 -> \"soudaine\"\\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|historical|30|Group[1064]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [328,\n",
       "  ['Group[1089]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"évocateur\" | \"évocatoire\" | \"allusif\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1089]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [329,\n",
       "  ['Group[1090]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"suggérer\" | \"évoquer\" | \"susciter\" | \"faire penser à\" | \"sous-entendre\" | \"supposer\" | \"envisager\"| \"soupçonner\" | \"pressentir\" | \"deviner\" | \"douter\" | \"présumer\" | \"entrevoir\" | \"sentir\" | \"conjecturer\" | \"penser\" | \"imaginer\" | \"subodorer\" | \"croire\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1090]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [330,\n",
       "  ['Group[1091]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"suggéré\" | \"évoqué\" | \"suscité\" | \"fait penser à\" | \"sous-entendu\" | \"supposé\" | \"envisagé\" | \"soupçonné\" | \"pressenti\" | \"deviné\" | \"douté\" | \"présumé\" | \"entrevu\" | \"senti\" | \"conjecturé\" | \"pensé\" | \"imaginé\" | \"subodoré\" | \"cru\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1091]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [331,\n",
       "  ['Group[1091]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"suggére\" | \"évoque\" | \"suscite\" | \"fait penser à\" | \"sous-entends\" | \"suppose\" | \"envisage\" | \"soupçonne\" | \"pressentis\" | \"devine\" | \"doute\" | \"présume\" | \"entrevois\" | \"sens\" | \"conjecture\" | \"pense\" | \"imagine\" | \"subodore\" | \"crois\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1091]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [332,\n",
       "  ['Group[1092]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"soupçon\" | \"doute\" | \"suspicion\" | \"crainte\" | \"croyance\" | \"présomption\"  | \"supposition\"\\n',\n",
       "   'Var2 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1092]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [333,\n",
       "  ['Group[1093]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"méfiant\" | \"soupçonneux\" | \"timoré\" | \"prudent\" | \"suspicieux\" | \"dubitatif\" | \"douteux\" | \"avec méfiance\" | \"suspect\" | \"précautionneux\" | \"sceptique\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1093]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [334,\n",
       "  ['Group[1100]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Deter Trigger_Rule\\n',\n",
       "   'Var1 -> \"évaluer\" | \"apprécier\" | \"mesurer\" | \"déterminer\" | \"jauger\"\\n',\n",
       "   'Deter -> \"tout\" | \"tous\" | \"toute\" | \"toutes\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1100]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [335,\n",
       "  ['Group[1101]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"exclure\" | \"rejeter\" | \"proscrire\" | \"supprimer\" | \"radier\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1101]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [336,\n",
       "  ['Group[1103]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pour\"\\n',\n",
       "   'Var2 -> \"prévenir\" | \"anticiper\" | \"empêcher\" | \"éviter\" | \"se prémunir contre\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[1103]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [337,\n",
       "  ['Group[1104, 1105]', 'Group[1104, 1105]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"maintenant\" | \"actuellement\" | \"aujourd\\'hui\" | \"à présent\" | \"dèsdésormais\" | \"présentement\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1104, 1105]|Clement\"|\"|both|termination|nonpatient|30|Group[1104, 1105]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [338,\n",
       "  ['Group[1106]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"traitement\" | \"soins\" | \"cure\" | \"intervention\" | \"soin\"\\n',\n",
       "   'Var2 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[1106]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [339,\n",
       "  ['Group[1107]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"événement\" | \"épisode\" | \"incident\" | \"fait\"\\n',\n",
       "   'Var2 -> \"déclencheur\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\" | \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1107]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [340,\n",
       "  ['Group[1109]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"dose\" | \"mesure\" | \"quantité\" | \"proportion\" | \"dôse\"\\n',\n",
       "   'Var2 -> \"incertaine\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[1109]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [341,\n",
       "  ['Group[1110]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"pas\"\\n',\n",
       "   'Var2 -> \"clair\" | \"sûr\" | \"certain\" | \"garanti\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1110]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [342,\n",
       "  ['Group[1112]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"peu\"\\n',\n",
       "   'Var2 -> \"probable\" | \"plausible\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[1112]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [343,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"noter\" | \"constater\" | \"relever\" | \"remarquer\" | \"observer\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [344,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\" | \"sans\"\\n',\n",
       "   'Var2 -> \"indication\" | \"avertissement\" | \"prescription\" | \"directive\" | \"annotation\" | \"explication\" | \"renvoi\" | \"information\" | \"note\" | \"recommandation\" | \"critère\" | \"notation\" | \"suggestion\" | \"mention\" | \"symptôme\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [345,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\" | \"sans\"\\n',\n",
       "   'Var2 -> \"douleur\" | \"souffrance\" | \"mal\" | \"supplice\" | \"nuisance\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [346,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"monter\" | \"élever\" | \"rehausser\" | \"relever\" | \"hausser\" | \"remonter\" | \"réhausser\" | \"intensifier\" | \"accroître\" | \"accentuer\" | \"amplifier\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [347,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"nouveau\" | \"récent\" | \"nouvelle\" | \"récente\" | \"nouvel\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [348,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"avoir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [349,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"certains\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [350,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"beaucoup\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [351,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"éprouver\" | \"ressentir\" | \"sentir\" | \"souffrir\" | \"endurer\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [352,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"remarquer\" | \"considérer\" | \"noter\" | \"observer\" | \"constater\" | \"distinguer\" | \"découvrir\" | \"observer\" | \"percevoir\" | \"voir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [353,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"augmentation\" | \"extension\" | \"amplification\" | \"allongement\" | \"addition\" | \"élévation\" | \"hausse\" | \"aggravation\" | \"agrandissement\" | \"intensification\" | \"redoublement\" | \"dilatation\" | \"croissance\" | \"développement\" | \"montée\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [354,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 ->  \"net\" | \"clair\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [355,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"utiliser\" | \"exploiter\" | \"manipuler\" | \"user\"| \"recourir\" | \"manier\" | \"se servir\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [356,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"rapport\" | \"correspondance\" | \"relation\" | \"ressemblance\" | \"analogie\" | \"corrélation\" | \"concordance\" | \"rapprochement\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [357,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"évidence\" | \"certitude\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [358,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"mention\" | \"évocation\" | \"notation\" | \"signalement\" | \"note\" | \"expression\" | \"référence\" | \"allusion\"\\n',\n",
       "   'Var3 -> \"d\\'\" | \"de\" | \"d\\'un\" | \"d\\'une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [359,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Article Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Article -> \"l\\'\" | \"le\" | \"la\" | \"un\" | \"une\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [360,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"périphérique\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [361,\n",
       "  ['Group[1117]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"plus\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [362,\n",
       "  ['Group[1129]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"souhaiter\" | \"convoiter\" | \"réclamer\" | \"tenir à\" \\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[1129]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [363,\n",
       "  ['Group[1130, 1131]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Word Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\" | \"ont\" \\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Word -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var3 -> \"négatif\" | \"négatifs\" | \"négative\" | \"négatives\" \\n',\n",
       "   '\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[1130, 1131]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [364,\n",
       "  ['Group[1132, 1133]', 'Group[1132, 1133]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\" | \"ont\" \\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"trouvé\" | \"reconnu\" | \"résolu\" | \"détecté\" | \"relevé\" | \"vu\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1132, 1133]|Clement\"|\"|both|termination|nonpatient|30|Group[1132, 1133]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [365,\n",
       "  ['Group[1134]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Word Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"était\"\\n',\n",
       "   'Word -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var2 -> \"suspecté\" | \"pressenti\" | \"conjecturé\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[1134]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [366,\n",
       "  ['Group[1134]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Word Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"étaient\"\\n',\n",
       "   'Word -> \"\\\\\\\\w+\"\\n',\n",
       "   'Var2 -> \"suspectés\" | \"pressentis\" | \"conjecturés\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[1134]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [367,\n",
       "  ['Group[1135, 1136]', 'Group[1135, 1136]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"| \"ont\" \\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"chargé\" | \"délégué\" | \"confié\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1135, 1136]|Clement\"|\"|both|termination|nonpatient|30|Group[1135, 1136]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [368,\n",
       "  ['Group[1137]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"était\"\\n',\n",
       "   'Var2 -> \"négatif\" | \"négative\" | \"nulle\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[1137]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [369,\n",
       "  ['Group[1137]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"étaitent\"\\n',\n",
       "   'Var2 -> \"négatifs\" | \"négatives\" | \"nulles\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[1137]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [370,\n",
       "  ['Group[1141]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->   Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"n\\'était\" | \"n\\'étaient\"\\n',\n",
       "   'Var2 -> \"pas\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1141]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [371,\n",
       "  ['Group[1145]', 'Group[1147, 1148]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"arrêté\" | \"stoppé\" | \"enrayé\" | \"contenu\" | \"suspendu\" | \"jugulé\" | \"terminé\" | \"fini\" | \"endigué\" | \"cesseé\" | \"interrompu\"\\n',\n",
       "   'Termin -> |\"_e\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[1145]|Clement\"|\"|forward|termination|negated|10|Group[1147, 1148]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [372,\n",
       "  ['Group[1145]', 'Group[1147, 1148]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"ont\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"arrêté\" | \"stoppé\" | \"enrayé\" | \"contenu\" | \"suspendu\" | \"jugulé\" | \"terminé\" | \"fini\" | \"endigué\" | \"cesseé\" | \"interrompu\"\\n',\n",
       "   'Termin -> \"_s\"|\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[1145]|Clement\"|\"forward|termination|negated|10|Group[1147, 1148]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [373,\n",
       "  ['Group[1145]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"arrêté\" | \"stoppé\" | \"enrayé\" | \"contenu\" | \"suspendu\" | \"jugulé\" | \"terminé\" | \"fini\" | \"endigué\" | \"cesseé\" | \"interrompu\"\\n',\n",
       "   'Termin -> |\"_e\"\\n',\n",
       "   'Var4 -> \"en raison de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1145]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [374,\n",
       "  ['Group[1145]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ont\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"arrêté\" | \"stoppé\" | \"enrayé\" | \"contenu\" | \"suspendu\" | \"jugulé\" | \"terminé\" | \"fini\" | \"endigué\" | \"cesseé\" | \"interrompu\"\\n',\n",
       "   'Termin -> \"_s\"|\"_es\"\\n',\n",
       "   'Var4 -> \"en raison de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1145]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [375,\n",
       "  ['Group[1149]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"était\"\\n',\n",
       "   'Var2 -> \"soupçonné\" | \"flairé\" | \"pressentié\" | \"présumé\" | \"entrevu\" | \"senti\" | \"redouté\" | \"conjecturé\" | \"imaginé\" | \"subodoré\" | \"cru\"\\n',\n",
       "   'Termin -> |\"_e\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[1149]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [376,\n",
       "  ['Group[1149]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"étaient\"\\n',\n",
       "   'Var2 -> \"soupçonné\" | \"flairé\" | \"pressentié\" | \"présumé\" | \"entrevu\" | \"senti\" | \"redouté\" | \"conjecturé\" | \"imaginé\" | \"subodoré\" | \"cru\"\\n',\n",
       "   'Termin -> \"_s\" |\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[1149]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [377,\n",
       "  ['Group[1152, 1153]', 'Group[1152, 1153]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"a\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"instruit\" | \"informé\" | \"renseigné\" | \"examiné\" | \"expliqué\" | \"montré\" | \"soigné\" | \"éclairci\" | \"expliqué\"\\n',\n",
       "   'Termin -> |\"_e\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1152, 1153]|Clement\"|\"|both|termination|nonpatient|30|Group[1152, 1153]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [378,\n",
       "  ['Group[1152, 1153]', 'Group[1152, 1153]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Termin Trigger_Rule\\n',\n",
       "   'Var1 -> \"ont\"\\n',\n",
       "   'Var2 -> \"été\"\\n',\n",
       "   'Var3 -> \"instruit\" | \"informé\" | \"renseigné\" | \"examiné\" | \"expliqué\" | \"montré\" | \"soigné\" | \"éclairci\" | \"expliqué\"\\n',\n",
       "   'Termin -> \"_s\"|\"_es\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1152, 1153]|Clement\"|\"|both|termination|nonpatient|30|Group[1152, 1153]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [379,\n",
       "  ['Group[1157]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Var5 Trigger_Rule\\n',\n",
       "   'Var1 -> \"ce\"\\n',\n",
       "   'Var2 -> \"qui\"\\n',\n",
       "   'Var3 -> \"doit\"\\n',\n",
       "   'Var4 -> \"être\"\\n',\n",
       "   'Var5 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1157]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [380,\n",
       "  ['Group[1158, 1159]', 'Group[1158, 1159]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Var4 Trigger_Rule\\n',\n",
       "   'Var1 -> \"si\"\\n',\n",
       "   'Var2 -> \"oui\"\\n',\n",
       "   'Var3 -> \"ou\"\\n',\n",
       "   'Var4 -> \"non\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1158, 1159]|Clement\"|\"|forward|pseudo|negated|30|Group[1158, 1159]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [381,\n",
       "  ['Group[1160, 1161]', 'Group[1160, 1161]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"lequel\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1160, 1161]|Clement\"|\"|both|termination|nonpatient|30|Group[1160, 1161]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [382,\n",
       "  ['Group[1162]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"tandis\"\\n',\n",
       "   'Var2 -> \"que\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1162]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [383,\n",
       "  ['Group[1163]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"qui\"\\n',\n",
       "   'Var2 -> \"n\\'est pas\"\\n',\n",
       "   'Var3 -> \"présent\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1163]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [384,\n",
       "  ['Group[1163]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"qui\"\\n',\n",
       "   'Var2 -> \"ne sont pas\"\\n',\n",
       "   'Var3 -> \"présents\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|negated|10|Group[1163]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [385,\n",
       "  ['Group[1164]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sera\"\\n',\n",
       "   'Var2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\\n',\n",
       "   'Var3 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1164]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [386,\n",
       "  ['Group[1166, 1167]', 'Group[1166, 1167]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Member Trigger_Rule\\n',\n",
       "   'Var1 -> \"avec\"\\n',\n",
       "   'Var2 -> \"\\\\\\\\w+\"\\n',\n",
       "   'Member -> \"parent\" | \"parents\" | \"père\" | \"beau-père\" | \"mère\" |\"belle-mère\" | \"papa\" | \"maman\" |\"fils\" | \"beau-fils\" | \"garçon\" | \"fille\" | \"belle-fille\" | \"filles\" | \"frère\"| \"frères\" |\"soeur\" |\"soeurs\" |\"sœur\" |\"sœurs\" | \"fratrie\" | \"oncle\" | \"tonton\"| \"oncles\" |\"tante\" |\"tata\"  |\"tantes\" |\"grand-mère\" | \"grand-père\" |\"cousin\" |\"cousins\" |\"famille\" |\"colocataire\" | \"colocataires\" | \"voisin\" | \"voisins\"\\n',\n",
       "   'Trigger_Rule -> \"|both|termination|historical|30|Group[1166, 1167]|Clement\"|\"|both|termination|nonpatient|30|Group[1166, 1167]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [387,\n",
       "  ['Group[1181]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"supplément\" | \"excédent\" | \"appoint\" | \"addition\" | \"surcroît\" | \"extra\" | \"surplus\" | \"additif\" | \"rallonge\" | \"ajout\" | \"avenant\" | \"excès\" | \"ajut\" | \"adjuvant\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [388,\n",
       "  ['Group[1181]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"causer\" | \"susciter\" | \"amener\" | \"entraîner\" | \"provoquer\" | \"occasionner\" | \"donner\" | \"engendrer\" | \"créer\" | \"être cause de\" | \"déclencher\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [389,\n",
       "  ['Group[1181]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"devenir\" | \"rendre\" | \"donner\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [390,\n",
       "  ['Group[1181]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"être\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [391,\n",
       "  ['Group[1207]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"difficultés\" | \"mal\" | \"embarras\" | \"empêchement\" | \"obstacle\" | \"complication\" | \"problème\" | \"ennui\" | \"accroc\" | \"contrariété\" | \"résistance\" | \"complexité\" | \"tracas\" | \"objection\" | \"peine\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[1207]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [392,\n",
       "  ['Group[1207, 1208]', 'Group[1207, 1208]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"peine\" | \"tristesse\" | \"douleur\" | \"souffrance\" | \"affliction\" | \"inquiétude\" | \"tourment\" | \"désolation\" | \"amertume\" | \"malheur\" | \"détresse\" | \"misère\" | \"difficulté\" | \"agonie\" | \"regret\"\\n',\n",
       "   'Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[1207, 1208]|Clement\"|\"|both|pseudo|negated|10|Group[1207, 1208]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [393,\n",
       "  ['Group[1243]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"aucun\" | \"aucune\" | \"nul\" | \"nulle\" |\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1243]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [394,\n",
       "  ['Group[1269, 1270]', 'Group[1269, 1270]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"succès\" | \"effet\" | \"résultats\" | \"aboutissement\"\\n',\n",
       "   'Trigger_Rule -> \"|backward|trigger|negated|10|Group[1269, 1270]|Clement\"|\"|forward|termination|negated|10|Group[1269, 1270]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [395,\n",
       "  ['Group[1283]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"sans\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Var3 -> \"autant\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1283]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [396,\n",
       "  ['Group[1285]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"inquiet\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1285]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [397,\n",
       "  ['Group[1285]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"inquiétant\" | \"troublant\" | \"menaçant\" | \"préoccupant\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[1285]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [398,\n",
       "  ['Group[1288, 1289]', 'Group[1288, 1289]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"donné\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|termination|uncertain|4|Group[1288, 1289]|Clement\"|\"|forward|termination|conditional|4|Group[1288, 1289]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [399,\n",
       "  ['Group[1292]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Trigger_Rule\\n',\n",
       "   'Var1 -> \"négatif\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|10|Group[1292]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [400,\n",
       "  ['Group[1317]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"risque\"\\n',\n",
       "   'Var2 -> \"élevé\"\\n',\n",
       "   'Var3 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|20|Group[1317]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [401,\n",
       "  ['Group[1318]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Var3 Trigger_Rule\\n',\n",
       "   'Var1 -> \"à\"\\n',\n",
       "   'Var2 -> \"risque\" \\n',\n",
       "   'Var3 -> \"de\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|negated|20|Group[1318]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]],\n",
       " [402,\n",
       "  ['Group[1320]'],\n",
       "  ['from nltk.parse.generate import generate, demo_grammar\\n',\n",
       "   'from nltk import CFG\\n',\n",
       "   '\\n',\n",
       "   'cfg_grammar= \"\"\"\\n',\n",
       "   'S ->  Var1 Var2 Trigger_Rule\\n',\n",
       "   'Var1 -> \"surveillé\" | \"examiné\" | \"suivi\"\\n',\n",
       "   'Var2 -> \"pour\"\\n',\n",
       "   'Trigger_Rule -> \"|forward|trigger|conditional|30|Group[1320]|Clement\"\\n',\n",
       "   '\"\"\"\\n',\n",
       "   '\\n',\n",
       "   'for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n',\n",
       "   \"    print(' '.join(sentence))\"]]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlwt\n",
    "# wb = xlwt.Workbook()\n",
    "# ws = wb.add_sheet('Rules')\n",
    "# for rownum, value in enumerate(update):\n",
    "#     ws.write(rownum+1, 0, value[0])\n",
    "#     ws.write(rownum+1, 1, value[1])\n",
    "#     ws.write(rownum+1, 2, value[2])\n",
    "# wb.save(\"./notebooks-Clement/List_of_Rules_.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_notebook = {}  \n",
    "\n",
    "json_notebook[\"metadata\"] = {}\n",
    "json_notebook[\"metadata\"][\"kernelspec\"]={}\n",
    "json_notebook[\"metadata\"][\"kernelspec\"][\"display_name\"]= \"Python 3\"\n",
    "json_notebook[\"metadata\"][\"kernelspec\"][\"language\"]= \"python\"\n",
    "json_notebook[\"metadata\"][\"kernelspec\"][\"name\"]= \"python3\"\n",
    "\n",
    "json_notebook[\"metadata\"][\"language_info\"]={}\n",
    "json_notebook[\"metadata\"][\"language_info\"][\"codemirror_mode\"]={}\n",
    "json_notebook[\"metadata\"][\"language_info\"][\"codemirror_mode\"][\"name\"]= \"ipython\"\n",
    "json_notebook[\"metadata\"][\"language_info\"][\"codemirror_mode\"][\"version\"]= 3\n",
    "\n",
    "json_notebook[\"metadata\"][\"file_extension\"]= \".py\"\n",
    "json_notebook[\"metadata\"][\"mimetype\"]= \"text/x-python\"\n",
    "json_notebook[\"metadata\"][\"name\"]= \"python\"\n",
    "json_notebook[\"metadata\"][\"nbconvert_exporter\"]= \"python\"\n",
    "json_notebook[\"metadata\"][\"pygments_lexer\"]= \"ipython3\"\n",
    "json_notebook[\"metadata\"][\"version\"]= \"3.7.2\"\n",
    "\n",
    "\n",
    "json_notebook[\"nbformat\"]= 4\n",
    "json_notebook[\"nbformat_minor\"]=2\n",
    "json_notebook[\"cells\"]=[]\n",
    "\n",
    "for i in range(len(update)):\n",
    "    \n",
    "    json_cell={}\n",
    "    json_cell[\"cell_type\"] = \"code\"\n",
    "    json_cell[\"metadata\"] = {}\n",
    "    json_cell[\"outputs\"] = []\n",
    "    json_cell[\"execution_count\"] = \"null\"\n",
    "    json_cell[\"source\"]=update[i][2]\n",
    "    json_notebook[\"cells\"].append(json_cell)\n",
    "\n",
    "\n",
    "\n",
    "with open(\"./notebooks-Clement/CFG_List_v0.5.ipynb\", 'w+') as outfile:  \n",
    "    json.dump(json_notebook, outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
