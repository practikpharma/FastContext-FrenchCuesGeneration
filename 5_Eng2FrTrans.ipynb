{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import math \n",
    "\n",
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "def remove_second_pair(list_orders):\n",
    "    removed_second_pairs=[]\n",
    "    for item in list_orders:\n",
    "        removed_second_pairs.append(item[0])\n",
    "    return(removed_second_pairs)\n",
    "\n",
    "\n",
    "def add_words_lists(words,list_orders):\n",
    "    table = pd.concat([words,list_orders],axis=1)\n",
    "    new_list_orders=[]\n",
    "        \n",
    "    for row in range(0,len(table)):\n",
    "        if (table.iloc[row,0]!=np.NaN) and (table.iloc[row,1]!=[]):            \n",
    "            if table.iloc[row,0] in table.iloc[row,1]:\n",
    "                table.iloc[row,1].remove(table.iloc[row,0])\n",
    "            table.iloc[row,1].insert(0,table.iloc[row,0])\n",
    "\n",
    "    return (table.iloc[:,1])\n",
    "        \n",
    "def convert_list_2_cfg(ordinary_list):\n",
    "    acc_str=\"\"\n",
    "    for w in ordinary_list:\n",
    "        acc_str+=\" | \"+ \"\\\"\"+w+\"\\\"\"\n",
    "    return(acc_str)    \n",
    "    \n",
    "\n",
    "def generate_cfg(wpos,w1,w2,w3,s1,s2,s3):\n",
    "    cfg_rules=[]\n",
    "\n",
    "    for idx in range(0,len(wpos)):\n",
    "        wpos[idx][1]=wpos[idx][1].replace(\" \", \"_\")\n",
    "        wpos[idx][1]=wpos[idx][1].capitalize()+str(idx+1)\n",
    "\n",
    "\n",
    "    str_start=\"S -> \"\n",
    "    for idx in range(0,len(wpos)):\n",
    "        str_start +=\" \"+wpos[idx][1]\n",
    "\n",
    "    cfg_rules.append(str_start)  \n",
    "\n",
    "\n",
    "    for idx in range(0,len(wpos)):\n",
    "        str_rule=\"\"\n",
    "        str_rule +=wpos[idx][1]+\" -> \"+\"\\\"\"+wpos[idx][0]+\"\\\"\"\n",
    "        cfg_rules.append(str_rule)  \n",
    "\n",
    "\n",
    "    if not isinstance(w1, str):\n",
    "        if np.isnan(w1):\n",
    "            w1=\"\"\n",
    "            \n",
    "    if not isinstance(w2, str):\n",
    "        if np.isnan(w2):\n",
    "            w2=\"\"\n",
    "            \n",
    "    if not isinstance(w3, str):\n",
    "        if np.isnan(w3):\n",
    "            w3=\"\"            \n",
    "\n",
    "    \n",
    "    cfg_rules_augmented=[]    \n",
    "    for rule in cfg_rules:\n",
    "        if rule.find(w1)>=0:\n",
    "            cfg_rules_augmented.append(rule+convert_list_2_cfg(s1[1:]))\n",
    "        elif rule.find(w2)>=0:\n",
    "            cfg_rules_augmented.append(rule+convert_list_2_cfg(s2[1:]))\n",
    "        elif rule.find(w3)>=0:\n",
    "            cfg_rules_augmented.append(rule+convert_list_2_cfg(s3[1:]))\n",
    "        else:\n",
    "            cfg_rules_augmented.append(rule)\n",
    "\n",
    "\n",
    "    cfg_grammar=\"\"\n",
    "    for rule in cfg_rules_augmented:\n",
    "        cfg_grammar+=rule+\"\\n\"     \n",
    "    \n",
    "    return(cfg_grammar)      \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "word_table=pd.read_excel(\n",
    "    \"/Users/mehdi.mirzapour/Dropbox/PractiKPharma/PractiKPharma_Code/excels/4_Phase3_TranslationTable.xlsx\")   \n",
    "\n",
    "    \n",
    "\n",
    "word_table=word_table.fillna(\"\")\n",
    "\n",
    "for row_w in range(word_table.shape[0]):\n",
    "        word_table[\"syn_1\"][row_w]=syn_table[\"Synonyms_Voting_Top10\"][row_s]\n",
    "\n",
    "\n",
    "# word_table.to_excel(\n",
    "#     \"/Users/mehdi.mirzapour/Dropbox/PractiKPharma/PractiKPharma_Code/excels/5_Phase3_TranslationTable.xlsx\")           \n",
    "    \n",
    "word_table\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicalclues=pd.read_excel(\n",
    "    \"/Users/mehdi.mirzapour/Dropbox/PractiKPharma/Lexicons/FrenchTranslation_Phase2_Step_2.xlsx\")\n",
    "\n",
    "lexicalclues[\"CFG_Rule\"]=\"\"\n",
    "lexicalclues[\"L(CFG_Rule)\"]=\"\"\n",
    "\n",
    "exp_fr=lexicalclues[\"French Expression\"]\n",
    "exp_en=lexicalclues[\"English Expression(s)\"].apply(lambda s: ast.literal_eval(s))\n",
    "\n",
    "word_pos=lexicalclues[\"Tokenization with POS\"].apply(lambda s: ast.literal_eval(s))\n",
    "\n",
    "\n",
    "word1=lexicalclues[\"word1\"]\n",
    "syn1_list=lexicalclues[\"syn1_ordered\"].apply(lambda s: ast.literal_eval(s))\n",
    "syn1_list=syn1_list.apply(remove_second_pair)\n",
    "syn1_list=add_words_lists(word1,syn1_list)\n",
    "\n",
    "word2=lexicalclues[\"word2\"]\n",
    "syn2_list=lexicalclues[\"syn2_ordered\"].apply(lambda s: ast.literal_eval(s))\n",
    "syn2_list=syn2_list.apply(remove_second_pair)\n",
    "syn2_list=add_words_lists(word2,syn2_list)\n",
    "\n",
    "word3=lexicalclues[\"word3\"]\n",
    "syn3_list=lexicalclues[\"syn3_ordered\"].apply(lambda s: ast.literal_eval(s))\n",
    "syn3_list=syn3_list.apply(remove_second_pair)\n",
    "syn3_list=add_words_lists(word3,syn3_list)\n",
    "\n",
    "\n",
    "\n",
    "json_notebook = {}  \n",
    "\n",
    "json_notebook[\"metadata\"] = {}\n",
    "json_notebook[\"metadata\"][\"kernelspec\"]={}\n",
    "json_notebook[\"metadata\"][\"kernelspec\"][\"display_name\"]= \"Python 3\"\n",
    "json_notebook[\"metadata\"][\"kernelspec\"][\"language\"]= \"python\"\n",
    "json_notebook[\"metadata\"][\"kernelspec\"][\"name\"]= \"python3\"\n",
    "\n",
    "json_notebook[\"metadata\"][\"language_info\"]={}\n",
    "json_notebook[\"metadata\"][\"language_info\"][\"codemirror_mode\"]={}\n",
    "json_notebook[\"metadata\"][\"language_info\"][\"codemirror_mode\"][\"name\"]= \"ipython\"\n",
    "json_notebook[\"metadata\"][\"language_info\"][\"codemirror_mode\"][\"version\"]= 3\n",
    "\n",
    "json_notebook[\"metadata\"][\"file_extension\"]= \".py\"\n",
    "json_notebook[\"metadata\"][\"mimetype\"]= \"text/x-python\"\n",
    "json_notebook[\"metadata\"][\"name\"]= \"python\"\n",
    "json_notebook[\"metadata\"][\"nbconvert_exporter\"]= \"python\"\n",
    "json_notebook[\"metadata\"][\"pygments_lexer\"]= \"ipython3\"\n",
    "json_notebook[\"metadata\"][\"version\"]= \"3.7.2\"\n",
    "\n",
    "\n",
    "json_notebook[\"nbformat\"]= 4\n",
    "json_notebook[\"nbformat_minor\"]=2\n",
    "\n",
    "\n",
    "\n",
    "seperation_margin=[[0,100],[101,200],[201,300],[301,400],[401,500],[501,600],[601,735]]\n",
    "\n",
    "\n",
    "for sm in seperation_margin:\n",
    "    \n",
    "    json_notebook[\"cells\"]=[]\n",
    "    \n",
    "    index_start=sm[0]\n",
    "    index_end=sm[1]\n",
    "    \n",
    "    strlist=\"_\"+str(index_start)+\"_\"+str(index_end)\n",
    "    \n",
    "    threshold=15\n",
    "    \n",
    "    for i in range(index_start,index_end+1): \n",
    "\n",
    "        expfr=exp_fr[i]\n",
    "        expen=exp_en[i]\n",
    "        wpos=word_pos[i]\n",
    "        w1=word1[i]\n",
    "        w2=word2[i]\n",
    "        w3=word3[i]\n",
    "        s1=syn1_list[i][0:threshold]\n",
    "        s2=syn2_list[i][0:threshold]\n",
    "        s3=syn3_list[i][0:threshold]\n",
    "\n",
    "        cfg_grammar=generate_cfg(wpos,w1,w2,w3,s1,s2,s3)\n",
    "\n",
    "        \n",
    "        json_cell={}\n",
    "        json_cell[\"cell_type\"] = \"code\"\n",
    "        json_cell[\"metadata\"] = {}\n",
    "        json_cell[\"outputs\"] = []\n",
    "        json_cell[\"execution_count\"] = \"null\"\n",
    "        json_source1=[\"from nltk.parse.generate import generate, demo_grammar\\n\",\n",
    "            \"from nltk import CFG\\n\",\n",
    "            \"\\n\",\n",
    "            \"#  Item Number     : \"+str(i)+\"\\n\",\n",
    "            \"#  French Term     : \"+str(expfr)+\"\\n\",\n",
    "            \"#  English Term(s) : \"+str(expen)+\"\\n\\n\",\n",
    "            \"\\n\",\n",
    "            \"cfg_grammar= \\\"\\\"\\\"\\n\"]\n",
    "        json_source2=[cfg_grammar]\n",
    "        json_source3=[\"\\\"\\\"\\\"\\n\",\n",
    "            \"\\n\",\n",
    "            \"for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\\n\",\n",
    "            \"    print(' '.join(sentence))\"]\n",
    "        json_cell[\"source\"]=json_source1+json_source2+json_source3\n",
    "\n",
    "        json_notebook[\"cells\"].append(json_cell)\n",
    "\n",
    "\n",
    "\n",
    "    with open(\"Validation_Notebook\"+strlist+\".ipynb\", 'w') as outfile:  \n",
    "        json.dump(json_notebook, outfile)\n",
    "print(\"Finished...\")\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
