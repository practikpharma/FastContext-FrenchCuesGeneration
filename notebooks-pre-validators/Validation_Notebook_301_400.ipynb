{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avait un \\w+ négatif pour |forward|trigger|negated|10|Group[557]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Determiner2 Adjective3 Adjective6 Adposition7 Trigger_Rule\n",
    "Verb1 -> \"avait\"\n",
    "Determiner2 -> \"un\"\n",
    "Adjective3 -> \"\\\\w+\"\n",
    "Adjective6 -> \"négatif\"\n",
    "Adposition7 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[557]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a un \\w+ négatif pour |forward|trigger|negated|10|Group[557]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Determiner2 Adjective3 Adjective6 Adposition7 Trigger_Rule\n",
    "Verb1 -> \"a\"\n",
    "Determiner2 -> \"un\"\n",
    "Adjective3 -> \"\\\\w+\"\n",
    "Adjective6 -> \"négatif\"\n",
    "Adposition7 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[557]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a été négatif |backward|trigger|negated|10|Group[561]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Auxiliary2 Adjective3 Trigger_Rule\n",
    "Auxiliary1 -> \"a\"\n",
    "Auxiliary2 -> \"été\"\n",
    "Adjective3 -> \"négatif\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[561]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a été exclu |backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\n",
      "a été refusé |backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\n",
      "a été repoussé |backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\n",
      "a été rejeté |backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\n",
      "a été éliminé |backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\n",
      "a été proscrit |backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\n",
    "Auxiliary1 -> \"a\"\n",
    "Auxiliary2 -> \"été\"\n",
    "Verb3 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n'a pas eu de |forward|trigger|negated|10|Group[569]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S -> Auxiliary2 Adverb3 Verb4 Determiner5 Trigger_Rule\n",
    "Auxiliary2 -> \"n'a\"\n",
    "Adverb3 -> \"pas\"\n",
    "Verb4 -> \"eu\"\n",
    "Determiner5 -> \"de\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[569]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avoir un \\w+ négatif pour |forward|trigger|negated|10|Group[571]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Determiner2 Adjective3 Adjective6 Adposition7 Trigger_Rule\n",
    "Verb1 -> \"avoir\"\n",
    "Determiner2 -> \"un\"\n",
    "Adjective3 -> \"\\\\w+\"\n",
    "Adjective6 -> \"négatif\"\n",
    "Adposition7 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[571]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ont été écartés |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été rejeter |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été éliminer |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été évincer |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été supprimer |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été proscrire |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été exclure |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été éloigner |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été côté |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été enlever |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été récuser |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été gouverner |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n",
      "ont été mis à l'écart |backward|trigger|negated|10|Group[573]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\n",
    "Auxiliary1 -> \"ont\"\n",
    "Auxiliary2 -> \"été\"\n",
    "Verb3 -> \"écartés\" | \"rejeter\" | \"éliminer\" | \"évincer\" | \"supprimer\" | \"proscrire\" | \"exclure\" | \"éloigner\" | \"côté\" | \"enlever\" | \"récuser\" | \"gouverner\" | \"mis à l'écart\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[573]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il a continué à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a reconduire à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a perpétuer à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a conserver à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a suivre à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a tenir à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a se poursuivre à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a donner suite à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a se perpétuer à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a s'acharner à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a s'obstiner à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a entretenir à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a perdurer à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a opiniâtrer à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n",
      "il a entêter à |forward|termination|negated|10|Group[575]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Pronoun1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\n",
    "Pronoun1 -> \"il\"\n",
    "Auxiliary2 -> \"a\"\n",
    "Verb3 -> \"continué\" | \"reconduire\" | \"perpétuer\" | \"conserver\" | \"suivre\" | \"tenir\" | \"se poursuivre\" | \"donner suite\" | \"se perpétuer\" | \"s'acharner\" | \"s'obstiner\" | \"entretenir\" | \"perdurer\" | \"opiniâtrer\" | \"entêter\"\n",
    "Adposition4 -> \"à\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[575]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "son vieux |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son vétuste |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son usé |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son passé |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son fatigué |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son séculaire |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son éloigné |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son historique |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son usagé |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son périmé |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son vieilli |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n",
      "son vieil |forward|termination|negated|10|Group[576]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Determiner1 Noun2 Trigger_Rule\n",
    "Determiner1 -> \"son\"\n",
    "Noun2 -> \"vieux\" | \"vétuste\" | \"usé\" | \"passé\" | \"fatigué\" | \"séculaire\" | \"éloigné\" | \"historique\" | \"usagé\" | \"périmé\" | \"vieilli\" | \"vieil\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[576]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adjective2 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Adjective2 -> \"physique\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de gémissement principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de lamentation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de protestation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de reproche principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de gémissement principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de lamentation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de protestation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de reproche principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de gémissement principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de lamentation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de protestation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de reproche principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de gémissement principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de lamentation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de protestation principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de reproche principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de plainte principale |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adposition2 Noun3 Adjective4 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Adposition2 -> \"de\"\n",
    "Noun3 -> \"plainte\" | \"gémissement\" | \"lamentation\" | \"protestation\" | \"reproche\" | \"plainte\"\n",
    "Adjective4 -> \"principale\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire et physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et physique |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Coordinating_conjunction2 Adjective3 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Coordinating_conjunction2 -> \"et\"\n",
    "Adjective3 -> \"physique\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire et |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Coordinating_conjunction2 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Coordinating_conjunction2 -> \"et\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire pour |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé pour |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir pour |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique pour |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adposition2 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Adposition2 -> \"pour\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire et examen |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et analyse |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et consultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et observation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et vérification |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et recherche |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et étude |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et auscultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et examen médical |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et autopsie |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et dépistage |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire et interrogatoire |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et examen |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et analyse |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et consultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et observation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et vérification |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et recherche |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et étude |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et auscultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et examen médical |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et autopsie |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et dépistage |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé et interrogatoire |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et examen |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et analyse |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et consultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et observation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et vérification |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et recherche |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et étude |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et auscultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et examen médical |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et autopsie |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et dépistage |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir et interrogatoire |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et examen |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et analyse |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et consultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et observation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et vérification |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et recherche |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et étude |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et auscultation |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et examen médical |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et autopsie |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et dépistage |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique et interrogatoire |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Coordinating_conjunction2 Noun3 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Coordinating_conjunction2 -> \"et\"\n",
    "Noun3 -> \"examen\" | \"analyse\" | \"consultation\" | \"observation\" | \"vérification\" | \"recherche\" | \"étude\" | \"auscultation\" | \"examen médical\" | \"autopsie\" | \"dépistage\" | \"interrogatoire\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire de la maladie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la malaise actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la mal actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la trouble actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de l'indisposition actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la souffrance actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la syndrome actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de l'infirmité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de l'incommodité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de l'atteinte actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la tare actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la altération actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la pathologie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la traumatisme actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "histoire de la récidive actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la maladie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la malaise actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la mal actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la trouble actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de l'indisposition actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la souffrance actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la syndrome actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de l'infirmité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de l'incommodité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de l'atteinte actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la tare actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la altération actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la pathologie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la traumatisme actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé de la récidive actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la maladie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la malaise actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la mal actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la trouble actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de l'indisposition actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la souffrance actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la syndrome actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de l'infirmité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de l'incommodité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de l'atteinte actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la tare actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la altération actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la pathologie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la traumatisme actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir de la récidive actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la maladie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la malaise actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la mal actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la trouble actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de l'indisposition actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la souffrance actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la syndrome actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de l'infirmité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de l'incommodité actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de l'atteinte actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la tare actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la altération actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la pathologie actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la traumatisme actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique de la récidive actuelle |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adposition2 Noun4 Adjective5 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Adposition2 -> \"de\"\n",
    "Noun4 -> \"la maladie\" | \"la malaise\" | \"la mal\" | \"la trouble\" | \"l'indisposition\" | \"la souffrance\" | \"la syndrome\" | \"l'infirmité\" | \"l'incommodité\" | \"l'atteinte\" | \"la tare\" | \"la altération\" | \"la pathologie\" | \"la traumatisme\" | \"la récidive\"\n",
    "Adjective5 -> \"actuelle\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histoire prenant |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "passé prenant |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "souvenir prenant |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n",
      "historique prenant |both|pseudo|historical|30|Group[578]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Verb2 Trigger_Rule\n",
    "Noun1 -> \"histoire\" | \"passé\" | \"souvenir\" | \"historique\"\n",
    "Verb2 -> \"prenant\"\n",
    "Trigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#l'histoire |forward|trigger|historical|30|Group[586]|PRE-VALIDATION\n",
      "#passé |forward|trigger|historical|30|Group[586]|PRE-VALIDATION\n",
      "#souvenir |forward|trigger|historical|30|Group[586]|PRE-VALIDATION\n",
      "#l'historique |forward|trigger|historical|30|Group[586]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S -> Noun3 Trigger_Rule\n",
    "Noun3 -> \"#l'histoire\" | \"#passé\" | \"#souvenir\" | \"#l'historique\"\n",
    "Trigger_Rule -> \"|forward|trigger|historical|30|Group[586]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toutefois |forward|termination|negated|10|Group[587]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Trigger_Rule\n",
    "Adverb1 -> \"toutefois\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[587]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ho |forward|trigger|historical|30|Group[588]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Trigger_Rule\n",
    "Noun1 -> \"ho\"\n",
    "Trigger_Rule -> \"|forward|trigger|historical|30|Group[588]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hx |forward|trigger|historical|30|Group[589]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adposition1 Trigger_Rule\n",
    "Adposition1 -> \"hx\"\n",
    "Trigger_Rule -> \"|forward|trigger|historical|30|Group[589]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si négatif |both|pseudo|conditional|30|Group[590]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Subordinating_conjunction1 Adjective2 Trigger_Rule\n",
    "Subordinating_conjunction1 -> \"si\"\n",
    "Adjective2 -> \"négatif\"\n",
    "Trigger_Rule -> \"|both|pseudo|conditional|30|Group[590]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si |forward|trigger|conditional|30|Group[591]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Subordinating_conjunction1 Trigger_Rule\n",
    "Subordinating_conjunction1 -> \"si\"\n",
    "Trigger_Rule -> \"|forward|trigger|conditional|30|Group[591]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en elle |both|pseudo|uncertain|30|Group[592]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adposition1 Pronoun2 Trigger_Rule\n",
    "Adposition1 -> \"en\"\n",
    "Pronoun2 -> \"elle\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[592]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans son |both|pseudo|uncertain|30|Group[593]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adposition1 Determiner2 Trigger_Rule\n",
    "Adposition1 -> \"dans\"\n",
    "Determiner2 -> \"son\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[593]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autrefois |both|trigger|historical|30|Group[594]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Trigger_Rule\n",
    "Noun1 -> \"autrefois\"\n",
    "Trigger_Rule -> \"|both|trigger|historical|30|Group[594]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans le contexte de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n",
      "dans le situation de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n",
      "dans le circonstance de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n",
      "dans le cadre de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n",
      "dans le conjoncture de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n",
      "dans le ambiance de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n",
      "dans le atmosphère de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n",
      "dans le condition de |forward|termination|negated|10|Group[595]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\n",
    "Adposition1 -> \"dans\"\n",
    "Determiner2 -> \"le\"\n",
    "Noun3 -> \"contexte\" | \"situation\" | \"circonstance\" | \"cadre\" | \"conjoncture\" | \"ambiance\" | \"atmosphère\" | \"condition\"\n",
    "Adposition4 -> \"de\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[595]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incompatible avec |forward|trigger|negated|10|Group[596]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adjective1 Adposition2 Trigger_Rule\n",
    "Adjective1 -> \"incompatible\"\n",
    "Adposition2 -> \"avec\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[596]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indication |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "avertissement |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "prescription |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "directive |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "annotation |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "explication |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "renvoi |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "information |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "note |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "recommandation |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "critère |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "notation |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "suggestion |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "mention |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n",
      "symptôme |forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Trigger_Rule\n",
    "Noun1 -> \"indication\" | \"avertissement\" | \"prescription\" | \"directive\" | \"annotation\" | \"explication\" | \"renvoi\" | \"information\" | \"note\" | \"recommandation\" | \"critère\" | \"notation\" | \"suggestion\" | \"mention\" | \"symptôme\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est négatif |backward|trigger|negated|10|Group[599]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Adjective2 Trigger_Rule\n",
    "Auxiliary1 -> \"est\"\n",
    "Adjective2 -> \"négatif\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[599]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est neg |backward|trigger|negated|10|Group[601]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Adverb2 Trigger_Rule\n",
    "Auxiliary1 -> \"est\"\n",
    "Adverb2 -> \"neg\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[601]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n'est plus |backward|trigger|negated|10|Group[603]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S -> Verb2 Adverb3 Trigger_Rule\n",
    "Verb2 -> \"n'est\"\n",
    "Adverb3 -> \"plus\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[603]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n'est pas |forward|trigger|negated|10|Group[605]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Adverb3 Trigger_Rule\n",
    "Verb1 -> \"n'est\"\n",
    "Adverb3 -> \"pas\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[605]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est exclu |backward|trigger|negated|10|Group[607]|PRE-VALIDATION\n",
      "est refusé |backward|trigger|negated|10|Group[607]|PRE-VALIDATION\n",
      "est repoussé |backward|trigger|negated|10|Group[607]|PRE-VALIDATION\n",
      "est rejeté |backward|trigger|negated|10|Group[607]|PRE-VALIDATION\n",
      "est éliminé |backward|trigger|negated|10|Group[607]|PRE-VALIDATION\n",
      "est proscrit |backward|trigger|negated|10|Group[607]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Verb2 Trigger_Rule\n",
    "Auxiliary1 -> \"est\"\n",
    "Verb2 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[607]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est arrêté |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est stopper |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est enrayer |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est contenir |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est suspendre |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est juguler |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est terminer |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est finir |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est endiguer |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est cesser |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est barrer |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est empêcher |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est interrompre |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est mettre fin |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n",
      "est geler |backward|trigger|negated|10|Group[609]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Verb2 Trigger_Rule\n",
    "Auxiliary1 -> \"est\"\n",
    "Verb2 -> \"arrêté\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"empêcher\" | \"interrompre\" | \"mettre fin\" | \"geler\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[609]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est à exclure pour |forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\n",
      "est à éliminer pour |forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\n",
      "est à rejeter pour |forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\n",
      "est à proscrire pour |forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\n",
      "est à éloigner pour |forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\n",
      "est à supprimer pour |forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\n",
      "est à radier pour |forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Adposition2 Noun3 Adposition4 Trigger_Rule\n",
    "Auxiliary1 -> \"est\"\n",
    "Adposition2 -> \"à\"\n",
    "Noun3 -> \"exclure\" | \"éliminer\" | \"rejeter\" | \"proscrire\" | \"éloigner\" | \"supprimer\" | \"radier\"\n",
    "Adposition4 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est à exclure |backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\n",
      "est à éliminer |backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\n",
      "est à rejeter |backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\n",
      "est à proscrire |backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\n",
      "est à éloigner |backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\n",
      "est à supprimer |backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\n",
      "est à radier |backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Adposition2 Noun3 Trigger_Rule\n",
    "Auxiliary1 -> \"est\"\n",
    "Adposition2 -> \"à\"\n",
    "Noun3 -> \"exclure\" | \"éliminer\" | \"rejeter\" | \"proscrire\" | \"éloigner\" | \"supprimer\" | \"radier\"\n",
    "Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manque de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "insuffisance de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "défaut de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "déficience de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "pénurie de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "carence de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "privation de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "lacune de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "omission de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "manquement de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "défaillance de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "rareté de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "oubli de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "faute de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n",
      "faiblesse de |forward|trigger|negated|10|Group[615]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adposition2 Trigger_Rule\n",
    "Noun1 -> \"manque\" | \"insuffisance\" | \"défaut\" | \"déficience\" | \"pénurie\" | \"carence\" | \"privation\" | \"lacune\" | \"omission\" | \"manquement\" | \"défaillance\" | \"rareté\" | \"oubli\" | \"faute\" | \"faiblesse\"\n",
    "Adposition2 -> \"de\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[615]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manquait |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "oublier |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "rater |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "fausser |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "déchoir |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "gâcher |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "omettre |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "enfreindre |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "faillir |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "être absent |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "avoir disparu |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "être en défaut |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "être dénué |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "être dépourvu |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n",
      "être disparu |forward|trigger|negated|10|Group[617]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Trigger_Rule\n",
    "Verb1 -> \"manquait\" | \"oublier\" | \"rater\" | \"fausser\" | \"déchoir\" | \"gâcher\" | \"omettre\" | \"enfreindre\" | \"faillir\" | \"être absent\" | \"avoir disparu\" | \"être en défaut\" | \"être dénué\" | \"être dépourvu\" | \"être disparu\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[617]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il y a \\> 0 année |backward|trigger|historical|30|Group[619]|PRE-VALIDATION\n",
      "il y a \\> 0 années |backward|trigger|historical|30|Group[619]|PRE-VALIDATION\n",
      "il y a \\> 0 an |backward|trigger|historical|30|Group[619]|PRE-VALIDATION\n",
      "il y a \\> 0 annuités |backward|trigger|historical|30|Group[619]|PRE-VALIDATION\n",
      "il y a \\> 0 ans |backward|trigger|historical|30|Group[619]|PRE-VALIDATION\n",
      "il y a \\> 0 annualité |backward|trigger|historical|30|Group[619]|PRE-VALIDATION\n",
      "il y a \\> 0 semaine |backward|trigger|historical|30|Group[619]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S -> Ph1 Adjective2 Noun5 Trigger_Rule\n",
    "Ph1 -> \"il y a\"\n",
    "Adjective2 -> \"\\\\> 0\"\n",
    "Noun5 -> \"année\" | \"années\" | \"an\" | \"annuités\" | \"ans\" | \"annualité\" | \"semaine\"\n",
    "Trigger_Rule -> \"|backward|trigger|historical|30|Group[619]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'hiver dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "l'été dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "le printemps dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "Septembre dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "octobre dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "novembre dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "mai dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "dernier mars dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "juin dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "juillet dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "janvier dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "février dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "l'automne dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "décembre dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "août dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n",
      "avril dernier |backward|trigger|historical|30|Group[626]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adjective2 Trigger_Rule\n",
    "Noun1 -> \"l'hiver\" |\"l'été\" |\"le printemps\" |\"Septembre\" |\"octobre\" |\"novembre\" |\"mai\" |\"dernier mars\" |\"juin\" |\"juillet\" |\"janvier\" |\"février\" |\"l'automne\" |\"décembre\" |\"août\" |\"avril\" \n",
    "Adjective2 -> \"dernier\"\n",
    "Trigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contributeurs probables à |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\n",
    "Noun1 -> \"contributeurs\"\n",
    "Adjective2 -> \"probables\"\n",
    "Adposition3 -> \"à\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probablement en cas de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "probablement en situation de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "probablement en événement de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "probablement en possibilité de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "probablement en éventualité de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Adposition2 Noun3 Adposition4 Trigger_Rule\n",
    "Adverb1 -> \"probablement\"\n",
    "Adposition2 -> \"en\"\n",
    "Noun3 -> \"cas\" | \"situation\" | \"événement\" | \"possibilité\" | \"éventualité\"\n",
    "Adposition4 -> \"de\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probablement de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Adposition2 Trigger_Rule\n",
    "Adverb1 -> \"probablement\"\n",
    "Adposition2 -> \"de\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composante probable de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "élément probable de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "ingrédient probable de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "constituante probable de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n",
      "facteur probable de |forward|termination|negated|10|Group[642]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\n",
    "Noun1 -> \"composante\" | \"élément\" | \"ingrédient\" | \"constituante\" | \"facteur\"\n",
    "Adjective2 -> \"probable\"\n",
    "Adposition3 -> \"de\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reflétant probablement |both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\n",
      "exprimer probablement |both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\n",
      "renvoyer probablement |both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\n",
      "indiquer probablement |both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\n",
      "marquer probablement |both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\n",
      "traduire probablement |both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\n",
      "incarner probablement |both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Adverb2 Trigger_Rule\n",
    "Verb1 -> \"reflétant\" | \"exprimer\" | \"renvoyer\" | \"indiquer\" | \"marquer\" | \"traduire\" | \"incarner\"\n",
    "Adverb2 -> \"probablement\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probable |forward|trigger|uncertain|30|Group[647]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adjective1 Trigger_Rule\n",
    "Adjective1 -> \"probable\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[647]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chercher tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "scruter tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "sonder tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "consulter tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "essayer tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "explorer tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "rechercher tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "examiner tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "fouiller tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "prospecter tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "interroger tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "découvrir tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "analyser tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "aller chercher tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "considérer tout |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Adverb2 Trigger_Rule\n",
    "Verb1 -> \"chercher\" | \"scruter\" | \"sonder\" | \"consulter\" | \"essayer\" | \"explorer\" | \"rechercher\" | \"examiner\" | \"fouiller\" | \"prospecter\" | \"interroger\" | \"découvrir\" | \"analyser\" | \"aller chercher\" | \"considérer\"\n",
    "Adverb2 -> \"tout\"\n",
    "Trigger_Rule -> \"|forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chercher |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "scruter |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "sonder |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "consulter |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "essayer |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "explorer |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "rechercher |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "examiner |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "fouiller |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "prospecter |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "interroger |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "découvrir |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "analyser |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "aller chercher |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n",
      "considérer |forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Trigger_Rule\n",
    "Verb1 -> \"chercher\" | \"scruter\" | \"sonder\" | \"consulter\" | \"essayer\" | \"explorer\" | \"rechercher\" | \"examiner\" | \"fouiller\" | \"prospecter\" | \"interroger\" | \"découvrir\" | \"analyser\" | \"aller chercher\" | \"considérer\"\n",
    "Trigger_Rule -> \"|forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nettement |both|pseudo|uncertain|30|Group[650]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Trigger_Rule\n",
    "Adverb1 -> \"nettement\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[650]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut être \\w+ sous-estimé |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ minimisé |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ minoré |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ mésestimé |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ déconsidéré |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ méprisé |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ décrié |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ dévalué |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ décrédité |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ discrédité |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ déprécié |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ méjugé |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ dévalorisé |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n",
      "peut être \\w+ sous-évalué |both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Auxiliary2 Verb3 Noun6 Trigger_Rule\n",
    "Verb1 -> \"peut\"\n",
    "Auxiliary2 -> \"être\"\n",
    "Verb3 -> \"\\\\w+\"\n",
    "Noun6 -> \"sous-estimé\" | \"minimisé\" | \"minoré\" | \"mésestimé\" | \"déconsidéré\" | \"méprisé\" | \"décrié\" | \"dévalué\" | \"décrédité\" | \"discrédité\" | \"déprécié\" | \"méjugé\" | \"dévalorisé\" | \"sous-évalué\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut contribuer |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut collaborer |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut concourir |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut coopérer |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut participer |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut servir |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut seconder |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut favoriser |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut agir |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut tendre |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut avoir part |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n",
      "peut prendre part |both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Verb2 Trigger_Rule\n",
    "Auxiliary1 -> \"peut\"\n",
    "Verb2 -> \"contribuer\" | \"collaborer\" | \"concourir\" | \"coopérer\" | \"participer\" | \"servir\" | \"seconder\" | \"favoriser\" | \"agir\" | \"tendre\" | \"avoir part\" | \"prendre part\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut-être dû à |forward|trigger|uncertain|30|Group[653]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Adjective2 Adposition3 Trigger_Rule\n",
    "Adverb1 -> \"peut-être\"\n",
    "Adjective2 -> \"dû\"\n",
    "Adposition3 -> \"à\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[653]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut être démasquer |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être découvrir |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être montrer |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être révéler |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être dévoiler |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être démontrer |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être trahir |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être deviner |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être lever le masque |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être dénicher |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être déceler |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être dépister |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être débusquer |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être détecter |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\n",
    "Verb1 -> \"peut\"\n",
    "Auxiliary2 -> \"être\"\n",
    "Verb3 -> \"démasquer\" | \"découvrir\" | \"montrer\" | \"révéler\" | \"dévoiler\" | \"démontrer\" | \"trahir\" | \"deviner\" | \"lever le masque\" | \"dénicher\" | \"déceler\" | \"dépister\" | \"débusquer\" | \"détecter\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut être lié à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être connexe à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être relié à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être imbriqué à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être solidaire à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être analogique à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être conjoint à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être attaché à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être inhérent à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être familier à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être allier à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être rattaché à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être coordonné à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être adjoint à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être assujetti à |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\n",
    "Verb1 -> \"peut\"\n",
    "Auxiliary2 -> \"être\"\n",
    "Verb3 -> \"lié\" | \"connexe\" | \"relié\" | \"imbriqué\" | \"solidaire\" | \"analogique\" | \"conjoint\" | \"attaché\" | \"inhérent\" | \"familier\" | \"allier\" | \"rattaché\" | \"coordonné\" | \"adjoint\" | \"assujetti\"\n",
    "Adposition4 -> \"à\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut être sous-estimé |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être minimisé |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être minoré |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être mésestimé |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être déconsidéré |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être méprisé |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être décrié |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être dévalué |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être décrédité |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être discrédité |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être déprécié |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être méjugé |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être dévalorisé |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n",
      "peut être sous-évalué |both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\n",
    "Verb1 -> \"peut\"\n",
    "Auxiliary2 -> \"être\"\n",
    "Verb3 -> \"sous-estimé\" | \"minimisé\" | \"minoré\" | \"mésestimé\" | \"déconsidéré\" | \"méprisé\" | \"décrié\" | \"dévalué\" | \"décrédité\" | \"discrédité\" | \"déprécié\" | \"méjugé\" | \"dévalorisé\" | \"sous-évalué\"\n",
    "Trigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut être |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Auxiliary2 Trigger_Rule\n",
    "Verb1 -> \"peut\"\n",
    "Auxiliary2 -> \"être\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut représenter |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut symboliser |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut décrire |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut montrer |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut reproduire |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut dépeindre |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut figurer |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut dessiner |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut peindre |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut exposer |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut présenter |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut signifier |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut exhiber |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut évoquer |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut désigner |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Verb2 Trigger_Rule\n",
    "Auxiliary1 -> \"peut\"\n",
    "Verb2 -> \"représenter\" | \"symboliser\" | \"décrire\" | \"montrer\" | \"reproduire\" | \"dépeindre\" | \"figurer\" | \"dessiner\" | \"peindre\" | \"exposer\" | \"présenter\" | \"signifier\" | \"exhiber\" | \"évoquer\" | \"désigner\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puis-je avoir |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adjective1 Verb2 Trigger_Rule\n",
    "Adjective1 -> \"puis-je\"\n",
    "Verb2 -> \"avoir\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peut avoir été précédé par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été devancer par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été annoncer par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été prévenir par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été distancé par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été annoncé par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été devancé par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été amené par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n",
      "peut avoir été préludé par |forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Auxiliary1 Auxiliary2 Auxiliary3 Verb4 Adposition5 Trigger_Rule\n",
    "Auxiliary1 -> \"peut\"\n",
    "Auxiliary2 -> \"avoir\"\n",
    "Auxiliary3 -> \"été\"\n",
    "Verb4 -> \"précédé\" | \"devancer\" | \"annoncer\" | \"prévenir\" | \"distancé\" | \"annoncé\" | \"devancé\" | \"amené\" | \"préludé\"\n",
    "Adposition5 -> \"par\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doucement |forward|termination|negated|10|Group[666]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Trigger_Rule\n",
    "Adverb1 -> \"doucement\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[666]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doux |forward|termination|negated|10|Group[666]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Trigger_Rule\n",
    "Adverb1 -> \"doux\"\n",
    "Trigger_Rule -> \"|forward|termination|negated|10|Group[666]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surveiller le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "veiller le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "inspecter le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "examiner le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "suivre le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "vérifier le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "avoir à l'oeil le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "être à l'affût le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "superviser le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "faire attention le \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Determiner2 Adjective3 Adposition6 Trigger_Rule\n",
    "Verb1 -> \"surveiller\" | \"veiller\" | \"inspecter\" | \"examiner\" | \"suivre\" | \"vérifier\" | \"avoir à l'oeil\" | \"être à l'affût\" | \"superviser\" | \"faire attention\"\n",
    "Determiner2 -> \"le\"\n",
    "Adjective3 -> \"\\\\w+\"\n",
    "Adposition6 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surveiller \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "veiller \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "inspecter \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "examiner \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "suivre \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "vérifier \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "avoir à l'oeil \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "être à l'affût \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "superviser \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n",
      "faire attention \\w+ pour |forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Adjective2 Adposition5 Trigger_Rule\n",
    "Verb1 -> \"surveiller\" | \"veiller\" | \"inspecter\" | \"examiner\" | \"suivre\" | \"vérifier\" | \"avoir à l'oeil\" | \"être à l'affût\" | \"superviser\" | \"faire attention\"\n",
    "Adjective2 -> \"\\\\w+\"\n",
    "Adposition5 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doit être exclu pour |forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\n",
      "doit être refusé pour |forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\n",
      "doit être repoussé pour |forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\n",
      "doit être rejeté pour |forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\n",
      "doit être éliminé pour |forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\n",
      "doit être proscrit pour |forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\n",
    "Verb1 -> \"doit\"\n",
    "Auxiliary2 -> \"être\"\n",
    "Verb3 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\n",
    "Adposition4 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doit être exclu |backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\n",
      "doit être refusé |backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\n",
      "doit être repoussé |backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\n",
      "doit être rejeté |backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\n",
      "doit être éliminé |backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\n",
      "doit être proscrit |backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\n",
    "Verb1 -> \"doit\"\n",
    "Auxiliary2 -> \"être\"\n",
    "Verb3 -> \"exclu\" | \"refusé\" | \"repoussé\" | \"rejeté\" | \"éliminé\" | \"proscrit\"\n",
    "Trigger_Rule -> \"|backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non |forward|trigger|negated|10|Group[680]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adverb1 Trigger_Rule\n",
    "Adverb1 -> \"non\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[680]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nég pour |forward|trigger|negated|10|Group[682]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Adposition2 Trigger_Rule\n",
    "Noun1 -> \"nég\"\n",
    "Adposition2 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[682]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nég. |backward|trigger|negated|10|Group[684]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Noun1 Trigger_Rule\n",
    "Noun1 -> \"nég.\"\n",
    "Trigger_Rule -> \"|backward|trigger|negated|10|Group[684]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "négatif pour |forward|trigger|negated|10|Group[686]|PRE-VALIDATION\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "\n",
    "cfg_grammar= \"\"\"\n",
    "S ->  Adjective1 Adposition2 Trigger_Rule\n",
    "Adjective1 -> \"négatif\"\n",
    "Adposition2 -> \"pour\"\n",
    "Trigger_Rule -> \"|forward|trigger|negated|10|Group[686]|PRE-VALIDATION\"\n",
    "\"\"\"\n",
    "\n",
    "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n",
    "    print(' '.join(sentence))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.7.2"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
