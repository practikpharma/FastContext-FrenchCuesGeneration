{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Verb2 Trigger_Rule\nAdverb1 -> \"pas\"\nVerb2 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[882]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Verb2 Trigger_Rule\nAdverb1 -> \"pas\"\nVerb2 -> \"vu\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[883]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Verb2 Trigger_Rule\nAdverb1 -> \"pas\"\nVerb2 -> \"r\u00e9soudre\" | \"d\u00e9terminer\" | \"trancher\" | \"solutionner\" | \"conclure\" | \"r\u00e9gler\" | \"trouver\" | \"r\u00e9silier\" | \"arr\u00eater\" | \"d\u00e9chiffrer\" | \"statuer\" | \"d\u00e9m\u00ealer\" | \"traiter\" | \"d\u00e9nouer\" | \"en finir\"\nTrigger_Rule -> \"|both|pseudo|negated|10|Group[885]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adverb2 Auxiliary3 Trigger_Rule\nAdverb1 -> \"ne\"\nAdverb2 -> \"pas\"\nAuxiliary3 -> \"\u00eatre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[886]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Auxiliary2 Verb3 Trigger_Rule\nPronoun1 -> \"c'\"\nAuxiliary2 -> \"est\"\nVerb3 -> \"not\u00e9\" | \"constat\u00e9\" | \"relev\u00e9\" | \"remarqu\u00e9\" | \"observ\u00e9\" | \"consign\u00e9\" | \"communiqu\u00e9\" | \"qualit\u00e9\" | \"transcrit\" | \"class\u00e9\" | \"\u00e9valu\u00e9\" | \"\u00e9tiquet\u00e9\" | \"estim\u00e9\" | \"mentionn\u00e9\" | \"coch\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[888, 889]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[888, 889]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adverb2 Trigger_Rule\nAdverb1 -> \"ne\"\nAdverb2 -> \"pas\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[891, 890]|PRE-VALIDATION\"|\"|forward|trigger|negated|20|Group[891, 890]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Verb2 Trigger_Rule\nAdverb1 -> \"maintenant\"\nVerb2 -> \"r\u00e9solu\" | \"d\u00e9cid\u00e9\" | \"solutionn\u00e9\" | \"fix\u00e9\" | \"conclu\" | \"trait\u00e9\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[892, 893]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[892, 893]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"origines\" | \"source\" | \"d\u00e9but\" | \"commencement\" | \"naissance\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"gen\u00e8se\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\" | \"motif\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[896]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"origine\" | \"d\u00e9but\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[896]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"origine\" | \"d\u00e9but\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[896]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"origines\" | \"source\" | \"d\u00e9but\" | \"commencement\" | \"naissance\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"gen\u00e8se\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\" | \"motif\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[896]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Adposition3 Trigger_Rule\nAdjective1 -> \"autres\"\nNoun2 -> \"possibilit\u00e9s\" | \"alternative\" | \"cas\" | \"hypoth\u00e8se\" | \"vraisemblance\" | \"potentiel\" | \"probabilit\u00e9\" | \"chance\" | \"plausibilit\u00e9\" | \"\u00e9ventuel\" | \"possible\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[900]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nVerb1 -> \"devrait\" | \"n\u00e9cessit\u00e9\" | \"avoir \u00e0\" | \"\u00eatre oblig\u00e9\" | \"\u00eatre tenu de\" | \"avoir besoin de\" | \"pourrait\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[901]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\nVerb1 -> \"devrait\" | \"n\u00e9cessit\u00e9\" | \"avoir \u00e0\" | \"\u00eatre oblig\u00e9\" | \"\u00eatre tenu de\" | \"avoir besoin de\" | \"pourrait\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[902]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Verb2 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nVerb2 -> \"pass\u00e9e\" | \"conclure\" | \"finie\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[903]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"ant\u00e9c\u00e9dents\" | \"ant\u00e9rieur\" | \"pr\u00e9alable\" | \"pr\u00e9existant\" | \"pass\u00e9\" | \"h\u00e9r\u00e9dit\u00e9\" | \"pr\u00e9curseur\" | \"pr\u00e9c\u00e9dente\" | \"ant\u00e9riorit\u00e9\" | \"pr\u00e9liminaire\" | \"condition\" | \"premier\" | \"antan\" | \"anciennet\u00e9\" | \"ant\u00e9c\u00e9dence\"\nAdjective2 -> \"m\u00e9dicaux\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[904]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nNoun1 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAuxiliary2 -> \"a\"\nVerb3 -> \"continu\u00e9\" | \"reconduire\" | \"perp\u00e9tuer\" | \"conserver\" | \"suivre\" | \"tenir\" | \"se poursuivre\" | \"donner suite\" | \"se perp\u00e9tuer\" | \"s'acharner\" | \"s'obstiner\" | \"entretenir\" | \"perdurer\" | \"opini\u00e2trer\" | \"ent\u00eater\"\nAdposition4 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[905]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adverb3 Auxiliary4 Adverb5 Trigger_Rule\nDeterminer1 -> \"le\"\nNoun2 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAdverb3 -> \"n'\"\nAuxiliary4 -> \"\u00e9tait\"\nAdverb5 -> \"pas\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[906]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"les\"\nNoun2 -> \"patients\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[908, 911]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[908, 911]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[908, 911]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[908, 911]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Noun2 Trigger_Rule\nVerb1 -> \"pauvre\" | \"faible\" | \"court\" | \"petit\" | \"modique\" | \"jeune\" | \"banal\"\nNoun2 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[912]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"poss\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[913]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"possibilit\u00e9\" | \"alternative\" | \"cas\" | \"hypoth\u00e8se\" | \"probabilit\u00e9\" | \"chance\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[913]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"peut-\u00eatre\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[913]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"possible\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[913, 914]|PRE-VALIDATION\"|\"|forward|trigger|conditional|30|Group[913, 914]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"pr\u00e9sente\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[918, 919]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[918, 919]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"en\"\nVerb2 -> \"pr\u00e9sentant\" | \"r\u00e9v\u00e9ler\" | \"exposer\" | \"\u00e9taler\" | \"constituer\" | \"afficher\" | \"exhiber\" | \"avancer\" | \"montrer\" | \"mettre en \u00e9vidence\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[918, 919]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[918, 919]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"probablement\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[922]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"Probablement\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[922]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"pr\u00e9sum\u00e9\" | \"soup\u00e7onner\" | \"estimer\" | \"conjecturer\" | \"pressentir\" | \"pr\u00e9sager\" | \"esp\u00e9rer\" | \"attendre\" | \"compter\" | \"pr\u00e9juger\" | \"pr\u00e9supposer\" | \"pr\u00e9tendre\" | \"pr\u00e9dire\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[923]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"ant\u00e9rieur\" | \"pr\u00e9c\u00e9dent\" | \"ant\u00e9c\u00e9dent\" | \"ant\u00e9pos\u00e9\" | \"pr\u00e9existant\" | \"ancien\" | \"premier\" | \"ant\u00e9nuptial\" | \"avant\" | \"pass\u00e9\" | \"pr\u00e9liminaire\" | \"plus ancien\" | \"ancienne\" | \"premi\u00e8re\" | \"ATCD\"\nAdposition2 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[924]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"prn\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[925]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Trigger_Rule\nAuxiliary1 -> \"prophylaxie\"\nTrigger_Rule -> \"|backward|trigger|conditional|10|Group[928]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"pt\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[929, 930]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[929, 930]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Auxiliary3 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"question\" | \"interpellation\" | \"information\"\nAuxiliary3 -> \"\u00e9tait\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[931]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"interrog\u00e9\" | \"demander\" | \"consulter\" | \"sonder\" | \"solliciter\" | \"interpeller\" | \"poser une question\" | \"s'informer\" | \"s'enqu\u00e9rir\" | \"auditionner\" | \"se demander\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[932]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adposition2 Trigger_Rule\nAdposition1 -> \"r\"\nAdposition2 -> \"o\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[933]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Subordinating_conjunction2 Trigger_Rule\nAdverb1 -> \"plut\u00f4t\"\nSubordinating_conjunction2 -> \"que\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[934]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"raisons\" | \"cause\" | \"pr\u00e9texte\" | \"justification\" | \"mobile\" | \"excuse\" | \"explication\" | \"rapport\" | \"fondement\" | \"all\u00e9gation\" | \"argument\" | \"d\u00e9monstration\" | \"indice\" | \"preuve\" | \"motivation\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[936]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"raison\" | \"cause\" | \"pourquoi\" | \"mobile\" | \"explication\" | \"fondement\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[936]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"raisons\" | \"cause\" | \"pr\u00e9texte\" | \"justification\" | \"mobile\" | \"excuse\" | \"explication\" | \"rapport\" | \"fondement\" | \"all\u00e9gation\" | \"argument\" | \"d\u00e9monstration\" | \"indice\" | \"preuve\" | \"motivation\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[936]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"raison\" | \"cause\" | \"pourquoi\" | \"mobile\" | \"explication\" | \"fondement\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[936]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"rapports\" | \"liaison\" | \"correspondance\" | \"connexion\" | \"lien\" | \"concordance\" | \"similitude\" | \"analogie\" | \"corr\u00e9lation\" | \"interd\u00e9pendance\" | \"attachement\" | \"encha\u00eenement\" | \"rapprochement\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[940, 941]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[940, 941]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"signal\u00e9\" | \"indiqu\u00e9\" | \"notifi\u00e9\" | \"d\u00e9couvert\" | \"montr\u00e9\" | \"d\u00e9voil\u00e9\" | \"soulign\u00e9\" | \"inform\u00e9\" | \"r\u00e9v\u00e9l\u00e9\" | \"signifi\u00e9\" | \"d\u00e9clar\u00e9\" | \"averti\" | \"rapport\u00e9\" | \"t\u00e9moign\u00e9\" | \"alert\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[940, 941]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[940, 941]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"r\u00e9solu\" | \"d\u00e9cid\u00e9\" | \"solutionn\u00e9\" | \"fix\u00e9\" | \"conclu\" | \"trait\u00e9\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[944]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"revenir\" | \"regagner\" | \"rentrer\" | \"repara\u00eetre\" | \"reprendre\" | \"repasser\" | \"recommencer\" | \"retomber\" | \"r\u00e9cidiver\" | \"retrouver\" | \"ressurgir\" | \"ressortir\" | \"reconduire\" | \"ramener\" | \"remettre\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[946]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"risque\" | \"dangereux\" | \"chance\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[947]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Verb2 Trigger_Rule\nNoun1 -> \"colocataires\"\nVerb2 -> \"appel\u00e9s\" | \"solliciter\" | \"requ\u00e9rir\" | \"t\u00e9l\u00e9phoner\" | \"avertir\" | \"pr\u00e9venir\" | \"alerter\" | \"signaler\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[948, 949]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[948, 949]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Auxiliary2 Trigger_Rule\nAdjective1 -> \"colocataire\"\nAuxiliary2 -> \"appel\u00e9e\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[948, 949]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[948, 949]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"colocataire\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[952]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"colocataires\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[952]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"ro\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[954]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Verb2 Trigger_Rule\nPronoun1 -> \"l'\"\nVerb2 -> \"\u00e9liminer\" | \"\u00e9carter\" | \"\u00e9vincer\" | \"exclure\" | \"chasser\" | \"proscrire\" | \"rejeter\" | \"repousser\" | \"enlever\" | \"\u00e9loigner\" | \"retirer\" | \"omettre\" | \"\u00f4ter\" | \"obmettre\" | \"r\u00e9cuser\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[955]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adposition3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[955]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"\u00e9liminer\" | \"\u00e9carter\" | \"\u00e9vincer\" | \"exclure\" | \"chasser\" | \"proscrire\" | \"rejeter\" | \"repousser\" | \"enlever\" | \"\u00e9loigner\" | \"retirer\" | \"omettre\" | \"\u00f4ter\" | \"obmettre\" | \"r\u00e9cuser\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[955]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[955]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Verb2 Adposition3 Trigger_Rule\nPronoun1 -> \"l'\"\nVerb2 -> \"\u00e9liminer\" | \"\u00e9carter\" | \"\u00e9vincer\" | \"exclure\" | \"chasser\" | \"proscrire\" | \"rejeter\" | \"repousser\" | \"enlever\" | \"\u00e9loigner\" | \"retirer\" | \"omettre\" | \"\u00f4ter\" | \"obmettre\" | \"r\u00e9cuser\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[955]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Determiner2 Noun3 Trigger_Rule\nNoun1 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nDeterminer2 -> \"le\"\nNoun3 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[961]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Determiner2 Noun3 Adposition4 Trigger_Rule\nNoun1 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nDeterminer2 -> \"la\"\nNoun3 -> \"patinet\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[961]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Trigger_Rule\nVerb1 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nAdposition2 -> \"contre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[975]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Trigger_Rule\nVerb1 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[977]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[979]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Determiner3 Noun4 Adposition5 Trigger_Rule\nAuxiliary1 -> \"a\"\nVerb2 -> \"jug\u00e9\" | \"prononcer\" | \"reconnu\" | \"not\u00e9\" | \"class\u00e9\" | \"\u00e9valu\u00e9\" | \"consid\u00e9r\u00e9\" | \"examin\u00e9\" | \"estim\u00e9\" | \"conclu\" | \"sond\u00e9\" | \"expertis\u00e9\" | \"entendu\" | \"trouv\u00e9\" | \"d\u00e9termin\u00e9\"\nDeterminer3 -> \"le\"\nNoun4 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAdposition5 -> \"contre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[981]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Determiner3 Noun4 Adposition5 Trigger_Rule\nAuxiliary1 -> \"a\"\nVerb2 -> \"jug\u00e9\" | \"prononcer\" | \"reconnu\" | \"not\u00e9\" | \"class\u00e9\" | \"\u00e9valu\u00e9\" | \"consid\u00e9r\u00e9\" | \"examin\u00e9\" | \"estim\u00e9\" | \"conclu\" | \"sond\u00e9\" | \"expertis\u00e9\" | \"entendu\" | \"trouv\u00e9\" | \"d\u00e9termin\u00e9\"\nDeterminer3 -> \"le\"\nNoun4 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAdposition5 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[983]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Noun3 Trigger_Rule\nVerb1 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nDeterminer2 -> \"le\"\nNoun3 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[985]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adposition3 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"chasse\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[987]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"chasse\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[989]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adposition3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"exclut\" | \"interdire\" | \"proscrire\" | \"\u00e9loigner\" | \"renvoyer\" | \"rejeter\" | \"\u00e9vincer\" | \"radier\" | \"\u00e9carter\" | \"emp\u00eacher\" | \"\u00e9cart\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[991]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"exclut\" | \"interdire\" | \"proscrire\" | \"\u00e9loigner\" | \"renvoyer\" | \"rejeter\" | \"\u00e9vincer\" | \"radier\" | \"\u00e9carter\" | \"emp\u00eacher\" | \"\u00e9cart\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[993]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Trigger_Rule\nVerb1 -> \"exclut\" | \"interdire\" | \"proscrire\" | \"\u00e9loigner\" | \"renvoyer\" | \"rejeter\" | \"\u00e9vincer\" | \"radier\" | \"\u00e9carter\" | \"emp\u00eacher\" | \"\u00e9cart\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[995]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"exclut\" | \"interdire\" | \"proscrire\" | \"\u00e9loigner\" | \"renvoyer\" | \"rejeter\" | \"\u00e9vincer\" | \"radier\" | \"\u00e9carter\" | \"emp\u00eacher\" | \"\u00e9cart\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[997]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Noun3 Adposition4 Trigger_Rule\nVerb1 -> \"exclut\" | \"interdire\" | \"proscrire\" | \"\u00e9loigner\" | \"renvoyer\" | \"rejeter\" | \"\u00e9vincer\" | \"radier\" | \"\u00e9carter\" | \"emp\u00eacher\" | \"\u00e9cart\"\nDeterminer2 -> \"le\"\nNoun3 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[999]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Noun3 Trigger_Rule\nVerb1 -> \"exclut\" | \"interdire\" | \"proscrire\" | \"\u00e9loigner\" | \"renvoyer\" | \"rejeter\" | \"\u00e9vincer\" | \"radier\" | \"\u00e9carter\" | \"emp\u00eacher\" | \"\u00e9cart\"\nDeterminer2 -> \"le\"\nNoun3 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1001]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"s\"\nNoun2 -> \"p\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[1003]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Trigger_Rule\nAdjective1 -> \"secondaire\"\nAdposition2 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1004]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"secondaire\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1004]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nPronoun1 -> \"elle\"\nAuxiliary2 -> \"a\"\nVerb3 -> \"continu\u00e9\" | \"reconduire\" | \"perp\u00e9tuer\" | \"conserver\" | \"suivre\" | \"tenir\" | \"se poursuivre\" | \"donner suite\" | \"se perp\u00e9tuer\" | \"s'acharner\" | \"s'obstiner\" | \"entretenir\" | \"perdurer\" | \"opini\u00e2trer\" | \"ent\u00eater\"\nAdposition4 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1006]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Punctuation2 Pronoun3 Trigger_Rule\nVerb1 -> \"devrait\" | \"n\u00e9cessit\u00e9\" | \"avoir \u00e0\" | \"\u00eatre oblig\u00e9\" | \"\u00eatre tenu de\" | \"avoir besoin de\" | \"pourrait\"\nPunctuation2 -> \"-\"\nPronoun3 -> \"il\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1009]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Punctuation2 Pronoun3 Trigger_Rule\nVerb1 -> \"devrait\" | \"n\u00e9cessit\u00e9\" | \"avoir \u00e0\" | \"\u00eatre oblig\u00e9\" | \"\u00eatre tenu de\" | \"avoir besoin de\" | \"pourrait\"\nPunctuation2 -> \"-\"\nPronoun3 -> \"elle\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1009]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Verb3 Punctuation4 Pronoun5 Trigger_Rule\nDeterminer1 -> \"le\"\nNoun2 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nVerb3 -> \"devrait\" | \"n\u00e9cessit\u00e9\" | \"avoir \u00e0\" | \"\u00eatre oblig\u00e9\" | \"\u00eatre tenu de\" | \"avoir besoin de\" | \"pourrait\"\nPunctuation4 -> \"-\"\nPronoun5 -> \"il\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1011]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Noun3 Adposition4 Trigger_Rule\nVerb1 -> \"montr\u00e9\" | \"affich\u00e9\" | \"exhibition\" | \"\u00e9tat\" | \"d\u00e9monstration\" | \"exposition\" | \"livr\u00e9\" | \"d\u00e9nud\u00e9\" | \"exhib\u00e9\" | \"d\u00e9not\u00e9\" | \"confirm\u00e9\" | \"expliqu\u00e9\" | \"d\u00e9couvert\" | \"affect\u00e9\" | \"d\u00e9voil\u00e9\"\nDeterminer2 -> \"une\"\nNoun3 -> \"question\" | \"interpellation\" | \"information\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1013]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Noun3 Adposition4 Trigger_Rule\nVerb1 -> \"montrer\" | \"indiquer\" | \"exposer\" | \"afficher\" | \"t\u00e9moigner\" | \"\u00e9tablir\" | \"d\u00e9montrer\" | \"signaler\" | \"prouver\" | \"manifester\" | \"repr\u00e9senter\" | \"r\u00e9v\u00e9ler\" | \"confirmer\" | \"attester\" | \"d\u00e9signer\"\nDeterminer2 -> \"une\"\nNoun3 -> \"question\" | \"interpellation\" | \"information\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1013]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"janvier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"juillet\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"septembre\" | \"Sept\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"ao\u00fbt\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"octobre\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"d\u00e9cembre\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"avril\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"Depuis\"\nNoun2 -> \"mai\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"novembre\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Trigger_Rule\nAdposition1 -> \"depuis\"\nDeterminer2 -> \"l'\"\nNoun3 -> \"\u00e9t\u00e9\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"juin\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"f\u00e9vrier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Trigger_Rule\nAdposition1 -> \"depuis\"\nDeterminer2 -> \"le\"\nNoun3 -> \"printemps\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"depuis\"\nNoun2 -> \"mars\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Trigger_Rule\nAdposition1 -> \"depuis\"\nDeterminer2 -> \"l'\"\nNoun3 -> \"hiver\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Trigger_Rule\nAdposition1 -> \"depuis\"\nDeterminer2 -> \"l'\"\nNoun3 -> \"automne\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[1015]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"s\u0153ur\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[1031]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"s\u0153urs\" | \"belle-s\u0153urs\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[1031]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}]}