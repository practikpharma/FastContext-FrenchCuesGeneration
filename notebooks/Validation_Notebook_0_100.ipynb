{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0\"\nNoun4 -> \"ann\u00e9e\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Adposition4 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0-mois\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Punctuation4 Noun5 Adposition6 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0\"\nPunctuation4 -> \"-\"\nNoun5 -> \"ann\u00e9es\"\nAdposition6 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Punctuation4 Noun5 Adposition6 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0\"\nPunctuation4 -> \"-\"\nNoun5 -> \"ann\u00e9e\"\nAdposition6 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Punctuation4 Noun5 Adposition6 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"13\"\nPunctuation4 -> \"-\"\nNoun5 -> \"jour\"\nAdposition6 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Pronoun3 Adposition4 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nPronoun3 -> \"13-jours\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"13\"\nNoun4 -> \"jours\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"1\"\nNoun4 -> \"semaines\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Punctuation4 Noun5 Adposition6 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0\"\nPunctuation4 -> \"-\"\nNoun5 -> \"mois\"\nAdposition6 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"13\"\nNoun4 -> \"jour\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0\"\nNoun4 -> \"mois\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"1\"\nNoun4 -> \"semaine\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0\"\nNoun4 -> \"-mois\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Punctuation4 Noun5 Adposition6 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"13\"\nPunctuation4 -> \"-\"\nNoun5 -> \"jours\"\nAdposition6 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Numeral3 Noun4 Adposition5 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \">\"\nNumeral3 -> \"0\"\nNoun4 -> \"ans\"\nAdposition5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[2]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Coordinating_conjunction2 Pronoun3 Pronoun4 Verb5 Numeral6 Noun7 Trigger_Rule\nAdjective1 -> \"\\\"\nCoordinating_conjunction2 -> \">\"\nPronoun3 -> \"Il\"\nPronoun4 -> \"y\"\nVerb5 -> \"a\"\nNumeral6 -> \"0\"\nNoun7 -> \"mois\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[4]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Coordinating_conjunction2 Pronoun3 Pronoun4 Verb5 Numeral6 Noun7 Trigger_Rule\nAdjective1 -> \"\\\"\nCoordinating_conjunction2 -> \">\"\nPronoun3 -> \"Il\"\nPronoun4 -> \"y\"\nVerb5 -> \"a\"\nNumeral6 -> \"0\"\nNoun7 -> \"an\" | \"ann\u00e9es\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[4]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Coordinating_conjunction2 Pronoun3 Pronoun4 Verb5 Numeral6 Noun7 Trigger_Rule\nAdjective1 -> \"\\\"\nCoordinating_conjunction2 -> \">\"\nPronoun3 -> \"Il\"\nPronoun4 -> \"y\"\nVerb5 -> \"a\"\nNumeral6 -> \"0\"\nNoun7 -> \"ans\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[4]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Coordinating_conjunction2 Pronoun3 Pronoun4 Verb5 Numeral6 Noun7 Trigger_Rule\nAdjective1 -> \"\\\"\nCoordinating_conjunction2 -> \">\"\nPronoun3 -> \"Il\"\nPronoun4 -> \"y\"\nVerb5 -> \"a\"\nNumeral6 -> \"1\"\nNoun7 -> \"semaine\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[4]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Punctuation1 Adverb2 Trigger_Rule\nPunctuation1 -> \":\"\nAdverb2 -> \"non\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[23]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Adposition3 Other4 Trigger_Rule\nAdjective1 -> \"\\\"\nNoun2 -> \"w\"\nAdposition3 -> \"+\"\nOther4 -> \"no\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[24]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"absence\" | \"manque\" | \"omission\" | \"privation\" | \"carence\" | \"d\u00e9faillance\" | \"d\u00e9fection\" | \"lacune\" | \"d\u00e9ficit\" | \"absent\" | \"d\u00e9ficience\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[26]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Determiner3 Trigger_Rule\nNoun1 -> \"absence\" | \"manque\" | \"omission\" | \"privation\" | \"carence\" | \"d\u00e9faillance\" | \"d\u00e9fection\" | \"lacune\" | \"d\u00e9ficit\" | \"absent\" | \"d\u00e9ficience\"\nAdposition2 -> \"d'\"\nDeterminer3 -> \"un\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[26]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Verb3 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nVerb3 -> \"\u00e9carter\" | \"rejeter\" | \"\u00e9liminer\" | \"isoler\" | \"\u00e9vincer\" | \"supprimer\" | \"proscrire\" | \"\u00f4ter\" | \"exclure\" | \"\u00e9loigner\" | \"renvoyer\" | \"refuser\" | \"se d\u00e9faire\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[30]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Determiner3 Noun4 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nDeterminer3 -> \"l'\"\nNoun4 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[30]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Pronoun3 Verb4 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nPronoun3 -> \"l'\"\nVerb4 -> \"\u00e9liminer\" | \"\u00e9carter\" | \"\u00e9vincer\" | \"exclure\" | \"chasser\" | \"proscrire\" | \"rejeter\" | \"repousser\" | \"enlever\" | \"\u00e9loigner\" | \"retirer\" | \"omettre\" | \"\u00f4ter\" | \"obmettre\" | \"r\u00e9cuser\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[30]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Noun3 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nNoun3 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[30]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Pronoun3 Verb4 Adposition5 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nPronoun3 -> \"l'\"\nVerb4 -> \"\u00e9liminer\" | \"\u00e9carter\" | \"\u00e9vincer\" | \"exclure\" | \"chasser\" | \"proscrire\" | \"rejeter\" | \"repousser\" | \"enlever\" | \"\u00e9loigner\" | \"retirer\" | \"omettre\" | \"\u00f4ter\" | \"obmettre\" | \"r\u00e9cuser\"\nAdposition5 -> \"contre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[30]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Noun3 Determiner4 Noun5 Trigger_Rule\nAdjective1 -> \"ad\u00e9quate\"\nAdposition2 -> \"pour\"\nNoun3 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nDeterminer4 -> \"le\"\nNoun5 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[42]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Verb3 Determiner4 Noun5 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nVerb3 -> \"\u00e9carter\" | \"rejeter\" | \"\u00e9liminer\" | \"isoler\" | \"\u00e9vincer\" | \"supprimer\" | \"proscrire\" | \"\u00f4ter\" | \"exclure\" | \"\u00e9loigner\" | \"renvoyer\" | \"refuser\" | \"se d\u00e9faire\"\nDeterminer4 -> \"le\"\nNoun5 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[42]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Verb3 Determiner4 Noun5 Adposition6 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nVerb3 -> \"\u00e9carter\" | \"rejeter\" | \"\u00e9liminer\" | \"isoler\" | \"\u00e9vincer\" | \"supprimer\" | \"proscrire\" | \"\u00f4ter\" | \"exclure\" | \"\u00e9loigner\" | \"renvoyer\" | \"refuser\" | \"se d\u00e9faire\"\nDeterminer4 -> \"le\"\nNoun5 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAdposition6 -> \"contre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[42]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Noun3 Determiner4 Noun5 Adposition6 Trigger_Rule\nVerb1 -> \"suffisant\" | \"passable\" | \"satisfaisant\" | \"supportable\" | \"raisonnable\" | \"acceptable\" | \"assez\" | \"correct\" | \"tol\u00e9rable\" | \"bon\" | \"pas mal\" | \"bien\" | \"ad\u00e9quat\" | \"assez bien\"\nAdposition2 -> \"pour\"\nNoun3 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nDeterminer4 -> \"le\"\nNoun5 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAdposition6 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[42]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"apr\u00e8s\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[47]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Subordinating_conjunction2 Trigger_Rule\nAdverb1 -> \"bien\"\nSubordinating_conjunction2 -> \"que\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[48]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"Presente\"\nAdposition2 -> \"avec\"\nTrigger_Rule -> \"|forward|termination|historical|10|Group[51, 49]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[51, 49]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Trigger_Rule\nAdjective1 -> \"pr\u00e9sente\"\nAdposition2 -> \"avec\"\nTrigger_Rule -> \"|forward|termination|historical|10|Group[51, 49]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[51, 49]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Adjective2 Noun3 Adposition4 Adjective5 Noun6 Adposition7 Noun8 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nAdjective5 -> \"\\\"\nNoun6 -> \"w\"\nAdposition7 -> \"+\"\nNoun8 -> \"show\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[53]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Adjective2 Adposition3 Determiner4 Noun5 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAdjective2 -> \"\\\"\nAdposition3 -> \"w\"\nDeterminer4 -> \"+\"\nNoun5 -> \"spectacles\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[53]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Adjective2 Noun3 Adposition4 Adjective5 Noun6 Adposition7 Noun8 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nAdjective5 -> \"\\\"\nNoun6 -> \"w\"\nAdposition7 -> \"+\"\nNoun8 -> \"affich\u00e9s\" | \"annoncer\" | \"indiquer\" | \"d\u00e9clarer\" | \"montrer\" | \"manifester\" | \"exprimer\" | \"r\u00e9v\u00e9ler\" | \"exhiber\" | \"marquer\" | \"t\u00e9moigner\" | \"affirmer\" | \"prouver\" | \"d\u00e9velopper\" | \"repr\u00e9senter\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[53]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"show\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[53]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Adjective2 Noun3 Adposition4 Verb5 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nVerb5 -> \"affich\u00e9\" | \"\u00e9tal\u00e9\" | \"expos\u00e9\" | \"pr\u00e9sent\u00e9\" | \"t\u00e9moign\u00e9\" | \"marqu\u00e9\" | \"d\u00e9crit\" | \"exhib\u00e9\" | \"d\u00e9couvert\" | \"affect\u00e9\" | \"exprim\u00e9\" | \"produit\" | \"d\u00e9montr\u00e9\" | \"d\u00e9voil\u00e9\" | \"manifest\u00e9\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[53]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Adjective2 Noun3 Adposition4 Adjective5 Noun6 Determiner7 Noun8 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nAdjective5 -> \"\\\"\nNoun6 -> \"w\"\nDeterminer7 -> \"+\"\nNoun8 -> \"spectacles\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[53]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Auxiliary2 Verb3 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAuxiliary2 -> \"a\"\nVerb3 -> \"fait\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[59]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Pronoun2 Auxiliary3 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nPronoun2 -> \"il\"\nAuxiliary3 -> \"avait\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[60]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Pronoun2 Auxiliary3 Auxiliary4 Verb5 Adposition6 Verb7 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nPronoun2 -> \"il\"\nAuxiliary3 -> \"a\"\nAuxiliary4 -> \"\u00e9t\u00e9\"\nVerb5 -> \"not\u00e9\" | \"constat\u00e9\" | \"relev\u00e9\" | \"remarqu\u00e9\" | \"observ\u00e9\" | \"consign\u00e9\" | \"communiqu\u00e9\" | \"qualit\u00e9\" | \"transcrit\" | \"class\u00e9\" | \"\u00e9valu\u00e9\" | \"\u00e9tiquet\u00e9\" | \"estim\u00e9\" | \"mentionn\u00e9\" | \"coch\u00e9\"\nAdposition6 -> \"pour\"\nVerb7 -> \"avoir\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[61]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Pronoun2 Auxiliary3 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nPronoun2 -> \"il\"\nAuxiliary3 -> \"\u00e9tait\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[62]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Verb2 Adposition3 Verb4 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nVerb2 -> \"not\u00e9\" | \"constat\u00e9\" | \"relev\u00e9\" | \"remarqu\u00e9\" | \"observ\u00e9\" | \"consign\u00e9\" | \"communiqu\u00e9\" | \"qualit\u00e9\" | \"transcrit\" | \"class\u00e9\" | \"\u00e9valu\u00e9\" | \"\u00e9tiquet\u00e9\" | \"estim\u00e9\" | \"mentionn\u00e9\" | \"coch\u00e9\"\nAdposition3 -> \"d'\"\nVerb4 -> \"avoir\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[63]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Pronoun2 Auxiliary3 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nPronoun2 -> \"elle\"\nAuxiliary3 -> \"avait\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[64]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Pronoun2 Auxiliary3 Auxiliary4 Verb5 Adposition6 Verb7 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nPronoun2 -> \"elle\"\nAuxiliary3 -> \"a\"\nAuxiliary4 -> \"\u00e9t\u00e9\"\nVerb5 -> \"not\u00e9e\" | \"observer\" | \"relever\" | \"mentionner\" | \"annoter\" | \"constater\" | \"souligner\" | \"\u00e9tiqueter\" | \"\u00e9valuer\" | \"classer\" | \"juger\" | \"commenter\"\nAdposition6 -> \"pour\"\nVerb7 -> \"avoir\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[65]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Pronoun2 Auxiliary3 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nPronoun2 -> \"elle\"\nAuxiliary3 -> \"\u00e9tait\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[66]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Determiner2 Noun3 Auxiliary4 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nDeterminer2 -> \"le\"\nNoun3 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAuxiliary4 -> \"avait\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[67]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Determiner2 Noun3 Auxiliary4 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nDeterminer2 -> \"le\"\nNoun3 -> \"patient\" | \"client\" | \"souffrant\" | \"sujet\"\nAuxiliary4 -> \"\u00e9tait\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[68]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Adposition2 Adverb3 Trigger_Rule\nCoordinating_conjunction1 -> \"et\"\nAdposition2 -> \"avec\"\nAdverb3 -> \"seulement\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[69]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adjective2 Trigger_Rule\nAdverb1 -> \"tout\"\nAdjective2 -> \"autre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[71]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"#\"\nAdjective2 -> \"tout\"\nTrigger_Rule -> \"|forward|trigger|negated|13|Group[72]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"Except\u00e9\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[73]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"semble\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[74]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adjective2 Trigger_Rule\nAuxiliary1 -> \"sont\"\nAdjective2 -> \"n\u00e9gatifs\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[75]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Auxiliary2 Adverb3 Trigger_Rule\nAdverb1 -> \"ne\"\nAuxiliary2 -> \"sont\"\nAdverb3 -> \"plus\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[77]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adjective2 Trigger_Rule\nAuxiliary1 -> \"sont\"\nAdjective2 -> \"exclus\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[79]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"sont\"\nVerb2 -> \"arr\u00eat\u00e9s\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"immobiliser\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"geler\" | \"couper\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[81]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"origine\" | \"d\u00e9but\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nDeterminer2 -> \"une\"\nNoun3 -> \"\u00e9tiologie\" | \"\u00e9tiologie\" | \"\u00e9tiopathie\" | \"causalit\u00e9\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"source\" | \"provenance\" | \"commencement\" | \"cause\" | \"fondement\" | \"d\u00e9but\" | \"point de d\u00e9part\" | \"source\" | \"d\u00e9part\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"cause\" | \"raison\" | \"pr\u00e9texte\" | \"fondement\" | \"source\" | \"intention\" | \"origine\" | \"but\" | \"d\u00e9clencheur\" | \"d\u00e9part\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nDeterminer2 -> \"une\"\nNoun3 -> \"cause\" | \"raison\" | \"pr\u00e9texte\" | \"fondement\" | \"source\" | \"intention\" | \"origine\" | \"but\" | \"d\u00e9clencheur\" | \"d\u00e9part\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adposition2 Trigger_Rule\nAdposition1 -> \"comme\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nDeterminer2 -> \"l'\"\nNoun3 -> \"\u00e9tiologie\" | \"\u00e9tiologie\" | \"\u00e9tiopathie\" | \"causalit\u00e9\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"origine\" | \"d\u00e9but\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"raison\" | \"cause\" | \"pourquoi\" | \"mobile\" | \"explication\" | \"fondement\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nDeterminer2 -> \"une\"\nNoun3 -> \"\u00e9tiologie\" | \"\u00e9tiologie\" | \"\u00e9tiopathie\" | \"causalit\u00e9\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nDeterminer2 -> \"une\"\nNoun3 -> \"raison\" | \"cause\" | \"pourquoi\" | \"mobile\" | \"explication\" | \"fondement\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[84]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"origine\" | \"d\u00e9but\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"raison\" | \"cause\" | \"pourquoi\" | \"mobile\" | \"explication\" | \"fondement\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"origine\" | \"d\u00e9but\" | \"commencement\" | \"provenance\" | \"cause\" | \"formation\" | \"base\" | \"fondement\" | \"pr\u00e9d\u00e9terminant\" | \"raison\" | \"d\u00e9part\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"\u00e9tiologie\" | \"\u00e9tiologie\" | \"\u00e9tiopathie\" | \"causalit\u00e9\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"\u00e9tiologie\" | \"\u00e9tiologie\" | \"\u00e9tiopathie\" | \"causalit\u00e9\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"source\" | \"provenance\" | \"commencement\" | \"cause\" | \"fondement\" | \"d\u00e9but\" | \"point de d\u00e9part\" | \"source\" | \"d\u00e9part\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"source\" | \"provenance\" | \"commencement\" | \"cause\" | \"fondement\" | \"d\u00e9but\" | \"point de d\u00e9part\" | \"source\" | \"d\u00e9part\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adjective3 Adposition4 Trigger_Rule\nAdposition1 -> \"comme\"\nNoun2 -> \"cause\" | \"raison\" | \"pr\u00e9texte\" | \"fondement\" | \"source\" | \"intention\" | \"origine\" | \"but\" | \"d\u00e9clencheur\" | \"d\u00e9part\"\nAdjective3 -> \"secondaire\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[90]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"comme\"\nVerb2 -> \"a\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[122]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"comme\"\nVerb2 -> \"requis\" | \"n\u00e9cessaire\" | \"prescrit\" | \"demand\u00e9\" | \"r\u00e9clam\u00e9\" | \"oblig\u00e9\" | \"impos\u00e9\" | \"exig\u00e9\" | \"souhaitable\" | \"sollicit\u00e9\" | \"indispensable\" | \"command\u00e9\" | \"n\u00e9cessit\u00e9\" | \"souhait\u00e9\" | \"enjoint\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[123]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Subordinating_conjunction2 Pronoun3 Trigger_Rule\nAdverb1 -> \"ainsi\"\nSubordinating_conjunction2 -> \"que\"\nPronoun3 -> \"tout\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[144]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"\u00e0\"\nNoun2 -> \"part\" | \"morceau\" | \"fragment\" | \"portion\" | \"participation\" | \"division\" | \"fraction\" | \"partage\" | \"ration\" | \"lot\" | \"quota\" | \"quotit\u00e9\" | \"quote-part\" | \"quotepart\" | \"pourcentage\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[146]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"comme\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[147]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Trigger_Rule\nAdposition1 -> \"en\"\nDeterminer2 -> \"ce\"\nNoun3 -> \"moment\" | \"jour\" | \"temps\" | \"saison\" | \"\u00e9poque\" | \"stage\" | \"\u00e9pisode\" | \"phase\" | \"plage de temps\" | \"stade\" | \"pendant que\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[148]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Punctuation4 Adverb5 Trigger_Rule\nAdposition1 -> \"\u00e0\"\nDeterminer2 -> \"ce\"\nNoun3 -> \"moment\" | \"jour\" | \"temps\" | \"saison\" | \"\u00e9poque\" | \"stage\" | \"\u00e9pisode\" | \"phase\" | \"plage de temps\" | \"stade\" | \"pendant que\"\nPunctuation4 -> \"-\"\nAdverb5 -> \"l\u00e0\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[148]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"tent\u00e9\" | \"exp\u00e9riment\u00e9\" | \"risqu\u00e9\" | \"cherch\u00e9\" | \"entrepris\" | \"os\u00e9\" | \"hasarder\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[150, 151]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[150, 151]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"tentative\" | \"exp\u00e9rience\" | \"exp\u00e9rimentation\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[152, 153]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[152, 153]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"tante\" | \"tatie\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[154]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"tante\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[154]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Adposition3 Trigger_Rule\nAuxiliary1 -> \"\u00eatre\"\nVerb2 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[156]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"\u00eatre\"\nVerb2 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[157]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"\u00eatre\"\nVerb2 -> \"arr\u00eat\u00e9\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"interrompre\" | \"mettre fin\" | \"geler\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[158, 159]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[158, 159]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Subordinating_conjunction1 Subordinating_conjunction2 Trigger_Rule\nSubordinating_conjunction1 -> \"parce\"\nSubordinating_conjunction2 -> \"que\"\nTrigger_Rule -> \"|both|termination|conditional|30|Group[160]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"au-del\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[162]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"biopsie\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[163]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"limite\" | \"seuil\" | \"serr\u00e9\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[164]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"fr\u00e8res\" | \"cousin\" | \"famille\" | \"parents\" | \"fr\u00e8re\" | \"fratrie\" | \"frere\" | \"s\u0153ur\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[165]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"fr\u00e8re\" | \"cousin\" | \"fratrie\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[167]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Coordinating_conjunction1 Trigger_Rule\nCoordinating_conjunction1 -> \"mais\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[168, 169]|PRE-VALIDATION\"|\"|backward|termination|negated|10|Group[168, 169]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}]}