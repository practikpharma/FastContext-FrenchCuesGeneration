{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 301\n", "#  French Term     : du grand-p\u00e8re\n", "#  English Term(s) : [\"grandfather's\"]\n", "#  Index(es)       : [605]\n", "#  Grouping(s)     : [551]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"du\"\nNoun2 -> \"grand-p\u00e8re\" | \"a\u00efeul\" | \"papi\" | \"papy\" | \"vieillard\" | \"p\u00e9p\u00e8re\" | \"grand-papa\" | \"bon-papa\" | \"pap\u00e9\" | \"grand-p\u00e8re\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 302\n", "#  French Term     : grand-m\u00e8re\n", "#  English Term(s) : ['grandmother']\n", "#  Index(es)       : [608]\n", "#  Grouping(s)     : [551]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"grand-m\u00e8re\" | \"a\u00efeule\" | \"mamie\" | \"m\u00e9m\u00e8re\" | \"grannie\" | \"mamita\" | \"vieille\" | \"bonne-maman\" | \"grand-maman\" | \"grand\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 303\n", "#  French Term     : grand-p\u00e8re\n", "#  English Term(s) : ['grandfather']\n", "#  Index(es)       : [606]\n", "#  Grouping(s)     : [551]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"grand-p\u00e8re\" | \"a\u00efeul\" | \"papi\" | \"papy\" | \"vieillard\" | \"p\u00e9p\u00e8re\" | \"grand-papa\" | \"bon-papa\" | \"pap\u00e9\" | \"grand-p\u00e8re\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 304\n", "#  French Term     : la grand-m\u00e8re\n", "#  English Term(s) : [\"grandmother's\"]\n", "#  Index(es)       : [607]\n", "#  Grouping(s)     : [551]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"grand-m\u00e8re\" | \"a\u00efeule\" | \"mamie\" | \"m\u00e9m\u00e8re\" | \"grannie\" | \"mamita\" | \"vieille\" | \"bonne-maman\" | \"grand-maman\" | \"grand\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 305\n", "#  French Term     : h o\n", "#  English Term(s) : ['h o']\n", "#  Index(es)       : [609, 610]\n", "#  Grouping(s)     : [555, 556]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Noun2 Trigger_Rule\nNoun1 -> \"h\" | \"\u00e2ge\" | \"p\u00e9riode\" | \"tant\u00f4t\" | \"constante de Planck\" | \"h\" | \"moment\" | \"jours\" | \"liturgie\" | \"instant\"\nNoun2 -> \"o\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[555, 556]\" |\"|forward|trigger|nonpatient|30|Group[555, 556]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 306\n", "#  French Term     : avait un \\ w + n\u00e9gatif pour\n", "#  English Term(s) : ['had a negative \\\\w+ for']\n", "#  Index(es)       : [611]\n", "#  Grouping(s)     : [557]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Adposition4 Adposition5 Adjective6 Adposition7 Trigger_Rule\nVerb1 -> \"avait\"\nDeterminer2 -> \"un\"\nAdjective3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nAdjective6 -> \"n\u00e9gatif\"\nAdposition7 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[557]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 307\n", "#  French Term     : a un \\ w + n\u00e9gatif pour\n", "#  English Term(s) : ['has a negative \\\\w+ for']\n", "#  Index(es)       : [612]\n", "#  Grouping(s)     : [557]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Adposition4 Adposition5 Adjective6 Adposition7 Trigger_Rule\nVerb1 -> \"a\"\nDeterminer2 -> \"un\"\nAdjective3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nAdjective6 -> \"n\u00e9gatif\"\nAdposition7 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[557]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 308\n", "#  French Term     : a \u00e9t\u00e9 n\u00e9gatif\n", "#  English Term(s) : ['has been negative']\n", "#  Index(es)       : [615]\n", "#  Grouping(s)     : [561]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Adjective3 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nAdjective3 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[561]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 309\n", "#  French Term     : a \u00e9t\u00e9 exclu\n", "#  English Term(s) : ['has been ruled out', 'was ruled out']\n", "#  Index(es)       : [616, 619]\n", "#  Grouping(s)     : [561, 563]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"exclu\" | \"exclusivement\" | \"expuls\u00e9\" | \"paria\" | \"renvoy\u00e9\" | \"prohib\u00e9\" | \"refus\u00e9\" | \"chass\u00e9\" | \"\u00e9conduit\" | \"inenvisageable\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[561, 563]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 310\n", "#  French Term     : n'a pas eu de\n", "#  English Term(s) : ['has not had any']\n", "#  Index(es)       : [621]\n", "#  Grouping(s)     : [569]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Auxiliary2 Adverb3 Verb4 Determiner5 Trigger_Rule\nAdverb1 -> \"n'\"\nAuxiliary2 -> \"a\"\nAdverb3 -> \"pas\"\nVerb4 -> \"eu\"\nDeterminer5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[569]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 311\n", "#  French Term     : avoir un \\ w + n\u00e9gatif pour\n", "#  English Term(s) : ['have a negative \\\\w+ for']\n", "#  Index(es)       : [623]\n", "#  Grouping(s)     : [571]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Adposition4 Adposition5 Adjective6 Adposition7 Trigger_Rule\nVerb1 -> \"avoir\"\nDeterminer2 -> \"un\"\nAdjective3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nAdjective6 -> \"n\u00e9gatif\"\nAdposition7 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[571]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 312\n", "#  French Term     : ont \u00e9t\u00e9 \u00e9cart\u00e9s\n", "#  English Term(s) : ['have been ruled out']\n", "#  Index(es)       : [625]\n", "#  Grouping(s)     : [573]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"ont\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"\u00e9cart\u00e9s\" | \"d\u00e9tourner\" | \"d\u00e9vier\" | \"s\u00e9parer\" | \"rejeter\" | \"chasser\" | \"bannir\" | \"exiler\" | \"\u00e9liminer\" | \"proscrire\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[573]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 313\n", "#  French Term     : il a continu\u00e9 \u00e0\n", "#  English Term(s) : ['he continued to']\n", "#  Index(es)       : [627]\n", "#  Grouping(s)     : [575]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nPronoun1 -> \"il\"\nAuxiliary2 -> \"a\"\nVerb3 -> \"continu\u00e9\" | \"pers\u00e9v\u00e9rer\" | \"prolonger\" | \"persister\" | \"demeurer\" | \"survivre\" | \"subsister\" | \"durer\" | \"\u00e9tendre\" | \"maintenir\"\nAdposition4 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[575]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 314\n", "#  French Term     : son vieux\n", "#  English Term(s) : ['her old', 'his old']\n", "#  Index(es)       : [628, 629]\n", "#  Grouping(s)     : [576]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"son\"\nNoun2 -> \"vieux\" | \"ancien\" | \"\u00e2g\u00e9\" | \"d\u00e9pass\u00e9\" | \"us\u00e9\" | \"vieillot\" | \"d\u00e9mod\u00e9\" | \"v\u00e9tuste\" | \"antique\" | \"surann\u00e9\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[576]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 315\n", "#  French Term     : histoire physique\n", "#  English Term(s) : ['history physical']\n", "#  Index(es)       : [636]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nAdjective2 -> \"physique\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 316\n", "#  French Term     : histoire de plainte principale\n", "#  English Term(s) : ['history of chief complaint']\n", "#  Index(es)       : [634]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Noun3 Adjective4 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nAdposition2 -> \"de\"\nNoun3 -> \"plainte\" | \"grief\" | \"complainte\" | \"j\u00e9r\u00e9miade\" | \"pleur\" | \"hurlement\" | \"cri\" | \"lamentation\" | \"g\u00e9missement\" | \"criaillerie\"\nAdjective4 -> \"principale\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 317\n", "#  French Term     : histoire et physique\n", "#  English Term(s) : ['history and physical']\n", "#  Index(es)       : [631]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Coordinating_conjunction2 Adjective3 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nCoordinating_conjunction2 -> \"et\"\nAdjective3 -> \"physique\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 318\n", "#  French Term     : histoire et\n", "#  English Term(s) : ['history and']\n", "#  Index(es)       : [632]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Coordinating_conjunction2 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nCoordinating_conjunction2 -> \"et\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 319\n", "#  French Term     : histoire pour\n", "#  English Term(s) : ['history for']\n", "#  Index(es)       : [633]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 320\n", "#  French Term     : histoire et examen\n", "#  English Term(s) : ['history and examination']\n", "#  Index(es)       : [630]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Coordinating_conjunction2 Noun3 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nCoordinating_conjunction2 -> \"et\"\nNoun3 -> \"examen\" | \"analyse\" | \"essai\" | \"\u00e9tude\" | \"v\u00e9rification\" | \"exploration\" | \"enqu\u00eate\" | \"inspection\" | \"observation\" | \"investigation\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 321\n", "#  French Term     : histoire de la maladie actuelle\n", "#  English Term(s) : ['history of present illness']\n", "#  Index(es)       : [635]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Determiner3 Noun4 Adjective5 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nAdposition2 -> \"de\"\nDeterminer3 -> \"la\"\nNoun4 -> \"maladie\" | \"mal\" | \"indisposition\" | \"souffrance\" | \"manie\" | \"affection\" | \"syndrome\" | \"travers\" | \"passion\" | \"tare\"\nAdjective5 -> \"actuelle\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 322\n", "#  French Term     : histoire prenant\n", "#  English Term(s) : ['history taking']\n", "#  Index(es)       : [637]\n", "#  Grouping(s)     : [578]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Verb2 Trigger_Rule\nNoun1 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nVerb2 -> \"prenant\" | \"attachant\" | \"attrayant\" | \"fascinant\" | \"passionnant\" | \"empoignant\" | \"int\u00e9ressant\" | \"attirant\" | \"dramatique\" | \"palpitant\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 323\n", "#  French Term     : #l'histoire\n", "#  English Term(s) : ['#history']\n", "#  Index(es)       : [638]\n", "#  Grouping(s)     : [586]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Determiner2 Noun3 Trigger_Rule\nNoun1 -> \"#\"\nDeterminer2 -> \"l'\"\nNoun3 -> \"histoire\" | \"conte\" | \"mensonge\" | \"annales\" | \"chronique\" | \"aventure\" | \"anecdote\" | \"description\" | \"l\u00e9gende\" | \"fastes\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[586]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 324\n", "#  French Term     : toutefois\n", "#  English Term(s) : ['however']\n", "#  Index(es)       : [639]\n", "#  Grouping(s)     : [587]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"toutefois\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[587]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 325\n", "#  French Term     : ho\n", "#  English Term(s) : ['ho']\n", "#  Index(es)       : [640]\n", "#  Grouping(s)     : [588]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"ho\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[588]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 326\n", "#  French Term     : hx\n", "#  English Term(s) : ['hx']\n", "#  Index(es)       : [641]\n", "#  Grouping(s)     : [589]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"hx\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[589]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 327\n", "#  French Term     : si n\u00e9gatif\n", "#  English Term(s) : ['if negative']\n", "#  Index(es)       : [642]\n", "#  Grouping(s)     : [590]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Subordinating_conjunction1 Adjective2 Trigger_Rule\nSubordinating_conjunction1 -> \"si\"\nAdjective2 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|both|pseudo|conditional|30|Group[590]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 328\n", "#  French Term     : si\n", "#  English Term(s) : ['if']\n", "#  Index(es)       : [643]\n", "#  Grouping(s)     : [591]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Subordinating_conjunction1 Trigger_Rule\nSubordinating_conjunction1 -> \"si\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[591]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 329\n", "#  French Term     : en elle\n", "#  English Term(s) : ['in her']\n", "#  Index(es)       : [644]\n", "#  Grouping(s)     : [592]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Pronoun2 Trigger_Rule\nAdposition1 -> \"en\"\nPronoun2 -> \"elle\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[592]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 330\n", "#  French Term     : dans son\n", "#  English Term(s) : ['in his']\n", "#  Index(es)       : [645]\n", "#  Grouping(s)     : [593]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Trigger_Rule\nAdposition1 -> \"dans\"\nDeterminer2 -> \"son\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[593]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 331\n", "#  French Term     : autrefois\n", "#  English Term(s) : ['in the past']\n", "#  Index(es)       : [646]\n", "#  Grouping(s)     : [594]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"autrefois\"\nTrigger_Rule -> \"|both|trigger|historical|30|Group[594]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 332\n", "#  French Term     : dans le contexte de\n", "#  English Term(s) : ['in the setting of']\n", "#  Index(es)       : [647]\n", "#  Grouping(s)     : [595]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"dans\"\nDeterminer2 -> \"le\"\nNoun3 -> \"contexte\" | \"texte\" | \"donn\u00e9e\" | \"situation\" | \"environnement\" | \"teneur\" | \"encadrement\" | \"circonstance\" | \"cadre\" | \"concordance\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[595]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 333\n", "#  French Term     : incompatible avec\n", "#  English Term(s) : ['inconsistent with']\n", "#  Index(es)       : [648]\n", "#  Grouping(s)     : [596]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Trigger_Rule\nAdjective1 -> \"incompatible\"\nAdposition2 -> \"avec\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[596]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 334\n", "#  French Term     : indication\n", "#  English Term(s) : ['indication']\n", "#  Index(es)       : [650]\n", "#  Grouping(s)     : [598]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"indication\" | \"renseignement\" | \"avis\" | \"indice\" | \"annonce\" | \"recommandation\" | \"note\" | \"directive\" | \"crit\u00e8re\" | \"prescription\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[598]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 335\n", "#  French Term     : est n\u00e9gatif\n", "#  English Term(s) : ['is negative']\n", "#  Index(es)       : [651]\n", "#  Grouping(s)     : [599]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adjective2 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdjective2 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[599]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 336\n", "#  French Term     : est neg\n", "#  English Term(s) : ['is neg']\n", "#  Index(es)       : [653]\n", "#  Grouping(s)     : [601]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adverb2 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdverb2 -> \"neg\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[601]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 337\n", "#  French Term     : n'est plus\n", "#  English Term(s) : ['is no longer']\n", "#  Index(es)       : [655]\n", "#  Grouping(s)     : [603]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Verb2 Adverb3 Trigger_Rule\nAdverb1 -> \"n'\"\nVerb2 -> \"est\"\nAdverb3 -> \"plus\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[603]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 338\n", "#  French Term     : n'est pas\n", "#  English Term(s) : ['is not', \"isn't\"]\n", "#  Index(es)       : [657, 658]\n", "#  Grouping(s)     : [605]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Auxiliary2 Adverb3 Trigger_Rule\nAdverb1 -> \"n'\"\nAuxiliary2 -> \"est\"\nAdverb3 -> \"pas\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[605]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 339\n", "#  French Term     : est exclu\n", "#  English Term(s) : ['is ruled out']\n", "#  Index(es)       : [661]\n", "#  Grouping(s)     : [607]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"est\"\nVerb2 -> \"exclu\" | \"exclusivement\" | \"expuls\u00e9\" | \"paria\" | \"renvoy\u00e9\" | \"prohib\u00e9\" | \"refus\u00e9\" | \"chass\u00e9\" | \"\u00e9conduit\" | \"inenvisageable\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[607]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 340\n", "#  French Term     : est arr\u00eat\u00e9\n", "#  English Term(s) : ['is stopped']\n", "#  Index(es)       : [663]\n", "#  Grouping(s)     : [609]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"est\"\nVerb2 -> \"arr\u00eat\u00e9\" | \"bloquer\" | \"suspendre\" | \"paralyser\" | \"endiguer\" | \"terminer\" | \"enrayer\" | \"saisir\" | \"\u00e9touffer\" | \"prendre\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[609]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 341\n", "#  French Term     : est \u00e0 exclure pour\n", "#  English Term(s) : ['is to be ruled out for']\n", "#  Index(es)       : [665]\n", "#  Grouping(s)     : [611]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adposition2 Noun3 Adposition4 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdposition2 -> \"\u00e0\"\nNoun3 -> \"exclure\" | \"expulser\" | \"\u00e9carter\" | \"renvoyer\" | \"repousser\" | \"rejeter\" | \"chasser\" | \"retrancher\" | \"excepter\" | \"bannir\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[611]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 342\n", "#  French Term     : est \u00e0 exclure\n", "#  English Term(s) : ['is to be ruled out']\n", "#  Index(es)       : [666]\n", "#  Grouping(s)     : [612]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adposition2 Noun3 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdposition2 -> \"\u00e0\"\nNoun3 -> \"exclure\" | \"expulser\" | \"\u00e9carter\" | \"renvoyer\" | \"repousser\" | \"rejeter\" | \"chasser\" | \"retrancher\" | \"excepter\" | \"bannir\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[612]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 343\n", "#  French Term     : manque de\n", "#  English Term(s) : ['lack of']\n", "#  Index(es)       : [667]\n", "#  Grouping(s)     : [615]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"manque\" | \"absence\" | \"privation\" | \"d\u00e9ficience\" | \"p\u00e9nurie\" | \"carence\" | \"insuffisance\" | \"disette\" | \"manquement\" | \"omission\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[615]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 344\n", "#  French Term     : manquait\n", "#  English Term(s) : ['lacked']\n", "#  Index(es)       : [669]\n", "#  Grouping(s)     : [617]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"manquait\" | \"torcher\" | \"enfreindre\" | \"omettre\" | \"risquer\" | \"tomber\" | \"perdre\" | \"louper\" | \"transiger\" | \"offenser\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[617]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 345\n", "#  French Term     : Le printemps dernier\n", "#  English Term(s) : ['last spring']\n", "#  Index(es)       : [691]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"Le\"\nNoun2 -> \"printemps\" | \"avril\" | \"renaissance\" | \"jeunesse\" | \"an\" | \"belle saison\" | \"\u00e2ge\" | \"saison\" | \"jeune\" | \"source\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 346\n", "#  French Term     : dernier \\> 0 ann\u00e9e\n", "#  English Term(s) : ['last \\\\> 0 year ago']\n", "#  Index(es)       : [673]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Coordinating_conjunction3 Numeral4 Noun5 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nCoordinating_conjunction3 -> \">\"\nNumeral4 -> \"0\"\nNoun5 -> \"ann\u00e9e\" | \"date\" | \"an\" | \"berge\" | \"promotion\" | \"cuv\u00e9e\" | \"mill\u00e9sime\" | \"dur\u00e9e\" | \"annuit\u00e9s\" | \"annualit\u00e9\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 347\n", "#  French Term     : f\u00e9vrier dernier\n", "#  English Term(s) : ['last february']\n", "#  Index(es)       : [682]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"f\u00e9vrier\" | \"f\u00e9vrier\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 348\n", "#  French Term     : dernier \\> il y a 0 mois\n", "#  English Term(s) : ['last \\\\> 0 month ago', 'last \\\\> 0 months ago']\n", "#  Index(es)       : [671, 672]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Coordinating_conjunction3 Pronoun4 Pronoun5 Verb6 Numeral7 Noun8 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nCoordinating_conjunction3 -> \">\"\nPronoun4 -> \"il\"\nPronoun5 -> \"y\"\nVerb6 -> \"a\"\nNumeral7 -> \"0\"\nNoun8 -> \"mois\" | \"mensualit\u00e9\" | \"menstrues\" | \"menstruation\" | \"r\u00e9tribution\" | \"appointements\" | \"traitement\" | \"salaire\" | \"paye\" | \"f\u00e9vrier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 349\n", "#  French Term     : l'automne dernier\n", "#  English Term(s) : ['last fall']\n", "#  Index(es)       : [681]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"automne\" | \"abaissement\" | \"cr\u00e9puscule\" | \"baisse\" | \"arri\u00e8re-saison\" | \"saison\" | \"Martin\" | \"tomb\u00e9e de la nuit\" | \"arri\u00e8re-automne\" | \"chute\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 350\n", "#  French Term     : mai dernier\n", "#  English Term(s) : ['last may']\n", "#  Index(es)       : [687]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"mai\" | \"domicile\" | \"mai\" | \"r\u00e9sidence\" | \"Lili\" | \"mois de Marie\" | \"may\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 351\n", "#  French Term     : novembre dernier\n", "#  English Term(s) : ['last november']\n", "#  Index(es)       : [688]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"novembre\" | \"Nicolas\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 352\n", "#  French Term     : Juillet dernier\n", "#  English Term(s) : ['last july']\n", "#  Index(es)       : [684]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"Juillet\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 353\n", "#  French Term     : janvier dernier\n", "#  English Term(s) : ['last january']\n", "#  Index(es)       : [683]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"janvier\" | \"janvier\" | \"Jan\" | \"Gommaire de Lierre\" | \"Janvier\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 354\n", "#  French Term     : Il y a \\ \\ 0 derni\u00e8res ann\u00e9es\n", "#  English Term(s) : ['last \\\\> 0 years ago']\n", "#  Index(es)       : [674]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Pronoun2 Verb3 Verb4 Other5 Numeral6 Adjective7 Noun8 Trigger_Rule\nPronoun1 -> \"Il\"\nPronoun2 -> \"y\"\nVerb3 -> \"a\"\nVerb4 -> \"\\\"\nOther5 -> \"\\\"\nNumeral6 -> \"0\"\nAdjective7 -> \"derni\u00e8res\"\nNoun8 -> \"ann\u00e9es\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 355\n", "#  French Term     : dernier d\u00e9cembre\n", "#  English Term(s) : ['last december']\n", "#  Index(es)       : [680]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Trigger_Rule\nAdjective1 -> \"dernier\"\nNoun2 -> \"d\u00e9cembre\" | \"Universit\u00e9 Harvard\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 356\n", "#  French Term     : ao\u00fbt dernier\n", "#  English Term(s) : ['last august']\n", "#  Index(es)       : [679]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"ao\u00fbt\" | \"moisson\" | \"aout\" | \"ao\u00fbt\" | \"San Pedro Sula\" | \"Ao\u00fbt\" | \"o\u00fbt\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 357\n", "#  French Term     : Juin dernier\n", "#  English Term(s) : ['last june']\n", "#  Index(es)       : [685]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"Juin\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 358\n", "#  French Term     : l'hiver dernier\n", "#  English Term(s) : ['last winter']\n", "#  Index(es)       : [693]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"hiver\" | \"vieillesse\" | \"frimas\" | \"froidure\" | \"an\" | \"froideur\" | \"hiver\" | \"\u00e9tat\" | \"temps\" | \"froids\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 359\n", "#  French Term     : avril dernier\n", "#  English Term(s) : ['last april']\n", "#  Index(es)       : [678]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"avril\" | \"aurore\" | \"germinal\" | \"avril\" | \"Avril\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 360\n", "#  French Term     : dernier mars\n", "#  English Term(s) : ['last march']\n", "#  Index(es)       : [686]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Trigger_Rule\nAdjective1 -> \"dernier\"\nNoun2 -> \"mars\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 361\n", "#  French Term     : Septembre dernier\n", "#  English Term(s) : ['last september']\n", "#  Index(es)       : [690]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"Septembre\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 362\n", "#  French Term     : dernier \\> 0 ans\n", "#  English Term(s) : ['last \\\\> 0 yrs ago']\n", "#  Index(es)       : [675]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Noun3 Numeral4 Noun5 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nNoun3 -> \">\"\nNumeral4 -> \"0\"\nNoun5 -> \"ans\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 363\n", "#  French Term     : dernier \\> il y a 1 semaine\n", "#  English Term(s) : ['last \\\\> 1 week ago', 'last \\\\> 1 weeks ago']\n", "#  Index(es)       : [676, 677]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Coordinating_conjunction3 Pronoun4 Pronoun5 Verb6 Numeral7 Noun8 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nCoordinating_conjunction3 -> \">\"\nPronoun4 -> \"il\"\nPronoun5 -> \"y\"\nVerb6 -> \"a\"\nNumeral7 -> \"1\"\nNoun8 -> \"semaine\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 364\n", "#  French Term     : octobre dernier\n", "#  English Term(s) : ['last october']\n", "#  Index(es)       : [689]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"octobre\" | \"vend\u00e9miaire\" | \"octobre\" | \"Octobre\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 365\n", "#  French Term     : l'\u00e9t\u00e9 dernier\n", "#  English Term(s) : ['last summer']\n", "#  Index(es)       : [692]\n", "#  Grouping(s)     : [626]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"\u00e9t\u00e9\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 366\n", "#  French Term     : contributeurs probables \u00e0\n", "#  English Term(s) : ['likely contributors to']\n", "#  Index(es)       : [695]\n", "#  Grouping(s)     : [642]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\nNoun1 -> \"contributeurs\" | \"abonn\u00e9\" | \"contributeur\" | \"donateur\"\nAdjective2 -> \"probables\"\nAdposition3 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 367\n", "#  French Term     : probablement en cas de\n", "#  English Term(s) : ['likely in setting of']\n", "#  Index(es)       : [697]\n", "#  Grouping(s)     : [642]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adposition2 Noun3 Adposition4 Trigger_Rule\nAdverb1 -> \"probablement\"\nAdposition2 -> \"en\"\nNoun3 -> \"cas\" | \"circonstance\" | \"affaire\" | \"fait\" | \"accident\" | \"possibilit\u00e9\" | \"\u00e9ventualit\u00e9\" | \"occasion\" | \"conjoncture\" | \"incident\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 368\n", "#  French Term     : probablement de\n", "#  English Term(s) : ['likely from']\n", "#  Index(es)       : [696]\n", "#  Grouping(s)     : [642]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adposition2 Trigger_Rule\nAdverb1 -> \"probablement\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 369\n", "#  French Term     : composante probable de\n", "#  English Term(s) : ['likely component of']\n", "#  Index(es)       : [694]\n", "#  Grouping(s)     : [642]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\nNoun1 -> \"composante\" | \"composante\" | \"\u00e9l\u00e9ment\" | \"constituant\" | \"corps\" | \"terme\" | \"unit\u00e9\" | \"ingr\u00e9dient\" | \"disposant\" | \"\u00e9crivant\"\nAdjective2 -> \"probable\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 370\n", "#  French Term     : refl\u00e9tant probablement\n", "#  English Term(s) : ['likely reflecting']\n", "#  Index(es)       : [698]\n", "#  Grouping(s)     : [646]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adverb2 Trigger_Rule\nVerb1 -> \"refl\u00e9tant\" | \"incarner\" | \"r\u00e9p\u00e9ter\" | \"exprimer\" | \"marquer\" | \"r\u00e9fl\u00e9chir\" | \"indiquer\" | \"traduire\" | \"rev\u00eatir\" | \"repr\u00e9senter\"\nAdverb2 -> \"probablement\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[646]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 371\n", "#  French Term     : probable\n", "#  English Term(s) : ['likely', 'probable']\n", "#  Index(es)       : [699, 700]\n", "#  Grouping(s)     : [647]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"probable\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[647]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 372\n", "#  French Term     : chercher tout\n", "#  English Term(s) : ['look for any']\n", "#  Index(es)       : [701]\n", "#  Grouping(s)     : [648]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adverb2 Trigger_Rule\nVerb1 -> \"chercher\" | \"imaginer\" | \"rechercher\" | \"tenter\" | \"essayer\" | \"explorer\" | \"scruter\" | \"consulter\" | \"sonder\" | \"requ\u00e9rir\"\nAdverb2 -> \"tout\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[648]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 373\n", "#  French Term     : chercher\n", "#  English Term(s) : ['look for']\n", "#  Index(es)       : [702]\n", "#  Grouping(s)     : [648]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"chercher\" | \"imaginer\" | \"rechercher\" | \"tenter\" | \"essayer\" | \"explorer\" | \"scruter\" | \"consulter\" | \"sonder\" | \"requ\u00e9rir\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[648]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 374\n", "#  French Term     : nettement\n", "#  English Term(s) : ['markedly']\n", "#  Index(es)       : [703]\n", "#  Grouping(s)     : [650]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"nettement\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[650]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 375\n", "#  French Term     : peut \u00eatre \\ w + sous-estim\u00e9\n", "#  English Term(s) : ['may be \\\\w+ underestimated']\n", "#  Index(es)       : [704]\n", "#  Grouping(s)     : [651]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Adposition5 Noun6 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nNoun6 -> \"sous-estim\u00e9\" | \"raval\u00e9\" | \"d\u00e9nigr\u00e9\" | \"d\u00e9consid\u00e9r\u00e9\" | \"minor\u00e9\" | \"minimis\u00e9\" | \"d\u00e9cr\u00e9dit\u00e9\" | \"m\u00e9sestim\u00e9\" | \"diminu\u00e9\" | \"d\u00e9tract\u00e9\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[651]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 376\n", "#  French Term     : peut contribuer\n", "#  English Term(s) : ['may be contributing']\n", "#  Index(es)       : [705]\n", "#  Grouping(s)     : [652]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"peut\"\nVerb2 -> \"contribuer\" | \"participer\" | \"coop\u00e9rer\" | \"favoriser\" | \"aider\" | \"agir\" | \"concourir\" | \"servir\" | \"collaborer\" | \"seconder\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[652]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 377\n", "#  French Term     : peut-\u00eatre d\u00fb \u00e0\n", "#  English Term(s) : ['may be due to']\n", "#  Index(es)       : [706]\n", "#  Grouping(s)     : [653]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adjective2 Adposition3 Trigger_Rule\nAdverb1 -> \"peut-\u00eatre\"\nAdjective2 -> \"d\u00fb\"\nAdposition3 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[653]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 378\n", "#  French Term     : peut \u00eatre d\u00e9masquer\n", "#  English Term(s) : ['may be unmasking']\n", "#  Index(es)       : [709]\n", "#  Grouping(s)     : [654]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"d\u00e9masquer\" | \"confondre\" | \"montrer\" | \"d\u00e9couvrir\" | \"d\u00e9montrer\" | \"d\u00e9voiler\" | \"br\u00fbler\" | \"livrer\" | \"arracher\" | \"p\u00e9n\u00e9trer\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 379\n", "#  French Term     : peut \u00eatre li\u00e9 \u00e0\n", "#  English Term(s) : ['may be related to']\n", "#  Index(es)       : [707]\n", "#  Grouping(s)     : [654]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"li\u00e9\" | \"ins\u00e9parable\" | \"adh\u00e9rent\" | \"conjoint\" | \"analogique\" | \"solidaire\" | \"reli\u00e9\" | \"imbriqu\u00e9\" | \"intime\" | \"b\u00e2t\u00e9\"\nAdposition4 -> \"\u00e0\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 380\n", "#  French Term     : peut \u00eatre sous-estim\u00e9\n", "#  English Term(s) : ['may be underestimated']\n", "#  Index(es)       : [708]\n", "#  Grouping(s)     : [654]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"sous-estim\u00e9\" | \"raval\u00e9\" | \"d\u00e9nigr\u00e9\" | \"d\u00e9consid\u00e9r\u00e9\" | \"minor\u00e9\" | \"minimis\u00e9\" | \"d\u00e9cr\u00e9dit\u00e9\" | \"m\u00e9sestim\u00e9\" | \"diminu\u00e9\" | \"d\u00e9tract\u00e9\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 381\n", "#  French Term     : peut \u00eatre\n", "#  English Term(s) : ['may be']\n", "#  Index(es)       : [710]\n", "#  Grouping(s)     : [659]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 382\n", "#  French Term     : peut repr\u00e9senter\n", "#  English Term(s) : ['may represent']\n", "#  Index(es)       : [713]\n", "#  Grouping(s)     : [659]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"peut\"\nVerb2 -> \"repr\u00e9senter\" | \"jouer\" | \"d\u00e9crire\" | \"exprimer\" | \"symboliser\" | \"montrer\" | \"correspondre\" | \"signifier\" | \"rendre\" | \"constituer\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 383\n", "#  French Term     : puis-je avoir\n", "#  English Term(s) : ['may have']\n", "#  Index(es)       : [712]\n", "#  Grouping(s)     : [659]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Verb2 Trigger_Rule\nAdjective1 -> \"puis-je\"\nVerb2 -> \"avoir\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 384\n", "#  French Term     : peut avoir \u00e9t\u00e9 pr\u00e9c\u00e9d\u00e9 par\n", "#  English Term(s) : ['may have been preceded by']\n", "#  Index(es)       : [711]\n", "#  Grouping(s)     : [659]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Auxiliary3 Verb4 Adposition5 Trigger_Rule\nAuxiliary1 -> \"peut\"\nAuxiliary2 -> \"avoir\"\nAuxiliary3 -> \"\u00e9t\u00e9\"\nVerb4 -> \"pr\u00e9c\u00e9d\u00e9\" | \"annoncer\" | \"diriger\" | \"appeler\" | \"d\u00e9passer\" | \"amener\" | \"aller\" | \"pr\u00e9luder\" | \"devancer\" | \"pr\u00e9venir\"\nAdposition5 -> \"par\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 385\n", "#  French Term     : doucement\n", "#  English Term(s) : ['mildly']\n", "#  Index(es)       : [715]\n", "#  Grouping(s)     : [666]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"doucement\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[666]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 386\n", "#  French Term     : doux\n", "#  English Term(s) : ['mild']\n", "#  Index(es)       : [716]\n", "#  Grouping(s)     : [666]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"doux\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[666]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 387\n", "#  French Term     : maman a appel\u00e9\n", "#  English Term(s) : ['mom called']\n", "#  Index(es)       : [717, 718]\n", "#  Grouping(s)     : [668, 669]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Auxiliary3 Trigger_Rule\nNoun1 -> \"maman\" | \"mamma\" | \"mamelle\" | \"accouch\u00e9e\" | \"mama\" | \"chrysanthemum morifolium\" | \"procr\u00e9atrice\" | \"g\u00e9nitrice\" | \"Mama\" | \"maman\"\nAuxiliary2 -> \"a\"\nAuxiliary3 -> \"appel\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[668, 669]\" |\"|both|termination|nonpatient|30|Group[668, 669]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 388\n", "#  French Term     : maman\n", "#  English Term(s) : ['mom']\n", "#  Index(es)       : [720]\n", "#  Grouping(s)     : [670]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"maman\" | \"mamma\" | \"mamelle\" | \"accouch\u00e9e\" | \"mama\" | \"chrysanthemum morifolium\" | \"procr\u00e9atrice\" | \"g\u00e9nitrice\" | \"Mama\" | \"maman\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[670]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 389\n", "#  French Term     : la maman\n", "#  English Term(s) : [\"mom's\"]\n", "#  Index(es)       : [719]\n", "#  Grouping(s)     : [670]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"maman\" | \"mamma\" | \"mamelle\" | \"accouch\u00e9e\" | \"mama\" | \"chrysanthemum morifolium\" | \"procr\u00e9atrice\" | \"g\u00e9nitrice\" | \"Mama\" | \"maman\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[670]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 390\n", "#  French Term     : surveiller le \\ w + pour\n", "#  English Term(s) : ['monitor the \\\\w+ for']\n", "#  Index(es)       : [722]\n", "#  Grouping(s)     : [672]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Noun4 Adposition5 Adposition6 Trigger_Rule\nVerb1 -> \"surveiller\" | \"observer\" | \"espionner\" | \"chaperonner\" | \"contr\u00f4ler\" | \"\u00e9pier\" | \"veiller\" | \"guetter\" | \"pister\" | \"examiner\"\nDeterminer2 -> \"le\"\nAdjective3 -> \"\\\"\nNoun4 -> \"w\"\nAdposition5 -> \"+\"\nAdposition6 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[672]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 391\n", "#  French Term     : surveiller \\ w + pour\n", "#  English Term(s) : ['monitor \\\\w+ for']\n", "#  Index(es)       : [721]\n", "#  Grouping(s)     : [672]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adjective2 Adposition3 Adposition4 Adposition5 Trigger_Rule\nVerb1 -> \"surveiller\" | \"observer\" | \"espionner\" | \"chaperonner\" | \"contr\u00f4ler\" | \"\u00e9pier\" | \"veiller\" | \"guetter\" | \"pister\" | \"examiner\"\nAdjective2 -> \"\\\"\nAdposition3 -> \"w\"\nAdposition4 -> \"+\"\nAdposition5 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[672]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 392\n", "#  French Term     : m\u00e8re a appel\u00e9\n", "#  English Term(s) : ['mother called']\n", "#  Index(es)       : [723, 724]\n", "#  Grouping(s)     : [674, 675]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Auxiliary3 Trigger_Rule\nNoun1 -> \"m\u00e8re\" | \"matrice\" | \"moule\" | \"ferment\" | \"nonne\" | \"source\" | \"femelle\" | \"surmoulage\" | \"patrie\" | \"mar\u00e2tre\"\nAuxiliary2 -> \"a\"\nAuxiliary3 -> \"appel\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[674, 675]\" |\"|both|termination|nonpatient|30|Group[674, 675]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 393\n", "#  French Term     : de la m\u00e8re\n", "#  English Term(s) : [\"mother's\"]\n", "#  Index(es)       : [725]\n", "#  Grouping(s)     : [676]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Trigger_Rule\nAdposition1 -> \"de\"\nDeterminer2 -> \"la\"\nNoun3 -> \"m\u00e8re\" | \"matrice\" | \"moule\" | \"ferment\" | \"nonne\" | \"source\" | \"femelle\" | \"surmoulage\" | \"patrie\" | \"mar\u00e2tre\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[676]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 394\n", "#  French Term     : m\u00e8re\n", "#  English Term(s) : ['mother']\n", "#  Index(es)       : [726]\n", "#  Grouping(s)     : [676]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"m\u00e8re\" | \"matrice\" | \"moule\" | \"ferment\" | \"nonne\" | \"source\" | \"femelle\" | \"surmoulage\" | \"patrie\" | \"mar\u00e2tre\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[676]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 395\n", "#  French Term     : doit \u00eatre exclu pour\n", "#  English Term(s) : ['must be ruled out for']\n", "#  Index(es)       : [727]\n", "#  Grouping(s)     : [678]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nVerb1 -> \"doit\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"exclu\" | \"exclusivement\" | \"expuls\u00e9\" | \"paria\" | \"renvoy\u00e9\" | \"prohib\u00e9\" | \"refus\u00e9\" | \"chass\u00e9\" | \"\u00e9conduit\" | \"inenvisageable\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[678]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 396\n", "#  French Term     : doit \u00eatre exclu\n", "#  English Term(s) : ['must be ruled out']\n", "#  Index(es)       : [728]\n", "#  Grouping(s)     : [679]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\nVerb1 -> \"doit\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"exclu\" | \"exclusivement\" | \"expuls\u00e9\" | \"paria\" | \"renvoy\u00e9\" | \"prohib\u00e9\" | \"refus\u00e9\" | \"chass\u00e9\" | \"\u00e9conduit\" | \"inenvisageable\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[679]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 397\n", "#  French Term     : non\n", "#  English Term(s) : ['n o', 'no']\n", "#  Index(es)       : [729, 730]\n", "#  Grouping(s)     : [680]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"non\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[680]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 398\n", "#  French Term     : n\u00e9g pour\n", "#  English Term(s) : ['neg for']\n", "#  Index(es)       : [733]\n", "#  Grouping(s)     : [682]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"n\u00e9g\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[682]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 399\n", "#  French Term     : n\u00e9g.\n", "#  English Term(s) : ['neg.']\n", "#  Index(es)       : [735]\n", "#  Grouping(s)     : [684]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Punctuation2 Trigger_Rule\nNoun1 -> \"n\u00e9g\"\nPunctuation2 -> \".\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[684]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "#  Item Number     : 400\n", "#  French Term     : n\u00e9gatif pour\n", "#  English Term(s) : ['negative for']\n", "#  Index(es)       : [737]\n", "#  Grouping(s)     : [686]\n\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Trigger_Rule\nAdjective1 -> \"n\u00e9gatif\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[686]\" \n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}]}