{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"du\"\nNoun2 -> \"grand-p\u00e8re\" | \"a\u00efeul\" | \"papi\" | \"papy\" | \"grand-papa\" | \"pap\u00e9\" | \"papet\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"grand-m\u00e8re\" | \"a\u00efeule\" | \"mamie\" | \"grand-maman\" | \"mamy\" | \"\"grandmaman\"\" | \"mammy\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"grand-p\u00e8re\" | \"a\u00efeul\" | \"papi\" | \"papy\" | \"grand-papa\" | \"pap\u00e9\" | \"papet\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"grand-m\u00e8re\" | \"a\u00efeule\" | \"mamie\" | \"grand-maman\" | \"mamy\" | \"\"grandmaman\"\" | \"mammy\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[551]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Noun2 Trigger_Rule\nNoun1 -> \"h\"\nNoun2 -> \"o\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[555, 556]|PRE-VALIDATION\"|\"|forward|trigger|nonpatient|30|Group[555, 556]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Adposition4 Adposition5 Adjective6 Adposition7 Trigger_Rule\nVerb1 -> \"avait\"\nDeterminer2 -> \"un\"\nAdjective3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nAdjective6 -> \"n\u00e9gatif\"\nAdposition7 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[557]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Adposition4 Adposition5 Adjective6 Adposition7 Trigger_Rule\nVerb1 -> \"a\"\nDeterminer2 -> \"un\"\nAdjective3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nAdjective6 -> \"n\u00e9gatif\"\nAdposition7 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[557]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Adjective3 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nAdjective3 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[561]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[561, 563]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Auxiliary2 Adverb3 Verb4 Determiner5 Trigger_Rule\nAdverb1 -> \"n'\"\nAuxiliary2 -> \"a\"\nAdverb3 -> \"pas\"\nVerb4 -> \"eu\"\nDeterminer5 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[569]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Adposition4 Adposition5 Adjective6 Adposition7 Trigger_Rule\nVerb1 -> \"avoir\"\nDeterminer2 -> \"un\"\nAdjective3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nAdjective6 -> \"n\u00e9gatif\"\nAdposition7 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[571]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"ont\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"\u00e9cart\u00e9s\" | \"rejeter\" | \"\u00e9liminer\" | \"\u00e9vincer\" | \"supprimer\" | \"proscrire\" | \"exclure\" | \"\u00e9loigner\" | \"c\u00f4t\u00e9\" | \"enlever\" | \"r\u00e9cuser\" | \"gouverner\" | \"mis \u00e0 l'\u00e9cart\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[573]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nPronoun1 -> \"il\"\nAuxiliary2 -> \"a\"\nVerb3 -> \"continu\u00e9\" | \"reconduire\" | \"perp\u00e9tuer\" | \"conserver\" | \"suivre\" | \"tenir\" | \"se poursuivre\" | \"donner suite\" | \"se perp\u00e9tuer\" | \"s'acharner\" | \"s'obstiner\" | \"entretenir\" | \"perdurer\" | \"opini\u00e2trer\" | \"ent\u00eater\"\nAdposition4 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[575]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"son\"\nNoun2 -> \"vieux\" | \"v\u00e9tuste\" | \"us\u00e9\" | \"pass\u00e9\" | \"fatigu\u00e9\" | \"s\u00e9culaire\" | \"\u00e9loign\u00e9\" | \"historique\" | \"usag\u00e9\" | \"p\u00e9rim\u00e9\" | \"vieilli\" | \"vieil\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[576]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nAdjective2 -> \"physique\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Noun3 Adjective4 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nAdposition2 -> \"de\"\nNoun3 -> \"plainte\" | \"g\u00e9missement\" | \"lamentation\" | \"protestation\" | \"reproche\" | \"plainte\"\nAdjective4 -> \"principale\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Coordinating_conjunction2 Adjective3 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nCoordinating_conjunction2 -> \"et\"\nAdjective3 -> \"physique\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Coordinating_conjunction2 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nCoordinating_conjunction2 -> \"et\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Coordinating_conjunction2 Noun3 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nCoordinating_conjunction2 -> \"et\"\nNoun3 -> \"examen\" | \"analyse\" | \"consultation\" | \"observation\" | \"v\u00e9rification\" | \"recherche\" | \"\u00e9tude\" | \"auscultation\" | \"examen m\u00e9dical\" | \"autopsie\" | \"d\u00e9pistage\" | \"interrogatoire\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Determiner3 Noun4 Adjective5 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nAdposition2 -> \"de\"\nDeterminer3 -> \"la\"\nNoun4 -> \"maladie\" | \"malaise\" | \"mal\" | \"trouble\" | \"indisposition\" | \"souffrance\" | \"syndrome\" | \"infirmit\u00e9\" | \"incommodit\u00e9\" | \"atteinte\" | \"tare\" | \"alt\u00e9ration\" | \"pathologie\" | \"traumatisme\" | \"r\u00e9cidive\"\nAdjective5 -> \"actuelle\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Verb2 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nVerb2 -> \"prenant\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[578]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Determiner2 Noun3 Trigger_Rule\nNoun1 -> \"#\"\nDeterminer2 -> \"l'\"\nNoun3 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[586]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"toutefois\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[587]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"ho\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[588]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"hx\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[589]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Subordinating_conjunction1 Adjective2 Trigger_Rule\nSubordinating_conjunction1 -> \"si\"\nAdjective2 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|both|pseudo|conditional|30|Group[590]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Subordinating_conjunction1 Trigger_Rule\nSubordinating_conjunction1 -> \"si\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[591]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Pronoun2 Trigger_Rule\nAdposition1 -> \"en\"\nPronoun2 -> \"elle\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[592]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Trigger_Rule\nAdposition1 -> \"dans\"\nDeterminer2 -> \"son\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[593]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"autrefois\"\nTrigger_Rule -> \"|both|trigger|historical|30|Group[594]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"dans\"\nDeterminer2 -> \"le\"\nNoun3 -> \"contexte\" | \"situation\" | \"circonstance\" | \"cadre\" | \"conjoncture\" | \"ambiance\" | \"atmosph\u00e8re\" | \"condition\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[595]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Trigger_Rule\nAdjective1 -> \"incompatible\"\nAdposition2 -> \"avec\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[596]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"indication\" | \"avertissement\" | \"prescription\" | \"directive\" | \"annotation\" | \"explication\" | \"renvoi\" | \"information\" | \"note\" | \"recommandation\" | \"crit\u00e8re\" | \"notation\" | \"suggestion\" | \"mention\" | \"sympt\u00f4me\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[598]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adjective2 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdjective2 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[599]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adverb2 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdverb2 -> \"neg\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[601]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Verb2 Adverb3 Trigger_Rule\nAdverb1 -> \"n'\"\nVerb2 -> \"est\"\nAdverb3 -> \"plus\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[603]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Auxiliary2 Adverb3 Trigger_Rule\nAdverb1 -> \"n'\"\nAuxiliary2 -> \"est\"\nAdverb3 -> \"pas\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[605]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"est\"\nVerb2 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[607]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"est\"\nVerb2 -> \"arr\u00eat\u00e9\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"interrompre\" | \"mettre fin\" | \"geler\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[609]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adposition2 Noun3 Adposition4 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdposition2 -> \"\u00e0\"\nNoun3 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[611]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adposition2 Noun3 Trigger_Rule\nAuxiliary1 -> \"est\"\nAdposition2 -> \"\u00e0\"\nNoun3 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[612]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"manque\" | \"insuffisance\" | \"d\u00e9faut\" | \"d\u00e9ficience\" | \"p\u00e9nurie\" | \"carence\" | \"privation\" | \"lacune\" | \"omission\" | \"manquement\" | \"d\u00e9faillance\" | \"raret\u00e9\" | \"oubli\" | \"faute\" | \"faiblesse\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[615]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"manquait\" | \"oublier\" | \"rater\" | \"fausser\" | \"d\u00e9choir\" | \"g\u00e2cher\" | \"omettre\" | \"enfreindre\" | \"faillir\" | \"\u00eatre absent\" | \"avoir disparu\" | \"\u00eatre en d\u00e9faut\" | \"\u00eatre d\u00e9nu\u00e9\" | \"\u00eatre d\u00e9pourvu\" | \"\u00eatre disparu\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[617]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"Le\"\nNoun2 -> \"printemps\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Coordinating_conjunction3 Numeral4 Noun5 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nCoordinating_conjunction3 -> \">\"\nNumeral4 -> \"0\"\nNoun5 -> \"ann\u00e9e\" | \"an\" | \"annuit\u00e9s\" | \"ans\" | \"annualit\u00e9\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"f\u00e9vrier\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Coordinating_conjunction3 Pronoun4 Pronoun5 Verb6 Numeral7 Noun8 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nCoordinating_conjunction3 -> \">\"\nPronoun4 -> \"il\"\nPronoun5 -> \"y\"\nVerb6 -> \"a\"\nNumeral7 -> \"0\"\nNoun8 -> \"mois\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"automne\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"mai\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"novembre\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"Juillet\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"janvier\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Pronoun2 Verb3 Verb4 Other5 Numeral6 Adjective7 Noun8 Trigger_Rule\nPronoun1 -> \"Il\"\nPronoun2 -> \"y\"\nVerb3 -> \"a\"\nVerb4 -> \"\\\"\nOther5 -> \"\\\"\nNumeral6 -> \"0\"\nAdjective7 -> \"derni\u00e8res\"\nNoun8 -> \"ann\u00e9es\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Trigger_Rule\nAdjective1 -> \"dernier\"\nNoun2 -> \"d\u00e9cembre\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"ao\u00fbt\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"Juin\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"hiver\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"avril\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Noun2 Trigger_Rule\nAdjective1 -> \"dernier\"\nNoun2 -> \"mars\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"Septembre\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Noun3 Numeral4 Noun5 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nNoun3 -> \">\"\nNumeral4 -> \"0\"\nNoun5 -> \"ans\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adjective2 Coordinating_conjunction3 Pronoun4 Pronoun5 Verb6 Numeral7 Noun8 Trigger_Rule\nAdjective1 -> \"dernier\"\nAdjective2 -> \"\\\"\nCoordinating_conjunction3 -> \">\"\nPronoun4 -> \"il\"\nPronoun5 -> \"y\"\nVerb6 -> \"a\"\nNumeral7 -> \"1\"\nNoun8 -> \"semaine\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"octobre\"\nAdjective2 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Adjective3 Trigger_Rule\nDeterminer1 -> \"l'\"\nNoun2 -> \"\u00e9t\u00e9\"\nAdjective3 -> \"dernier\"\nTrigger_Rule -> \"|backward|trigger|historical|30|Group[626]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\nNoun1 -> \"contributeurs\"\nAdjective2 -> \"probables\"\nAdposition3 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adposition2 Noun3 Adposition4 Trigger_Rule\nAdverb1 -> \"probablement\"\nAdposition2 -> \"en\"\nNoun3 -> \"cas\" | \"situation\" | \"\u00e9v\u00e9nement\" | \"possibilit\u00e9\" | \"\u00e9ventualit\u00e9\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adposition2 Trigger_Rule\nAdverb1 -> \"probablement\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\nNoun1 -> \"composante\" | \"\u00e9l\u00e9ment\" | \"ingr\u00e9dient\" | \"constituante\" | \"facteur\"\nAdjective2 -> \"probable\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[642]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adverb2 Trigger_Rule\nVerb1 -> \"refl\u00e9tant\" | \"exprimer\" | \"renvoyer\" | \"indiquer\" | \"marquer\" | \"traduire\" | \"incarner\"\nAdverb2 -> \"probablement\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[646]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"probable\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[647]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adverb2 Trigger_Rule\nVerb1 -> \"chercher\" | \"scruter\" | \"sonder\" | \"consulter\" | \"essayer\" | \"explorer\" | \"rechercher\" | \"examiner\" | \"fouiller\" | \"prospecter\" | \"interroger\" | \"d\u00e9couvrir\" | \"analyser\" | \"aller chercher\" | \"consid\u00e9rer\"\nAdverb2 -> \"tout\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"chercher\" | \"scruter\" | \"sonder\" | \"consulter\" | \"essayer\" | \"explorer\" | \"rechercher\" | \"examiner\" | \"fouiller\" | \"prospecter\" | \"interroger\" | \"d\u00e9couvrir\" | \"analyser\" | \"aller chercher\" | \"consid\u00e9rer\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[648]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"nettement\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[650]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Adposition5 Noun6 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"\\\"\nAdposition4 -> \"w\"\nAdposition5 -> \"+\"\nNoun6 -> \"sous-estim\u00e9\" | \"minimis\u00e9\" | \"minor\u00e9\" | \"m\u00e9sestim\u00e9\" | \"d\u00e9consid\u00e9r\u00e9\" | \"m\u00e9pris\u00e9\" | \"d\u00e9cri\u00e9\" | \"d\u00e9valu\u00e9\" | \"d\u00e9cr\u00e9dit\u00e9\" | \"discr\u00e9dit\u00e9\" | \"d\u00e9pr\u00e9ci\u00e9\" | \"m\u00e9jug\u00e9\" | \"d\u00e9valoris\u00e9\" | \"sous-\u00e9valu\u00e9\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[651]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"peut\"\nVerb2 -> \"contribuer\" | \"collaborer\" | \"concourir\" | \"coop\u00e9rer\" | \"participer\" | \"servir\" | \"seconder\" | \"favoriser\" | \"agir\" | \"tendre\" | \"avoir part\" | \"prendre part\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[652]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adjective2 Adposition3 Trigger_Rule\nAdverb1 -> \"peut-\u00eatre\"\nAdjective2 -> \"d\u00fb\"\nAdposition3 -> \"\u00e0\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[653]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"d\u00e9masquer\" | \"d\u00e9couvrir\" | \"montrer\" | \"r\u00e9v\u00e9ler\" | \"d\u00e9voiler\" | \"d\u00e9montrer\" | \"trahir\" | \"deviner\" | \"lever le masque\" | \"d\u00e9nicher\" | \"d\u00e9celer\" | \"d\u00e9pister\" | \"d\u00e9busquer\" | \"d\u00e9tecter\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"li\u00e9\" | \"connexe\" | \"reli\u00e9\" | \"imbriqu\u00e9\" | \"solidaire\" | \"analogique\" | \"conjoint\" | \"attach\u00e9\" | \"inh\u00e9rent\" | \"familier\" | \"allier\" | \"rattach\u00e9\" | \"coordonn\u00e9\" | \"adjoint\" | \"assujetti\"\nAdposition4 -> \"\u00e0\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"sous-estim\u00e9\" | \"minimis\u00e9\" | \"minor\u00e9\" | \"m\u00e9sestim\u00e9\" | \"d\u00e9consid\u00e9r\u00e9\" | \"m\u00e9pris\u00e9\" | \"d\u00e9cri\u00e9\" | \"d\u00e9valu\u00e9\" | \"d\u00e9cr\u00e9dit\u00e9\" | \"discr\u00e9dit\u00e9\" | \"d\u00e9pr\u00e9ci\u00e9\" | \"m\u00e9jug\u00e9\" | \"d\u00e9valoris\u00e9\" | \"sous-\u00e9valu\u00e9\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[654]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Trigger_Rule\nVerb1 -> \"peut\"\nAuxiliary2 -> \"\u00eatre\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"peut\"\nVerb2 -> \"repr\u00e9senter\" | \"symboliser\" | \"d\u00e9crire\" | \"montrer\" | \"reproduire\" | \"d\u00e9peindre\" | \"figurer\" | \"dessiner\" | \"peindre\" | \"exposer\" | \"pr\u00e9senter\" | \"signifier\" | \"exhiber\" | \"\u00e9voquer\" | \"d\u00e9signer\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Verb2 Trigger_Rule\nAdjective1 -> \"puis-je\"\nVerb2 -> \"avoir\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Auxiliary3 Verb4 Adposition5 Trigger_Rule\nAuxiliary1 -> \"peut\"\nAuxiliary2 -> \"avoir\"\nAuxiliary3 -> \"\u00e9t\u00e9\"\nVerb4 -> \"pr\u00e9c\u00e9d\u00e9\" | \"devancer\" | \"annoncer\" | \"pr\u00e9venir\" | \"distanc\u00e9\" | \"annonc\u00e9\" | \"devanc\u00e9\" | \"amen\u00e9\" | \"pr\u00e9lud\u00e9\"\nAdposition5 -> \"par\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[659]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"doucement\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[666]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"doux\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[666]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Auxiliary3 Trigger_Rule\nNoun1 -> \"maman\" | \"belle-m\u00e8re\" | \"belle-maman\"\nAuxiliary2 -> \"a\"\nAuxiliary3 -> \"appel\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[668, 669]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[668, 669]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"maman\" | \"belle-m\u00e8re\" | \"belle-maman\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[670]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"la\"\nNoun2 -> \"maman\" | \"belle-m\u00e8re\" | \"belle-maman\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[670]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Determiner2 Adjective3 Noun4 Adposition5 Adposition6 Trigger_Rule\nVerb1 -> \"surveiller\" | \"veiller\" | \"inspecter\" | \"examiner\" | \"suivre\" | \"v\u00e9rifier\" | \"avoir \u00e0 l'oeil\" | \"\u00eatre \u00e0 l'aff\u00fbt\" | \"superviser\" | \"faire attention\"\nDeterminer2 -> \"le\"\nAdjective3 -> \"\\\"\nNoun4 -> \"w\"\nAdposition5 -> \"+\"\nAdposition6 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adjective2 Adposition3 Adposition4 Adposition5 Trigger_Rule\nVerb1 -> \"surveiller\" | \"veiller\" | \"inspecter\" | \"examiner\" | \"suivre\" | \"v\u00e9rifier\" | \"avoir \u00e0 l'oeil\" | \"\u00eatre \u00e0 l'aff\u00fbt\" | \"superviser\" | \"faire attention\"\nAdjective2 -> \"\\\"\nAdposition3 -> \"w\"\nAdposition4 -> \"+\"\nAdposition5 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[672]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Auxiliary3 Trigger_Rule\nNoun1 -> \"m\u00e8re\" | \"parent\" | \"soeur\" | \"mere\" | \"parents\" | \"belle-m\u00e8re\"\nAuxiliary2 -> \"a\"\nAuxiliary3 -> \"appel\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[674, 675]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[674, 675]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Trigger_Rule\nAdposition1 -> \"de\"\nDeterminer2 -> \"la\"\nNoun3 -> \"m\u00e8re\" | \"parent\" | \"soeur\" | \"mere\" | \"parents\" | \"belle-m\u00e8re\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[676]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"m\u00e8re\" | \"parent\" | \"soeur\" | \"mere\" | \"parents\" | \"belle-m\u00e8re\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[676]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nVerb1 -> \"doit\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nAdposition4 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[678]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Auxiliary2 Verb3 Trigger_Rule\nVerb1 -> \"doit\"\nAuxiliary2 -> \"\u00eatre\"\nVerb3 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[679]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"non\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[680]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"n\u00e9g\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[682]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Punctuation2 Trigger_Rule\nNoun1 -> \"n\u00e9g\"\nPunctuation2 -> \".\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[684]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Trigger_Rule\nAdjective1 -> \"n\u00e9gatif\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[686]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}]}