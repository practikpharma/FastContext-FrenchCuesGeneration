{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Noun3 Trigger_Rule\nNoun1 -> \"rapports\" | \"liaison\" | \"correspondance\" | \"connexion\" | \"lien\" | \"concordance\" | \"similitude\" | \"analogie\" | \"corr\u00e9lation\" | \"interd\u00e9pendance\" | \"attachement\" | \"encha\u00eenement\" | \"rapprochement\"\nAdposition2 -> \"de\"\nNoun3 -> \"soeur\" | \"jumeau\" | \"belle-s\u0153ur\" | \"s\u0153ur\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1034, 1035]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1034, 1035]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Verb3 Trigger_Rule\nNoun1 -> \"soeur\" | \"jumeau\" | \"belle-s\u0153ur\" | \"s\u0153ur\"\nAuxiliary2 -> \"a\"\nVerb3 -> \"rapport\u00e9\" | \"r\u00e9v\u00e9ler\" | \"exposer\" | \"signaler\" | \"mentionner\" | \"d\u00e9voiler\" | \"t\u00e9moigner\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1034, 1035]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1034, 1035]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Auxiliary3 Trigger_Rule\nNoun1 -> \"soeur\" | \"jumeau\" | \"belle-s\u0153ur\" | \"s\u0153ur\"\nAuxiliary2 -> \"a\"\nAuxiliary3 -> \"appel\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1034, 1035]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1034, 1035]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"histoire\" | \"pass\u00e9\" | \"souvenir\" | \"historique\"\nAdjective2 -> \"sociale\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[1040]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Verb2 Trigger_Rule\nNoun1 -> \"fils\" | \"gar\u00e7on\" | \"beau-fils\"\nVerb2 -> \"rapport\u00e9\" | \"r\u00e9v\u00e9ler\" | \"exposer\" | \"signaler\" | \"mentionner\" | \"d\u00e9voiler\" | \"t\u00e9moigner\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1041, 1042]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1041, 1042]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Noun3 Trigger_Rule\nNoun1 -> \"rapports\" | \"liaison\" | \"correspondance\" | \"connexion\" | \"lien\" | \"concordance\" | \"similitude\" | \"analogie\" | \"corr\u00e9lation\" | \"interd\u00e9pendance\" | \"attachement\" | \"encha\u00eenement\" | \"rapprochement\"\nAdposition2 -> \"de\"\nNoun3 -> \"fils\" | \"gar\u00e7on\" | \"beau-fils\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1041, 1042]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1041, 1042]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Auxiliary2 Trigger_Rule\nNoun1 -> \"fils\" | \"gar\u00e7on\" | \"beau-fils\"\nAuxiliary2 -> \"appel\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1041, 1042]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1041, 1042]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"fils\" | \"gar\u00e7on\" | \"beau-fils\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[1047]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"des\"\nNoun2 -> \"fils\" | \"gar\u00e7on\" | \"beau-fils\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[1047]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"source\" | \"provenance\" | \"commencement\" | \"cause\" | \"fondement\" | \"d\u00e9but\" | \"point de d\u00e9part\" | \"source\" | \"d\u00e9part\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1049]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"source\" | \"provenance\" | \"commencement\" | \"cause\" | \"fondement\" | \"d\u00e9but\" | \"point de d\u00e9part\" | \"source\" | \"d\u00e9part\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1049]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"sources\" | \"provenance\" | \"racine\" | \"commencement\" | \"naissance\" | \"cause\" | \"fondement\" | \"base\" | \"amont\" | \"d\u00e9but\" | \"point de d\u00e9part\" | \"d\u00e9part\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1049]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"sources\" | \"provenance\" | \"racine\" | \"commencement\" | \"naissance\" | \"cause\" | \"fondement\" | \"base\" | \"amont\" | \"d\u00e9but\" | \"point de d\u00e9part\" | \"d\u00e9part\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1049]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Determiner3 Noun4 Trigger_Rule\nVerb1 -> \"parler\" | \"bavarder\" | \"discuter\" | \"dialoguer\" | \"converser\" | \"communiquer\" | \"s'entretenir\" | \"s'expliquer\" | \"s'adresser\"\nAdposition2 -> \"avec\"\nDeterminer3 -> \"la\"\nNoun4 -> \"famille\" | \"cercle familial\" | \"entourage\" | \"parents\" | \"belle-famille\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1053, 1054]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1053, 1054]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Determiner3 Noun4 Trigger_Rule\nVerb1 -> \"parl\u00e9\" | \"bavarder\" | \"discuter\" | \"dialoguer\" | \"converser\" | \"communiquer\" | \"s'entretenir\" | \"s'expliquer\" | \"s'adresser\"\nAdposition2 -> \"avec\"\nDeterminer3 -> \"la\"\nNoun4 -> \"famille\" | \"cercle familial\" | \"entourage\" | \"parents\" | \"belle-famille\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1053, 1054, 1094, 1095]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1053, 1054, 1094, 1095]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"\u00c9tats\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1057, 1058]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1057, 1058]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Noun3 Trigger_Rule\nNoun1 -> \"message\" | \"communication\" | \"avis\" | \"annonce\" | \"commission\" | \"communiqu\u00e9\" | \"information\" | \"signe\" | \"note\"\nAdposition2 -> \"de\"\nNoun3 -> \"statut\" | \"situation\" | \"condition\" | \"prescription\" | \"ordonnance\" | \"constitution\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[1059]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Trigger_Rule\nAdverb1 -> \"encore\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1060]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Verb3 Trigger_Rule\nVerb1 -> \"arr\u00eat\u00e9\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"interrompre\" | \"mettre fin\" | \"geler\"\nAdposition2 -> \"de\"\nVerb3 -> \"prendre\" | \"manger\" | \"absorber\" | \"avaler\" | \"boire\" | \"d\u00e9vorer\" | \"ingurgiter\" | \"ing\u00e9rer\"\nTrigger_Rule -> \"|both|pseudo|negated|10|Group[1061]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Verb3 Trigger_Rule\nNoun1 -> \"\u00e9tudes\" | \"examen\" | \"exp\u00e9rimentation\" | \"enqu\u00eate\" | \"analyse\" | \"approfondissement\" | \"exploration\" | \"observation\" | \"expertise\" | \"rapport\"\nAdposition2 -> \"pour\"\nVerb3 -> \"\u00e9valuer\" | \"juger\" | \"appr\u00e9cier\" | \"chiffrer\" | \"calculer\" | \"quantifier\" | \"mesurer\" | \"d\u00e9terminer\" | \"expertiser\" | \"jauger\" | \"compter\" | \"peser\" | \"comparer\" | \"examiner\" | \"recenser\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1062]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Verb3 Trigger_Rule\nNoun1 -> \"\u00e9tude\" | \"examen\" | \"exp\u00e9rimentation\" | \"enqu\u00eate\" | \"analyse\" | \"exploration\" | \"observation\" | \"expertise\" | \"rapport\" | \"investigation\"\nAdposition2 -> \"pour\"\nVerb3 -> \"\u00e9valuer\" | \"juger\" | \"appr\u00e9cier\" | \"chiffrer\" | \"calculer\" | \"quantifier\" | \"mesurer\" | \"d\u00e9terminer\" | \"expertiser\" | \"jauger\" | \"compter\" | \"peser\" | \"comparer\" | \"examiner\" | \"recenser\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1063]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\nNoun1 -> \"apparition\" | \"arriv\u00e9e\" | \"av\u00e8nement\" | \"\u00e9closion\" | \"venue\" | \"manifestation\" | \"\u00e9ruption\" | \"cr\u00e9ation\" | \"naissance\" | \"introduction\" | \"survenance\" | \"production\" | \"survenue\" | \"\u00e9mergence\" | \"pouss\u00e9e\"\nAdjective2 -> \"soudaine\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|both|pseudo|historical|30|Group[1064]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"\u00e9vocateur\" | \"\u00e9vocatoire\" | \"allusif\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1089]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"sugg\u00e9rer\" | \"proposer\" | \"inspirer\" | \"insinuer\" | \"\u00e9voquer\" | \"dicter\" | \"persuader\" | \"susciter\" | \"soumettre\" | \"enseigner\" | \"recommander\" | \"faire penser \u00e0\" | \"sous-entendre\" | \"supposer\" | \"envisager\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1090]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"soup\u00e7onn\u00e9\" | \"flairer\" | \"pressentir\" | \"deviner\" | \"douter\" | \"pr\u00e9sumer\" | \"entrevoir\" | \"sentir\" | \"redouter\" | \"conjecturer\" | \"penser\" | \"imaginer\" | \"subodorer\" | \"croire\" | \"avoir id\u00e9e de\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1091]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"soup\u00e7on\" | \"doute\" | \"suspicion\" | \"crainte\" | \"croyance\" | \"pr\u00e9somption\" | \"scepticisme\" | \"supposition\" | \"suspect\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1092]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Trigger_Rule\nVerb1 -> \"m\u00e9fiant\" | \"soup\u00e7onneux\" | \"timor\u00e9\" | \"prudent\" | \"suspicieux\" | \"dubitatif\" | \"d\u00e9fensif\" | \"douteux\" | \"craintive\" | \"avec m\u00e9fiance\" | \"suspect\" | \"pr\u00e9cautionneux\" | \"sceptique\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1093]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Determiner1 Noun2 Trigger_Rule\nDeterminer1 -> \"le\"\nNoun2 -> \"pr\u00e9sum\u00e9\" | \"soup\u00e7onner\" | \"estimer\" | \"conjecturer\" | \"pressentir\" | \"pr\u00e9sager\" | \"esp\u00e9rer\" | \"attendre\" | \"compter\" | \"pr\u00e9juger\" | \"pr\u00e9supposer\" | \"pr\u00e9tendre\" | \"pr\u00e9dire\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1098]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Adjective3 Trigger_Rule\nVerb1 -> \"\u00e9valuer\" | \"juger\" | \"appr\u00e9cier\" | \"chiffrer\" | \"calculer\" | \"quantifier\" | \"mesurer\" | \"d\u00e9terminer\" | \"expertiser\" | \"jauger\" | \"compter\" | \"peser\" | \"comparer\" | \"examiner\" | \"recenser\"\nAdposition2 -> \"pour\"\nAdjective3 -> \"tout\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1100]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"exclure\" | \"\u00e9liminer\" | \"rejeter\" | \"proscrire\" | \"\u00e9loigner\" | \"supprimer\" | \"radier\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1101]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"pour\"\nVerb2 -> \"pr\u00e9venir\" | \"pr\u00e9c\u00e9der\" | \"avertir\" | \"alerter\" | \"anticiper\" | \"emp\u00eacher\" | \"aviser\" | \"\u00e9viter\" | \"parer\" | \"conjurer\" | \"devant\" | \"signaler au\" | \"pr\u00e9munir contre\" | \"\u00e9carter\" | \"aller au-devant\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1103]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"aujourd'hui\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1104, 1105]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1104, 1105]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Trigger_Rule\nNoun1 -> \"traitement\" | \"soins\" | \"th\u00e9rapeutique\" | \"cure\" | \"intervention\" | \"rem\u00e8de\" | \"r\u00e9gime\" | \"soin\" | \"prescription\"\nAdposition2 -> \"de\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[1106]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\nNoun1 -> \"\u00e9v\u00e9nement\" | \"r\u00e9sultat\" | \"issue\" | \"\u00e9pisode\" | \"occasion\" | \"incident\" | \"fait\" | \"histoire\" | \"accident\" | \"\u00e9v\u00e8nement\" | \"condition\" | \"catastrophe\" | \"trag\u00e9die\" | \"\u00e9preuve\"\nAdjective2 -> \"d\u00e9clencheur\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1107]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"oncle\" | \"tonton\" | \"parents\"\nTrigger_Rule -> \"|forward|trigger|nonpatient|30|Group[1108]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Trigger_Rule\nNoun1 -> \"dose\" | \"mesure\" | \"quantit\u00e9\" | \"posologie\" | \"taux\" | \"ration\" | \"portion\" | \"prise\" | \"d\u00f4se\" | \"dosage\"\nAdjective2 -> \"incertaine\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[1109]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adjective2 Trigger_Rule\nAdverb1 -> \"pas\"\nAdjective2 -> \"clair\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1110]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Adjective2 Trigger_Rule\nAdverb1 -> \"peu\"\nAdjective2 -> \"probable\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[1112]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"particularit\u00e9\" | \"exception\" | \"irr\u00e9gularit\u00e9\" | \"anomalie\" | \"particularisme\" | \"sp\u00e9cificit\u00e9\" | \"circonstance\" | \"diff\u00e9rence\" | \"singularit\u00e9\" | \"indice\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1114]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"utilisation\" | \"emploi\" | \"maniement\" | \"usage\" | \"exploitation\" | \"consommation\" | \"appel\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1116]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"not\u00e9\" | \"constat\u00e9\" | \"relev\u00e9\" | \"remarqu\u00e9\" | \"observ\u00e9\" | \"consign\u00e9\" | \"communiqu\u00e9\" | \"qualit\u00e9\" | \"transcrit\" | \"class\u00e9\" | \"\u00e9valu\u00e9\" | \"\u00e9tiquet\u00e9\" | \"estim\u00e9\" | \"mentionn\u00e9\" | \"coch\u00e9\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"signes\" | \"signal\" | \"indice\" | \"marque\" | \"preuve\" | \"stigmate\" | \"annonce\" | \"indication\" | \"t\u00e9moignage\" | \"manifestation\" | \"traces\" | \"avertissements\" | \"observations\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"vital\" | \"indispensable\" | \"fondamental\" | \"primordial\" | \"principal\" | \"important\" | \"capital\" | \"substantiel\" | \"in\u00e9vitable\" | \"crucial\" | \"critique\" | \"essentielle\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"preuve\" | \"t\u00e9moignage\" | \"justification\" | \"d\u00e9monstration\" | \"gage\" | \"conviction\" | \"argument\" | \"constatation\" | \"confirmation\" | \"crit\u00e8re\" | \"signe\" | \"motif\" | \"assurance\" | \"fondement\" | \"\u00e9vidence\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"indication\" | \"avertissement\" | \"prescription\" | \"directive\" | \"annotation\" | \"explication\" | \"renvoi\" | \"information\" | \"note\" | \"recommandation\" | \"crit\u00e8re\" | \"notation\" | \"suggestion\" | \"mention\" | \"sympt\u00f4me\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdjective2 -> \"autre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"douleur\" | \"souffrance\" | \"mal\" | \"supplice\" | \"algie\" | \"g\u00e9missement\" | \"blessure\" | \"faire mal\" | \"nuisance\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"monter\" | \"\u00e9lever\" | \"rehausser\" | \"relever\" | \"hausser\" | \"remonter\" | \"r\u00e9hausser\" | \"s'intensifier\" | \"accro\u00eetre\" | \"accentuer\" | \"amplifier\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"nouveau\" | \"r\u00e9cent\" | \"original\" | \"in\u00e9dit\" | \"nouveaut\u00e9\" | \"naissant\" | \"commen\u00e7ant\" | \"nouvelle\" | \"r\u00e9cente\" | \"jeunes\" | \"nouvel\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"avoir\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdjective2 -> \"significative\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"majeur\" | \"important\" | \"exceptionnel\" | \"consid\u00e9rable\" | \"essentiel\" | \"principal\" | \"pr\u00e9dominant\" | \"pr\u00e9\u00e9minent\" | \"primordial\" | \"profond\" | \"capital\" | \"substantiel\" | \"\u00e9norme\" | \"grave\" | \"significatif\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"maximum\" | \"maximal\" | \"limite\" | \"pointe\" | \"sommet\" | \"pic\" | \"haut\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Pronoun2 Trigger_Rule\nAdposition1 -> \"sans\"\nPronoun2 -> \"certains\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdjective2 -> \"paraspinal\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"signe\" | \"signal\" | \"indice\" | \"marque\" | \"preuve\" | \"indication\" | \"t\u00e9moignage\" | \"manifestation\" | \"avertissement\" | \"trace\" | \"observation\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"gauche\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adverb2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdverb2 -> \"beaucoup\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"\u00e9prouver\" | \"ressentir\" | \"sentir\" | \"souffrir\" | \"exp\u00e9rimenter\" | \"endurer\" | \"risquer\" | \"affliger\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"grossier\" | \"vague\" | \"rudimentaire\" | \"approximatif\" | \"massif\" | \"\u00e9pais\" | \"imparfait\" | \"cru\" | \"sordide\" | \"r\u00e9pugnant\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"purulent\" | \"suppur\u00e9\" | \"suppurant\" | \"infect\u00e9\" | \"sanieux\" | \"coulant\" | \"infectieux\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"remarqu\u00e9\" | \"pens\u00e9e\" | \"consid\u00e9ration\" | \"commentaire\" | \"note\" | \"observation\" | \"not\u00e9\" | \"constat\u00e9\" | \"distingu\u00e9\" | \"d\u00e9couvert\" | \"observ\u00e9\" | \"per\u00e7u\" | \"vu\" | \"avis\u00e9\" | \"rep\u00e9r\u00e9\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"augmentation\" | \"extension\" | \"amplification\" | \"allongement\" | \"addition\" | \"\u00e9l\u00e9vation\" | \"hausse\" | \"aggravation\" | \"agrandissement\" | \"intensification\" | \"redoublement\" | \"dilatation\" | \"croissance\" | \"d\u00e9veloppement\" | \"mont\u00e9e\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"droit\" | \"net\" | \"franc\" | \"clair\" | \"uniforme\" | \"sain\" | \"d'aplomb\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"utiliser\" | \"exploiter\" | \"manipuler\" | \"servir\" | \"user\" | \"b\u00e9n\u00e9ficier\" | \"profiter\" | \"recourir\" | \"adopter\" | \"manier\" | \"mettre \u00e0 profit\" | \"tirer parti\" | \"tirer profit\" | \"se servir\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"rapport\" | \"correspondance\" | \"relation\" | \"accord\" | \"ressemblance\" | \"affinit\u00e9\" | \"r\u00e9cit\" | \"analogie\" | \"corr\u00e9lation\" | \"concordance\" | \"conformit\u00e9\" | \"parent\u00e9\" | \"expos\u00e9\" | \"rapprochement\" | \"t\u00e9moignage\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"\u00e9vidence\" | \"certitude\" | \"preuve\" | \"flagrance\" | \"nettet\u00e9\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"mention\" | \"\u00e9vocation\" | \"notation\" | \"signalement\" | \"note\" | \"expression\" | \"r\u00e9f\u00e9rence\" | \"reflet\" | \"allusion\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Pronoun2 Trigger_Rule\nAdposition1 -> \"sans\"\nPronoun2 -> \"laquelle\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Trigger_Rule\nAdposition1 -> \"sans\"\nDeterminer2 -> \"le\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"p\u00e9riph\u00e9rique\" | \"p\u00e9riph\u00e9rie\" | \"externe\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adverb2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdverb2 -> \"plus\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"preuve\" | \"t\u00e9moignage\" | \"justification\" | \"d\u00e9monstration\" | \"gage\" | \"conviction\" | \"argument\" | \"constatation\" | \"confirmation\" | \"crit\u00e8re\" | \"signe\" | \"motif\" | \"assurance\" | \"fondement\" | \"\u00e9vidence\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1117, 1119]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Trigger_Rule\nAdposition1 -> \"sans\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1121]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adposition2 Trigger_Rule\nAdposition1 -> \"w\"\nAdposition2 -> \"o\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1127]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"vouloir\" | \"souhaiter\" | \"demander\" | \"convoiter\" | \"exiger\" | \"requ\u00e9rir\" | \"r\u00e9clamer\" | \"ordonner\" | \"commander\" | \"tenir\" | \"envier\" | \"accepter\" | \"consentir\" | \"permettre\" | \"pr\u00e9tendre\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1129]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Adjective4 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"trouv\u00e9\" | \"reconnu\" | \"consid\u00e9r\u00e9\" | \"rep\u00e9r\u00e9\" | \"r\u00e9solu\" | \"compris\" | \"estim\u00e9\" | \"d\u00e9tect\u00e9\" | \"relev\u00e9\" | \"surpris\" | \"vu\" | \"d\u00e9nich\u00e9\" | \"retrouv\u00e9\" | \"d\u00e9got\u00e9\" | \"devin\u00e9\"\nAdjective4 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[1130, 1131]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[1130, 1131]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"trouv\u00e9\" | \"reconnu\" | \"consid\u00e9r\u00e9\" | \"rep\u00e9r\u00e9\" | \"r\u00e9solu\" | \"compris\" | \"estim\u00e9\" | \"d\u00e9tect\u00e9\" | \"relev\u00e9\" | \"surpris\" | \"vu\" | \"d\u00e9nich\u00e9\" | \"retrouv\u00e9\" | \"d\u00e9got\u00e9\" | \"devin\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1132, 1133]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1132, 1133]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adverb2 Verb3 Trigger_Rule\nAuxiliary1 -> \"\u00e9tait\"\nAdverb2 -> \"initialement\"\nVerb3 -> \"suspect\u00e9\" | \"mettre en cause\" | \"mettre en doute\" | \"sentir\" | \"pressentir\" | \"conjecturer\" | \"pr\u00e9juger\" | \"pr\u00e9figurer\" | \"doute\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[1134]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"charg\u00e9\" | \"d\u00e9l\u00e9gu\u00e9\" | \"confi\u00e9\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1135, 1136]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1135, 1136]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adjective2 Trigger_Rule\nAuxiliary1 -> \"\u00e9tait\"\nAdjective2 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[1137]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Adjective4 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"not\u00e9\" | \"constat\u00e9\" | \"relev\u00e9\" | \"remarqu\u00e9\" | \"observ\u00e9\" | \"consign\u00e9\" | \"communiqu\u00e9\" | \"qualit\u00e9\" | \"transcrit\" | \"class\u00e9\" | \"\u00e9valu\u00e9\" | \"\u00e9tiquet\u00e9\" | \"estim\u00e9\" | \"mentionn\u00e9\" | \"coch\u00e9\"\nAdjective4 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[1139]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Auxiliary2 Adverb3 Trigger_Rule\nAdverb1 -> \"n'\"\nAuxiliary2 -> \"\u00e9tait\"\nAdverb3 -> \"pas\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1141]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Adposition4 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"arr\u00eat\u00e9\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"interrompre\" | \"mettre fin\" | \"geler\"\nAdposition4 -> \"par\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1145]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Adposition4 Noun5 Adposition6 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"arr\u00eat\u00e9\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"interrompre\" | \"mettre fin\" | \"geler\"\nAdposition4 -> \"en\"\nNoun5 -> \"raison\" | \"cause\" | \"pourquoi\" | \"mobile\" | \"explication\" | \"fondement\"\nAdposition6 -> \"de\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1145]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"a\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"arr\u00eat\u00e9\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"interrompre\" | \"mettre fin\" | \"geler\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[1147, 1148]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[1147, 1148]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"\u00e9tait\"\nVerb2 -> \"soup\u00e7onn\u00e9\" | \"flairer\" | \"pressentir\" | \"deviner\" | \"douter\" | \"pr\u00e9sumer\" | \"entrevoir\" | \"sentir\" | \"redouter\" | \"conjecturer\" | \"penser\" | \"imaginer\" | \"subodorer\" | \"croire\" | \"avoir id\u00e9e de\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[1149]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"ont\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"instruits\" | \"inform\u00e9\" | \"renseign\u00e9\" | \"examin\u00e9\" | \"expliqu\u00e9\" | \"montr\u00e9\" | \"soign\u00e9\" | \"\u00e9clairci\" | \"expliquer\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1152, 1153]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1152, 1153]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Auxiliary2 Verb3 Trigger_Rule\nAuxiliary1 -> \"ont\"\nAuxiliary2 -> \"\u00e9t\u00e9\"\nVerb3 -> \"arr\u00eat\u00e9s\" | \"stopper\" | \"enrayer\" | \"contenir\" | \"suspendre\" | \"juguler\" | \"terminer\" | \"immobiliser\" | \"finir\" | \"endiguer\" | \"cesser\" | \"barrer\" | \"emp\u00eacher\" | \"geler\" | \"couper\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[1154, 1155]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[1154, 1155]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Adverb2 Trigger_Rule\nAuxiliary1 -> \"\u00e9taient\"\nAdverb2 -> \"totalement\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1156]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Pronoun2 Auxiliary3 Auxiliary4 Verb5 Auxiliary6 Trigger_Rule\nPronoun1 -> \"ce\"\nPronoun2 -> \"qui\"\nAuxiliary3 -> \"doit\"\nAuxiliary4 -> \"\u00eatre\"\nVerb5 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nAuxiliary6 -> \"est\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1157]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Subordinating_conjunction1 Noun2 Coordinating_conjunction3 Adverb4 Trigger_Rule\nSubordinating_conjunction1 -> \"si\"\nNoun2 -> \"oui\"\nCoordinating_conjunction3 -> \"ou\"\nAdverb4 -> \"non\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1158, 1159]|PRE-VALIDATION\"|\"|forward|pseudo|negated|30|Group[1158, 1159]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Trigger_Rule\nPronoun1 -> \"lequel\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1160, 1161]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1160, 1161]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Subordinating_conjunction2 Trigger_Rule\nAdverb1 -> \"tandis\"\nSubordinating_conjunction2 -> \"que\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1162]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Pronoun1 Adverb2 Auxiliary3 Adverb4 Adjective5 Trigger_Rule\nPronoun1 -> \"qui\"\nAdverb2 -> \"ne\"\nAuxiliary3 -> \"sont\"\nAdverb4 -> \"pas\"\nAdjective5 -> \"pr\u00e9sents\"\nTrigger_Rule -> \"|forward|termination|negated|10|Group[1163]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Adposition3 Trigger_Rule\nAuxiliary1 -> \"sera\"\nVerb2 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1164]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Auxiliary1 Verb2 Trigger_Rule\nAuxiliary1 -> \"sera\"\nVerb2 -> \"exclu\" | \"refus\u00e9\" | \"repouss\u00e9\" | \"rejet\u00e9\" | \"\u00e9limin\u00e9\" | \"proscrit\"\nTrigger_Rule -> \"|backward|trigger|uncertain|30|Group[1165]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nAdposition1 -> \"avec\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"papa\" | \"paternel\" | \"papas\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1166, 1167]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1166, 1167]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nAdposition1 -> \"avec\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"p\u00e8re\" | \"parent\" | \"abb\u00e9\" | \"beau-p\u00e8re\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1166, 1167]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1166, 1167]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nAdposition1 -> \"avec\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"m\u00e8re\" | \"parent\" | \"soeur\" | \"mere\" | \"parents\" | \"belle-m\u00e8re\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1166, 1167]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1166, 1167]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nAdposition1 -> \"avec\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"maman\" | \"belle-m\u00e8re\" | \"belle-maman\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1166, 1167]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1166, 1167]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nAdposition1 -> \"avec\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"fille\" | \"belle-fille\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1166, 1167]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1166, 1167]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nAdposition1 -> \"avec\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"fils\" | \"gar\u00e7on\" | \"beau-fils\"\nTrigger_Rule -> \"|both|termination|historical|30|Group[1166, 1167]|PRE-VALIDATION\"|\"|both|termination|nonpatient|30|Group[1166, 1167]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"avec\"\nDeterminer2 -> \"une\"\nNoun3 -> \"question\" | \"interpellation\" | \"information\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1178]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Trigger_Rule\nAdposition1 -> \"sans\"\nDeterminer2 -> \"un\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"suppl\u00e9ment\" | \"exc\u00e9dent\" | \"appoint\" | \"addition\" | \"surcro\u00eet\" | \"extra\" | \"surplus\" | \"additif\" | \"rallonge\" | \"ajout\" | \"avenant\" | \"exc\u00e8s\" | \"ajut\" | \"adjuvant\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Trigger_Rule\nAdposition1 -> \"sans\"\nDeterminer2 -> \"aucun\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"causer\" | \"susciter\" | \"amener\" | \"entra\u00eener\" | \"procurer\" | \"provoquer\" | \"occasionner\" | \"donner\" | \"engendrer\" | \"motiver\" | \"apporter\" | \"d\u00e9terminer\" | \"cr\u00e9er\" | \"\u00eatre cause de\" | \"d\u00e9clencher\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Determiner2 Noun3 Adposition4 Trigger_Rule\nAdposition1 -> \"sans\"\nDeterminer2 -> \"aucune\"\nNoun3 -> \"preuve\" | \"t\u00e9moignage\" | \"justification\" | \"d\u00e9monstration\" | \"gage\" | \"conviction\" | \"argument\" | \"constatation\" | \"confirmation\" | \"crit\u00e8re\" | \"signe\" | \"motif\" | \"assurance\" | \"fondement\" | \"\u00e9vidence\"\nAdposition4 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"apparente\" | \"visible\" | \"\u00e9vident\" | \"suppos\u00e9\" | \"probable\" | \"manifeste\" | \"superficiel\" | \"ostensible\" | \"perceptible\" | \"plausible\" | \"pro\u00e9minent\" | \"vraisemblable\" | \"discernable\" | \"apercevable\" | \"distinct\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Noun3 Adposition4 Noun5 Trigger_Rule\nAdposition1 -> \"sans\"\nAdjective2 -> \"\\\"\nNoun3 -> \"w\"\nAdposition4 -> \"+\"\nNoun5 -> \"preuves\" | \"t\u00e9moignage\" | \"justification\" | \"d\u00e9monstration\" | \"gage\" | \"conviction\" | \"argument\" | \"constatation\" | \"confirmation\" | \"crit\u00e8re\" | \"signe\" | \"assurance\" | \"fondement\" | \"\u00e9vidence\" | \"affirmation\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdjective2 -> \"actif\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"anormal\" | \"bizarre\" | \"singulier\" | \"insolite\" | \"irr\u00e9gulier\" | \"anomal\" | \"exceptionnel\" | \"\u00e9tonnant\" | \"extraordinaire\" | \"surprenant\" | \"inhabituel\" | \"\u00e9trange\" | \"d\u00e9form\u00e9\" | \"malade\" | \"pathologique\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Verb2 Trigger_Rule\nAdposition1 -> \"sans\"\nVerb2 -> \"devenir\" | \"rendre\" | \"futur\" | \"mouvant\" | \"dynamisme\" | \"mutation\" | \"passer\" | \"\u00eatre\" | \"changer\" | \"advenir\" | \"tourner\" | \"tomber\" | \"transformation\" | \"se faire\" | \"donner\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Auxiliary2 Trigger_Rule\nAdposition1 -> \"sans\"\nAuxiliary2 -> \"\u00eatre\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adjective2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdjective2 -> \"audible\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1181]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"difficult\u00e9s\" | \"mal\" | \"embarras\" | \"emp\u00eachement\" | \"obstacle\" | \"complication\" | \"probl\u00e8me\" | \"ennui\" | \"accroc\" | \"contrari\u00e9t\u00e9\" | \"r\u00e9sistance\" | \"complexit\u00e9\" | \"tracas\" | \"objection\" | \"peine\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[1207]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"diff\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[1207]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"peine\" | \"tristesse\" | \"douleur\" | \"souffrance\" | \"affliction\" | \"inqui\u00e9tude\" | \"tourment\" | \"d\u00e9solation\" | \"amertume\" | \"malheur\" | \"d\u00e9tresse\" | \"mis\u00e8re\" | \"difficult\u00e9\" | \"agonie\" | \"regret\"\nTrigger_Rule -> \"|both|pseudo|uncertain|30|Group[1207, 1208]|PRE-VALIDATION\"|\"|both|pseudo|negated|10|Group[1207, 1208]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adverb2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdverb2 -> \"non\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1243]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adverb2 Trigger_Rule\nAdposition1 -> \"sans\"\nAdverb2 -> \"pas\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1243]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Trigger_Rule\nAdposition1 -> \"sans\"\nNoun2 -> \"succ\u00e8s\" | \"effet\" | \"r\u00e9sultats\" | \"aboutissement\"\nTrigger_Rule -> \"|backward|trigger|negated|10|Group[1269, 1270]|PRE-VALIDATION\"|\"|forward|termination|negated|10|Group[1269, 1270]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Adposition2 Adverb3 Trigger_Rule\nAdposition1 -> \"sans\"\nAdposition2 -> \"pour\"\nAdverb3 -> \"autant\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1283]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Adposition2 Trigger_Rule\nAdjective1 -> \"inquiet\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1285]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Trigger_Rule\nVerb1 -> \"inqui\u00e9tant\" | \"effrayant\" | \"angoissant\" | \"troublant\" | \"mena\u00e7ant\" | \"alarmant\" | \"ennuyeux\" | \"intimidant\" | \"pr\u00e9occupant\" | \"d\u00e9concertant\" | \"grave\" | \"terrifiant\" | \"pessimiste\" | \"tragique\" | \"sombre\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1285]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Trigger_Rule\nVerb1 -> \"donn\u00e9\" | \"prescrit\" | \"administr\u00e9\" | \"prodigu\u00e9\" | \"appliqu\u00e9\" | \"fait\" | \"indiqu\u00e9\" | \"propos\u00e9\" | \"distribu\u00e9\" | \"redonn\u00e9\" | \"assen\u00e9\" | \"employ\u00e9\" | \"inocul\u00e9\"\nTrigger_Rule -> \"|forward|termination|uncertain|4|Group[1288, 1289]|PRE-VALIDATION\"|\"|forward|termination|conditional|4|Group[1288, 1289]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"avec\"\nNoun2 -> \"r\u00e9solution\" | \"dessein\" | \"intention\" | \"volont\u00e9\" | \"d\u00e9nouement\" | \"proposition\" | \"solution\" | \"t\u00e9nacit\u00e9\" | \"exigence\" | \"constance\" | \"ent\u00eatement\" | \"d\u00e9sir\" | \"cran\" | \"obstination\" | \"d\u00e9no\u00fbment\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|5|Group[1290]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Trigger_Rule\nNoun1 -> \"appel\" | \"r\u00e9clamation\" | \"rappel\" | \"avertissement\" | \"communication\" | \"coup de t\u00e9l\u00e9phone\" | \"appel t\u00e9l\u00e9phonique\" | \"t\u00e9l\u00e9phone\"\nTrigger_Rule -> \"|forward|trigger|negated|5|Group[1291]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adjective1 Trigger_Rule\nAdjective1 -> \"n\u00e9gatif\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1292]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Noun3 Trigger_Rule\nNoun1 -> \"h\"\nAdposition2 -> \"/\"\nNoun3 -> \"o\"\nTrigger_Rule -> \"|forward|trigger|historical|30|Group[1300, 1301]|PRE-VALIDATION\"|\"|forward|trigger|nonpatient|30|Group[1300, 1301]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adverb1 Noun2 Adposition3 Noun4 Trigger_Rule\nAdverb1 -> \"non\"\nNoun2 -> \"h\"\nAdposition3 -> \"/\"\nNoun4 -> \"o\"\nTrigger_Rule -> \"|forward|trigger|negated|10|Group[1304]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adposition2 Noun3 Trigger_Rule\nNoun1 -> \"r\"\nAdposition2 -> \"/\"\nNoun3 -> \"o\"\nTrigger_Rule -> \"|forward|trigger|uncertain|30|Group[1306]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Noun1 Adjective2 Adposition3 Trigger_Rule\nNoun1 -> \"risque\" | \"dangereux\" | \"chance\"\nAdjective2 -> \"\u00e9lev\u00e9\"\nAdposition3 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|negated|20|Group[1317]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Adposition1 Noun2 Adposition3 Trigger_Rule\nAdposition1 -> \"\u00e0\"\nNoun2 -> \"risque\" | \"dangereux\" | \"chance\"\nAdposition3 -> \"de\"\nTrigger_Rule -> \"|forward|trigger|negated|20|Group[1318]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Trigger_Rule\nVerb1 -> \"surveill\u00e9\" | \"veiller\" | \"inspecter\" | \"examiner\" | \"suivre\" | \"v\u00e9rifier\" | \"regarder\" | \"avoir \u00e0 l'oeil\" | \"\u00eatre \u00e0 l'aff\u00fbt\" | \"m\u00e9fier\" | \"superviser\" | \"faire attention\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1320]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": "null", "source": ["from nltk.parse.generate import generate, demo_grammar\n", "from nltk import CFG\n", "\n", "cfg_grammar= \"\"\"\n", "S ->  Verb1 Adposition2 Trigger_Rule\nVerb1 -> \"surveiller\" | \"veiller\" | \"inspecter\" | \"examiner\" | \"suivre\" | \"v\u00e9rifier\" | \"avoir \u00e0 l'oeil\" | \"\u00eatre \u00e0 l'aff\u00fbt\" | \"superviser\" | \"faire attention\"\nAdposition2 -> \"pour\"\nTrigger_Rule -> \"|forward|trigger|conditional|30|Group[1320]|PRE-VALIDATION\"\n", "\"\"\"\n", "\n", "for sentence in generate(CFG.fromstring(cfg_grammar), n=1000):\n", "    print(' '.join(sentence))"]}]}